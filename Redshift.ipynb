{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zcosmos = 'zcosmos-asu-txt.txt'\n",
    "f = open(zcosmos, 'r')\n",
    "data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosmos = 'cosmos-asu-txt.txt'\n",
    "g = open(cosmos, 'r')\n",
    "data2 = g.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'factor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c327494522e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'factor'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.factor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def primes(n):\n",
    "    primfac = []\n",
    "    d = 2\n",
    "    while d*d <= n:\n",
    "        while (n % d) == 0:\n",
    "            primfac.append(d)  # supposing you want multiple factors repeated\n",
    "            n //= d\n",
    "        d += 1\n",
    "    if n > 1:\n",
    "        primfac.append(n)\n",
    "    return primfac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 7, 7]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primes(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 M\n",
      "                                                 a\n",
      "z      RAJ        DEJ                C     Im\n"
     ]
    }
   ],
   "source": [
    "print(data[:3*49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "data = []\n",
    "\n",
    "with open('zcosmos-asu-txt.txt', 'r') as f:\n",
    "    read_the_data = csv.reader(f, delimiter=' ')\n",
    "    for row in read_the_data:\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'M'], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'a'], ['z', '', '', '', '', '', 'RAJ', '', '', '', '', '', '', '', 'DEJ', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'C', '', '', '', '', 'Imag', '', 's'], ['COSMOS', '2000', '(deg)', '2000', '(deg)', 'z', '', '', '', '', '', '', 'Class', '(mag)', 'k'], [], ['700137', '150.502792', '+01.877646', '', '0.8798', '', '', '1.5', '22.27', '1'], ['700142', '150.395737', '+01.837453', '', '0.6972', '', '', '3.5', '21.96', '1'], ['700178', '150.305008', '+01.876265', '', '0.9069', '', '', '9.5', '22.24', '1'], ['700189', '150.308258', '+01.916484', '', '0.8964', '', '', '2.5', '21.84', '1'], ['700210', '150.210480', '+01.828116', '', '0.2835', '', '', '1.5', '22.14', '1'], ['700219', '150.096649', '+01.866851', '', '0.6984', '', '', '1.5', '22.50', '1'], ['700229', '150.079788', '+01.917175', '', '', '', '', '', '', '', '', '', '', '0.0', '21.91', '1'], ['700247', '149.994583', '+01.839973', '', '', '', '', '', '', '', '', '', '', '0.0', '22.47', '1'], ['700257', '149.986618', '+01.885134', '', '0.0793', '', '', '9.3', '22.41', '1'], ['700267', '150.023560', '+01.826732', '', '', '', '', '', '', '', '', '', '', '0.0', '22.38', '1'], ['700273', '150.022873', '+01.826888', '', '0.3712', '', '24.5', '22.31', '1'], ['700274', '149.926743', '+01.869646', '', '0.5255', '', '', '4.5', '22.29', '1'], ['700276', '149.926590', '+01.936117', '', '0.0000', '', '', '4.4', '22.47', '1'], ['700284', '149.828354', '+01.827316', '', '', '', '', '', '', '', '', '', '', '0.0', '22.49', '1'], ['700291', '149.890167', '+01.859292', '', '0.9389', '', '', '2.5', '22.46', '1'], ['700296', '149.838379', '+01.906688', '', '0.3441', '', '', '3.5', '22.15', '1'], ['700298', '149.816711', '+01.916690', '', '0.8321', '', '', '3.5', '22.49', '1'], ['700447', '150.425690', '+02.123886', '', '0.7349', '', '', '3.5', '22.49', '1'], ['700448', '150.515930', '+02.123844', '', '', '', '', '', '', '', '', '', '20.0', '22.05', '1'], ['700458', '150.403305', '+02.055193', '', '', '', '', '', '', '', '', '', '', '0.0', '22.44', '1'], ['700468', '150.272659', '+01.966908', '', '0.3315', '', '', '3.5', '22.46', '1'], ['700480', '150.314987', '+02.008310', '', '0.1212', '', '', '9.1', '21.81', '1'], ['700485', '150.281250', '+02.018867', '', '0.2231', '', '', '1.1', '22.47', '1'], ['700490', '150.390335', '+02.032606', '', '0.2180', '', '', '3.5', '22.46', '1'], ['700496', '150.253342', '+02.047743', '', '', '', '', '', '', '', '', '', '', '0.0', '22.31', '1'], ['700497', '150.250412', '+02.049666', '', '1.1745', '', '', '1.5', '22.49', '1'], ['700501', '150.338699', '+02.069421', '', '', '', '', '', '', '', '', '', '', '0.0', '22.36', '1'], ['700504', '150.330231', '+02.070813', '', '', '', '', '', '', '', '', '', '20.0', '22.39', '1'], ['700508', '150.321060', '+02.080639', '', '0.8693', '', '', '9.5', '22.50', '1'], ['700514', '150.310593', '+02.103501', '', '0.7435', '', '', '3.5', '22.50', '1'], ['700517', '150.269043', '+02.113425', '', '0.6630', '', '', '4.5', '22.47', '1'], ['700518', '150.269592', '+02.124011', '', '0.8369', '', '', '3.1', '22.35', '1'], ['700521', '150.255112', '+02.115362', '', '0.9840', '', '', '1.1', '22.33', '1'], ['700523', '150.238770', '+02.053835', '', '', '', '', '', '', '', '', '', '', '0.0', '20.66', '1'], ['700526', '150.349777', '+01.981473', '', '0.4612', '', '', '2.1', '21.63', '1'], ['700529', '150.280594', '+02.021275', '', '0.2465', '', '', '3.5', '21.46', '1'], ['700534', '150.208984', '+01.964908', '', '0.6208', '', '', '3.5', '22.50', '1'], ['700549', '150.197693', '+02.015484', '', '', '', '', '', '', '', '', '', '', '0.0', '22.49', '1'], ['700551', '150.192886', '+02.015537', '', '0.4071', '', '', '1.5', '22.39', '1'], ['700558', '150.146378', '+02.061364', '', '0.7439', '', '', '2.5', '22.35', '1'], ['700559', '150.094986', '+02.062308', '', '0.7237', '', '', '3.1', '22.19', '1'], ['700567', '150.203461', '+02.098240', '', '0.9305', '', '', '3.1', '22.44', '1'], ['700568', '150.205734', '+02.105596', '', '0.4235', '', '', '3.5', '22.40', '1'], ['700571', '150.123367', '+02.109298', '', '0.0000', '', '', '4.1', '22.48', '1'], ['700576', '150.221207', '+02.103694', '', '0.1233', '', '', '3.1', '19.69', '1'], ['700583', '150.095154', '+02.116387', '', '0.1948', '', '', '4.4', '22.10', '1'], ['700585', '150.122604', '+02.108544', '', '0.7268', '', '', '2.5', '22.46', '1'], ['700587', '150.183044', '+02.028994', '', '0.2214', '', '', '3.4', '20.47', '1'], ['700593', '149.951141', '+01.974875', '', '0.3719', '', '', '4.5', '22.50', '1'], ['700597', '149.973602', '+02.007710', '', '0.8061', '', '', '1.1', '22.46', '1']]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_data = data[5:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['700137', '150.502792', '+01.877646', '', '0.8798', '', '', '1.5', '22.27', '1'], ['700142', '150.395737', '+01.837453', '', '0.6972', '', '', '3.5', '21.96', '1'], ['700178', '150.305008', '+01.876265', '', '0.9069', '', '', '9.5', '22.24', '1'], ['700189', '150.308258', '+01.916484', '', '0.8964', '', '', '2.5', '21.84', '1'], ['700210', '150.210480', '+01.828116', '', '0.2835', '', '', '1.5', '22.14', '1'], ['700219', '150.096649', '+01.866851', '', '0.6984', '', '', '1.5', '22.50', '1'], ['700229', '150.079788', '+01.917175', '', '', '', '', '', '', '', '', '', '', '0.0', '21.91', '1'], ['700247', '149.994583', '+01.839973', '', '', '', '', '', '', '', '', '', '', '0.0', '22.47', '1'], ['700257', '149.986618', '+01.885134', '', '0.0793', '', '', '9.3', '22.41', '1'], ['700267', '150.023560', '+01.826732', '', '', '', '', '', '', '', '', '', '', '0.0', '22.38', '1'], ['700273', '150.022873', '+01.826888', '', '0.3712', '', '24.5', '22.31', '1'], ['700274', '149.926743', '+01.869646', '', '0.5255', '', '', '4.5', '22.29', '1'], ['700276', '149.926590', '+01.936117', '', '0.0000', '', '', '4.4', '22.47', '1'], ['700284', '149.828354', '+01.827316', '', '', '', '', '', '', '', '', '', '', '0.0', '22.49', '1'], ['700291', '149.890167', '+01.859292', '', '0.9389', '', '', '2.5', '22.46', '1'], ['700296', '149.838379', '+01.906688', '', '0.3441', '', '', '3.5', '22.15', '1'], ['700298', '149.816711', '+01.916690', '', '0.8321', '', '', '3.5', '22.49', '1'], ['700447', '150.425690', '+02.123886', '', '0.7349', '', '', '3.5', '22.49', '1'], ['700448', '150.515930', '+02.123844', '', '', '', '', '', '', '', '', '', '20.0', '22.05', '1'], ['700458', '150.403305', '+02.055193', '', '', '', '', '', '', '', '', '', '', '0.0', '22.44', '1'], ['700468', '150.272659', '+01.966908', '', '0.3315', '', '', '3.5', '22.46', '1'], ['700480', '150.314987', '+02.008310', '', '0.1212', '', '', '9.1', '21.81', '1'], ['700485', '150.281250', '+02.018867', '', '0.2231', '', '', '1.1', '22.47', '1'], ['700490', '150.390335', '+02.032606', '', '0.2180', '', '', '3.5', '22.46', '1'], ['700496', '150.253342', '+02.047743', '', '', '', '', '', '', '', '', '', '', '0.0', '22.31', '1'], ['700497', '150.250412', '+02.049666', '', '1.1745', '', '', '1.5', '22.49', '1'], ['700501', '150.338699', '+02.069421', '', '', '', '', '', '', '', '', '', '', '0.0', '22.36', '1'], ['700504', '150.330231', '+02.070813', '', '', '', '', '', '', '', '', '', '20.0', '22.39', '1'], ['700508', '150.321060', '+02.080639', '', '0.8693', '', '', '9.5', '22.50', '1'], ['700514', '150.310593', '+02.103501', '', '0.7435', '', '', '3.5', '22.50', '1'], ['700517', '150.269043', '+02.113425', '', '0.6630', '', '', '4.5', '22.47', '1'], ['700518', '150.269592', '+02.124011', '', '0.8369', '', '', '3.1', '22.35', '1'], ['700521', '150.255112', '+02.115362', '', '0.9840', '', '', '1.1', '22.33', '1'], ['700523', '150.238770', '+02.053835', '', '', '', '', '', '', '', '', '', '', '0.0', '20.66', '1'], ['700526', '150.349777', '+01.981473', '', '0.4612', '', '', '2.1', '21.63', '1'], ['700529', '150.280594', '+02.021275', '', '0.2465', '', '', '3.5', '21.46', '1'], ['700534', '150.208984', '+01.964908', '', '0.6208', '', '', '3.5', '22.50', '1'], ['700549', '150.197693', '+02.015484', '', '', '', '', '', '', '', '', '', '', '0.0', '22.49', '1'], ['700551', '150.192886', '+02.015537', '', '0.4071', '', '', '1.5', '22.39', '1'], ['700558', '150.146378', '+02.061364', '', '0.7439', '', '', '2.5', '22.35', '1'], ['700559', '150.094986', '+02.062308', '', '0.7237', '', '', '3.1', '22.19', '1'], ['700567', '150.203461', '+02.098240', '', '0.9305', '', '', '3.1', '22.44', '1'], ['700568', '150.205734', '+02.105596', '', '0.4235', '', '', '3.5', '22.40', '1'], ['700571', '150.123367', '+02.109298', '', '0.0000', '', '', '4.1', '22.48', '1'], ['700576', '150.221207', '+02.103694', '', '0.1233', '', '', '3.1', '19.69', '1'], ['700583', '150.095154', '+02.116387', '', '0.1948', '', '', '4.4', '22.10', '1'], ['700585', '150.122604', '+02.108544', '', '0.7268', '', '', '2.5', '22.46', '1'], ['700587', '150.183044', '+02.028994', '', '0.2214', '', '', '3.4', '20.47', '1']]\n"
     ]
    }
   ],
   "source": [
    "print(actual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-cef3a3b051ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactual_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "for item in actual_data[1]:\n",
    "    item = float(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import astropy\n",
    "from astropy import io\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package astropy.io.fits in astropy.io:\n",
      "\n",
      "NAME\n",
      "    astropy.io.fits\n",
      "\n",
      "DESCRIPTION\n",
      "    A package for reading and writing FITS files and manipulating their\n",
      "    contents.\n",
      "    \n",
      "    A module for reading and writing Flexible Image Transport System\n",
      "    (FITS) files.  This file format was endorsed by the International\n",
      "    Astronomical Union in 1999 and mandated by NASA as the standard format\n",
      "    for storing high energy astrophysics data.  For details of the FITS\n",
      "    standard, see the NASA/Science Office of Standards and Technology\n",
      "    publication, NOST 100-2.0.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _numpy_hacks\n",
      "    card\n",
      "    column\n",
      "    compression\n",
      "    connect\n",
      "    convenience\n",
      "    diff\n",
      "    file\n",
      "    fitsrec\n",
      "    hdu (package)\n",
      "    header\n",
      "    py3compat\n",
      "    scripts (package)\n",
      "    setup_package\n",
      "    tests (package)\n",
      "    util\n",
      "    verify\n",
      "\n",
      "CLASSES\n",
      "    astropy.config.configuration.ConfigNamespace(builtins.object)\n",
      "        Conf\n",
      "    astropy.io.fits.hdu.base.ExtensionHDU(astropy.io.fits.hdu.base._ValidHDU)\n",
      "        astropy.io.fits.hdu.image.ImageHDU(astropy.io.fits.hdu.image._ImageBaseHDU, astropy.io.fits.hdu.base.ExtensionHDU)\n",
      "    astropy.io.fits.hdu.base.NonstandardExtHDU(astropy.io.fits.hdu.base.ExtensionHDU)\n",
      "        astropy.io.fits.hdu.nonstandard.FitsHDU\n",
      "    astropy.io.fits.hdu.image._ImageBaseHDU(astropy.io.fits.hdu.base._ValidHDU)\n",
      "        astropy.io.fits.hdu.image.ImageHDU(astropy.io.fits.hdu.image._ImageBaseHDU, astropy.io.fits.hdu.base.ExtensionHDU)\n",
      "        astropy.io.fits.hdu.image.PrimaryHDU\n",
      "            astropy.io.fits.hdu.groups.GroupsHDU(astropy.io.fits.hdu.image.PrimaryHDU, astropy.io.fits.hdu.table._TableLikeHDU)\n",
      "    astropy.io.fits.hdu.table._TableBaseHDU(astropy.io.fits.hdu.base.ExtensionHDU, astropy.io.fits.hdu.table._TableLikeHDU)\n",
      "        astropy.io.fits.hdu.table.BinTableHDU\n",
      "            astropy.io.fits.hdu.compressed.CompImageHDU\n",
      "        astropy.io.fits.hdu.table.TableHDU\n",
      "    astropy.io.fits.util.NotifierMixin(builtins.object)\n",
      "        astropy.io.fits.column.ColDefs\n",
      "        astropy.io.fits.column.Column\n",
      "    astropy.io.fits.verify._Verify(builtins.object)\n",
      "        astropy.io.fits.card.Card\n",
      "        astropy.io.fits.hdu.hdulist.HDUList(builtins.list, astropy.io.fits.verify._Verify)\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        astropy.io.fits.verify.VerifyError\n",
      "    builtins.list(builtins.object)\n",
      "        astropy.io.fits.hdu.hdulist.HDUList(builtins.list, astropy.io.fits.verify._Verify)\n",
      "    builtins.object\n",
      "        astropy.io.fits.card.Undefined\n",
      "        astropy.io.fits.column.Delayed\n",
      "        astropy.io.fits.fitsrec.FITS_record\n",
      "            astropy.io.fits.hdu.groups.Group\n",
      "        astropy.io.fits.hdu.image.Section\n",
      "        astropy.io.fits.hdu.streaming.StreamingHDU\n",
      "        astropy.io.fits.header.Header\n",
      "    numpy.recarray(numpy.ndarray)\n",
      "        astropy.io.fits.fitsrec.FITS_rec\n",
      "            astropy.io.fits.hdu.groups.GroupData\n",
      "    \n",
      "    class BinTableHDU(_TableBaseHDU)\n",
      "     |  Binary table HDU class.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  data : array, `FITS_rec`, or `~astropy.table.Table`\n",
      "     |      Data to be used.\n",
      "     |  header : `Header`\n",
      "     |      Header to be used.\n",
      "     |  name : str\n",
      "     |      Name to be populated in ``EXTNAME`` keyword.\n",
      "     |  uint : bool, optional\n",
      "     |      Set to `True` if the table contains unsigned integer columns.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BinTableHDU\n",
      "     |      _TableBaseHDU\n",
      "     |      astropy.io.fits.hdu.base.ExtensionHDU\n",
      "     |      _TableLikeHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None, name=None, uint=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  dump(self, datafile=None, cdfile=None, hfile=None, overwrite=False)\n",
      "     |      Dump the table HDU to a file in ASCII format.  The table may be dumped\n",
      "     |      in three separate files, one containing column definitions, one\n",
      "     |      containing header parameters, and one for table data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      datafile : file path, file object or file-like object, optional\n",
      "     |          Output data file.  The default is the root name of the\n",
      "     |          fits file associated with this HDU appended with the\n",
      "     |          extension ``.txt``.\n",
      "     |      \n",
      "     |      cdfile : file path, file object or file-like object, optional\n",
      "     |          Output column definitions file.  The default is `None`, no\n",
      "     |          column definitions output is produced.\n",
      "     |      \n",
      "     |      hfile : file path, file object or file-like object, optional\n",
      "     |          Output header parameters file.  The default is `None`,\n",
      "     |          no header parameters output is produced.\n",
      "     |      \n",
      "     |      overwrite : bool, optional\n",
      "     |          If ``True``, overwrite the output file if it exists. Raises an\n",
      "     |          ``OSError`` (``IOError`` for Python 2) if ``False`` and the\n",
      "     |          output file exists. Default is ``False``.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.3\n",
      "     |             ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The primary use for the `dump` method is to allow viewing and editing\n",
      "     |      the table data and parameters in a standard text editor.\n",
      "     |      The `load` method can be used to create a new table from the three\n",
      "     |      plain text (ASCII) files.\n",
      "     |      \n",
      "     |      \n",
      "     |      - **datafile:** Each line of the data file represents one row of table\n",
      "     |        data.  The data is output one column at a time in column order.  If\n",
      "     |        a column contains an array, each element of the column array in the\n",
      "     |        current row is output before moving on to the next column.  Each row\n",
      "     |        ends with a new line.\n",
      "     |      \n",
      "     |        Integer data is output right-justified in a 21-character field\n",
      "     |        followed by a blank.  Floating point data is output right justified\n",
      "     |        using 'g' format in a 21-character field with 15 digits of\n",
      "     |        precision, followed by a blank.  String data that does not contain\n",
      "     |        whitespace is output left-justified in a field whose width matches\n",
      "     |        the width specified in the ``TFORM`` header parameter for the\n",
      "     |        column, followed by a blank.  When the string data contains\n",
      "     |        whitespace characters, the string is enclosed in quotation marks\n",
      "     |        (``\"\"``).  For the last data element in a row, the trailing blank in\n",
      "     |        the field is replaced by a new line character.\n",
      "     |      \n",
      "     |        For column data containing variable length arrays ('P' format), the\n",
      "     |        array data is preceded by the string ``'VLA_Length= '`` and the\n",
      "     |        integer length of the array for that row, left-justified in a\n",
      "     |        21-character field, followed by a blank.\n",
      "     |      \n",
      "     |        .. note::\n",
      "     |      \n",
      "     |            This format does *not* support variable length arrays using the\n",
      "     |            ('Q' format) due to difficult to overcome ambiguities. What this\n",
      "     |            means is that this file format cannot support VLA columns in\n",
      "     |            tables stored in files that are over 2 GB in size.\n",
      "     |      \n",
      "     |        For column data representing a bit field ('X' format), each bit\n",
      "     |        value in the field is output right-justified in a 21-character field\n",
      "     |        as 1 (for true) or 0 (for false).\n",
      "     |      \n",
      "     |      - **cdfile:** Each line of the column definitions file provides the\n",
      "     |        definitions for one column in the table.  The line is broken up into\n",
      "     |        8, sixteen-character fields.  The first field provides the column\n",
      "     |        name (``TTYPEn``).  The second field provides the column format\n",
      "     |        (``TFORMn``).  The third field provides the display format\n",
      "     |        (``TDISPn``).  The fourth field provides the physical units\n",
      "     |        (``TUNITn``).  The fifth field provides the dimensions for a\n",
      "     |        multidimensional array (``TDIMn``).  The sixth field provides the\n",
      "     |        value that signifies an undefined value (``TNULLn``).  The seventh\n",
      "     |        field provides the scale factor (``TSCALn``).  The eighth field\n",
      "     |        provides the offset value (``TZEROn``).  A field value of ``\"\"`` is\n",
      "     |        used to represent the case where no value is provided.\n",
      "     |      \n",
      "     |      - **hfile:** Each line of the header parameters file provides the\n",
      "     |        definition of a single HDU header card as represented by the card\n",
      "     |        image.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  load(datafile, cdfile=None, hfile=None, replace=False, header=None) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Create a table from the input ASCII files.  The input is from up to\n",
      "     |      three separate files, one containing column definitions, one containing\n",
      "     |      header parameters, and one containing column data.\n",
      "     |      \n",
      "     |      The column definition and header parameters files are not required.\n",
      "     |      When absent the column definitions and/or header parameters are taken\n",
      "     |      from the header object given in the header argument; otherwise sensible\n",
      "     |      defaults are inferred (though this mode is not recommended).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      datafile : file path, file object or file-like object\n",
      "     |          Input data file containing the table data in ASCII format.\n",
      "     |      \n",
      "     |      cdfile : file path, file object, file-like object, optional\n",
      "     |          Input column definition file containing the names,\n",
      "     |          formats, display formats, physical units, multidimensional\n",
      "     |          array dimensions, undefined values, scale factors, and\n",
      "     |          offsets associated with the columns in the table.  If\n",
      "     |          `None`, the column definitions are taken from the current\n",
      "     |          values in this object.\n",
      "     |      \n",
      "     |      hfile : file path, file object, file-like object, optional\n",
      "     |          Input parameter definition file containing the header\n",
      "     |          parameter definitions to be associated with the table.  If\n",
      "     |          `None`, the header parameter definitions are taken from\n",
      "     |          the current values in this objects header.\n",
      "     |      \n",
      "     |      replace : bool\n",
      "     |          When `True`, indicates that the entire header should be\n",
      "     |          replaced with the contents of the ASCII file instead of\n",
      "     |          just updating the current header.\n",
      "     |      \n",
      "     |      header : Header object\n",
      "     |          When the cdfile and hfile are missing, use this Header object in\n",
      "     |          the creation of the new table and HDU.  Otherwise this Header\n",
      "     |          supercedes the keywords from hfile, which is only used to update\n",
      "     |          values not present in this Header, unless ``replace=True`` in which\n",
      "     |          this Header's values are completely replaced with the values from\n",
      "     |          hfile.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The primary use for the `load` method is to allow the input of ASCII\n",
      "     |      data that was edited in a standard text editor of the table data and\n",
      "     |      parameters.  The `dump` method can be used to create the initial ASCII\n",
      "     |      files.\n",
      "     |      \n",
      "     |      \n",
      "     |      - **datafile:** Each line of the data file represents one row of table\n",
      "     |        data.  The data is output one column at a time in column order.  If\n",
      "     |        a column contains an array, each element of the column array in the\n",
      "     |        current row is output before moving on to the next column.  Each row\n",
      "     |        ends with a new line.\n",
      "     |      \n",
      "     |        Integer data is output right-justified in a 21-character field\n",
      "     |        followed by a blank.  Floating point data is output right justified\n",
      "     |        using 'g' format in a 21-character field with 15 digits of\n",
      "     |        precision, followed by a blank.  String data that does not contain\n",
      "     |        whitespace is output left-justified in a field whose width matches\n",
      "     |        the width specified in the ``TFORM`` header parameter for the\n",
      "     |        column, followed by a blank.  When the string data contains\n",
      "     |        whitespace characters, the string is enclosed in quotation marks\n",
      "     |        (``\"\"``).  For the last data element in a row, the trailing blank in\n",
      "     |        the field is replaced by a new line character.\n",
      "     |      \n",
      "     |        For column data containing variable length arrays ('P' format), the\n",
      "     |        array data is preceded by the string ``'VLA_Length= '`` and the\n",
      "     |        integer length of the array for that row, left-justified in a\n",
      "     |        21-character field, followed by a blank.\n",
      "     |      \n",
      "     |        .. note::\n",
      "     |      \n",
      "     |            This format does *not* support variable length arrays using the\n",
      "     |            ('Q' format) due to difficult to overcome ambiguities. What this\n",
      "     |            means is that this file format cannot support VLA columns in\n",
      "     |            tables stored in files that are over 2 GB in size.\n",
      "     |      \n",
      "     |        For column data representing a bit field ('X' format), each bit\n",
      "     |        value in the field is output right-justified in a 21-character field\n",
      "     |        as 1 (for true) or 0 (for false).\n",
      "     |      \n",
      "     |      - **cdfile:** Each line of the column definitions file provides the\n",
      "     |        definitions for one column in the table.  The line is broken up into\n",
      "     |        8, sixteen-character fields.  The first field provides the column\n",
      "     |        name (``TTYPEn``).  The second field provides the column format\n",
      "     |        (``TFORMn``).  The third field provides the display format\n",
      "     |        (``TDISPn``).  The fourth field provides the physical units\n",
      "     |        (``TUNITn``).  The fifth field provides the dimensions for a\n",
      "     |        multidimensional array (``TDIMn``).  The sixth field provides the\n",
      "     |        value that signifies an undefined value (``TNULLn``).  The seventh\n",
      "     |        field provides the scale factor (``TSCALn``).  The eighth field\n",
      "     |        provides the offset value (``TZEROn``).  A field value of ``\"\"`` is\n",
      "     |        used to represent the case where no value is provided.\n",
      "     |      \n",
      "     |      - **hfile:** Each line of the header parameters file provides the\n",
      "     |        definition of a single HDU header card as represented by the card\n",
      "     |        image.\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      This is an abstract type that implements the shared functionality of\n",
      "     |      the ASCII and Binary Table HDU types, which should be used instead of\n",
      "     |      this.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _TableBaseHDU:\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the table HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  update(self)\n",
      "     |      Update header keywords to reflect recent changes of columns.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _TableBaseHDU:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      The :class:`ColDefs` objects describing the columns in this table.\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base.ExtensionHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Works similarly to the normal writeto(), but prepends a default\n",
      "     |      `PrimaryHDU` are required by extension HDUs (which cannot stand on\n",
      "     |      their own).\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |         ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from _TableLikeHDU:\n",
      "     |  \n",
      "     |  from_columns(columns, header=None, nrows=0, fill=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Given either a `ColDefs` object, a sequence of `Column` objects,\n",
      "     |      or another table HDU or table data (a `FITS_rec` or multi-field\n",
      "     |      `numpy.ndarray` or `numpy.recarray` object, return a new table HDU of\n",
      "     |      the class this method was called on using the column definition from\n",
      "     |      the input.\n",
      "     |      \n",
      "     |      See also `FITS_rec.from_columns`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns : sequence of `Column`, `ColDefs`, or other\n",
      "     |          The columns from which to create the table data, or an object with\n",
      "     |          a column-like structure from which a `ColDefs` can be instantiated.\n",
      "     |          This includes an existing `BinTableHDU` or `TableHDU`, or a\n",
      "     |          `numpy.recarray` to give some examples.\n",
      "     |      \n",
      "     |          If these columns have data arrays attached that data may be used in\n",
      "     |          initializing the new table.  Otherwise the input columns will be\n",
      "     |          used as a template for a new table with the requested number of\n",
      "     |          rows.\n",
      "     |      \n",
      "     |      header : `Header`\n",
      "     |          An optional `Header` object to instantiate the new HDU yet.  Header\n",
      "     |          keywords specifically related to defining the table structure (such\n",
      "     |          as the \"TXXXn\" keywords like TTYPEn) will be overridden by the\n",
      "     |          supplied column definitions, but all other informational and data\n",
      "     |          model-specific keywords are kept.\n",
      "     |      \n",
      "     |      nrows : int\n",
      "     |          Number of rows in the new table.  If the input columns have data\n",
      "     |          associated with them, the size of the largest input column is used.\n",
      "     |          Otherwise the default is 0.\n",
      "     |      \n",
      "     |      fill : bool\n",
      "     |          If `True`, will fill all cells with zeros or blanks.  If `False`,\n",
      "     |          copy the data from input, undefined cells will still be filled with\n",
      "     |          zeros/blanks.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      Any additional keyword arguments accepted by the HDU class's\n",
      "     |      ``__init__`` may also be passed in as keyword arguments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, blocking='standard', checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, blocking='standard', datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file object or file-like object\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __new__(cls, data=None, header=None, *args, **kwargs)\n",
      "     |      Iterates through the subclasses of _BaseHDU and uses that class's\n",
      "     |      match_header() method to determine which subclass to instantiate.\n",
      "     |      \n",
      "     |      It's important to be aware that the class hierarchy is traversed in a\n",
      "     |      depth-last order.  Each match_header() should identify an HDU type as\n",
      "     |      uniquely as possible.  Abstract types may choose to simply return False\n",
      "     |      or raise NotImplementedError to be skipped.\n",
      "     |      \n",
      "     |      If any unexpected exceptions are raised while evaluating\n",
      "     |      match_header(), the type is taken to be _CorruptedHDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class Card(astropy.io.fits.verify._Verify)\n",
      "     |  Shared methods for verification.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Card\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |  \n",
      "     |  __init__(self, keyword=None, value=None, comment=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  fromstring(image) from builtins.type\n",
      "     |      Construct a `Card` object from a (raw) string. It will pad the string\n",
      "     |      if it is not the length of a card image (80 columns).  If the card\n",
      "     |      image is longer than 80 columns, assume it contains ``CONTINUE``\n",
      "     |      card(s).\n",
      "     |  \n",
      "     |  normalize_keyword(keyword) from builtins.type\n",
      "     |      `classmethod` to convert a keyword value that may contain a\n",
      "     |      field-specifier to uppercase.  The effect is to raise the key to\n",
      "     |      uppercase and leave the field specifier in its original case.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : or str\n",
      "     |          A keyword value or a ``keyword.field-specifier`` value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  comment\n",
      "     |      Get the comment attribute from the card image if not already set.\n",
      "     |  \n",
      "     |  field_specifier\n",
      "     |      The field-specifier of record-valued keyword cards; always `None` on\n",
      "     |      normal cards.\n",
      "     |  \n",
      "     |  image\n",
      "     |      The card \"image\", that is, the 80 byte character string that represents\n",
      "     |      this card in an actual FITS header.\n",
      "     |  \n",
      "     |  is_blank\n",
      "     |      `True` if the card is completely blank--that is, it has no keyword,\n",
      "     |      value, or comment.  It appears in the header as 80 spaces.\n",
      "     |      \n",
      "     |      Returns `False` otherwise.\n",
      "     |  \n",
      "     |  keyword\n",
      "     |      Returns the keyword name parsed from the card image.\n",
      "     |  \n",
      "     |  rawkeyword\n",
      "     |      On record-valued keyword cards this is the name of the standard <= 8\n",
      "     |      character FITS keyword that this RVKC is stored in.  Otherwise it is\n",
      "     |      the card's normal keyword.\n",
      "     |  \n",
      "     |  rawvalue\n",
      "     |      On record-valued keyword cards this is the raw string value in\n",
      "     |      the ``<field-specifier>: <value>`` format stored in the card in order\n",
      "     |      to represent a RVKC.  Otherwise it is the card's normal value.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value associated with the keyword stored in this card.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  length = 80\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ColDefs(astropy.io.fits.util.NotifierMixin)\n",
      "     |  Column definitions class.\n",
      "     |  \n",
      "     |  It has attributes corresponding to the `Column` attributes\n",
      "     |  (e.g. `ColDefs` has the attribute ``names`` while `Column`\n",
      "     |  has ``name``). Each attribute in `ColDefs` is a list of\n",
      "     |  corresponding attribute values from all `Column` objects.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ColDefs\n",
      "     |      astropy.io.fits.util.NotifierMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other, option='left')\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __getattr__(self, name)\n",
      "     |      Automatically returns the values for the given keyword attribute for\n",
      "     |      all `Column`s in this list.\n",
      "     |      \n",
      "     |      Implements for example self.units, self.formats, etc.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |  \n",
      "     |  __init__(self, input, ascii=False)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      input : sequence of `Column`, `ColDefs`, other\n",
      "     |          An existing table HDU, an existing `ColDefs`, or any multi-field\n",
      "     |          Numpy array or `numpy.recarray`.\n",
      "     |      \n",
      "     |      ascii : bool\n",
      "     |          Use True to ensure that ASCII table columns are used.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sub__(self, other)\n",
      "     |  \n",
      "     |  add_col(self, column)\n",
      "     |      Append one `Column` to the column definition.\n",
      "     |  \n",
      "     |  change_attrib(self, col_name, attrib, new_value)\n",
      "     |      Change an attribute (in the ``KEYWORD_ATTRIBUTES`` list) of a `Column`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      col_name : str or int\n",
      "     |          The column name or index to change\n",
      "     |      \n",
      "     |      attrib : str\n",
      "     |          The attribute name\n",
      "     |      \n",
      "     |      new_value : object\n",
      "     |          The new value for the attribute\n",
      "     |  \n",
      "     |  change_name(self, col_name, new_name)\n",
      "     |      Change a `Column`'s name.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      col_name : str\n",
      "     |          The current name of the column\n",
      "     |      \n",
      "     |      new_name : str\n",
      "     |          The new name of the column\n",
      "     |  \n",
      "     |  change_unit(self, col_name, new_unit)\n",
      "     |      Change a `Column`'s unit.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      col_name : str or int\n",
      "     |          The column name or index\n",
      "     |      \n",
      "     |      new_unit : str\n",
      "     |          The new unit for the column\n",
      "     |  \n",
      "     |  del_col(self, col_name)\n",
      "     |      Delete (the definition of) one `Column`.\n",
      "     |      \n",
      "     |      col_name : str or int\n",
      "     |          The column's name or index\n",
      "     |  \n",
      "     |  info(self, attrib='all', output=None)\n",
      "     |      Get attribute(s) information of the column definition.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      attrib : str\n",
      "     |          Can be one or more of the attributes listed in\n",
      "     |          ``astropy.io.fits.column.KEYWORD_ATTRIBUTES``.  The default is\n",
      "     |          ``\"all\"`` which will print out all attributes.  It forgives plurals\n",
      "     |          and blanks.  If there are two or more attribute names, they must be\n",
      "     |          separated by comma(s).\n",
      "     |      \n",
      "     |      output : file, optional\n",
      "     |          File-like object to output to.  Outputs to stdout by default.\n",
      "     |          If `False`, returns the attributes as a `dict` instead.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This function doesn't return anything by default; it just prints to\n",
      "     |      stdout.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, input, ascii=False)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  formats\n",
      "     |  \n",
      "     |  names\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.util.NotifierMixin:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Exclude listeners when saving the listener's state, since they may be\n",
      "     |      ephemeral.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.util.NotifierMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Column(astropy.io.fits.util.NotifierMixin)\n",
      "     |  Class which contains the definition of one column, e.g.  ``ttype``,\n",
      "     |  ``tform``, etc. and the array containing values for the column.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Column\n",
      "     |      astropy.io.fits.util.NotifierMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Two columns are equal if their name and format are the same.  Other\n",
      "     |      attributes aren't taken into account at this time.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Like __eq__, the hash of a column should be based on the unique column\n",
      "     |      name and format, and be case-insensitive with respect to the column\n",
      "     |      name.\n",
      "     |  \n",
      "     |  __init__(self, name=None, format=None, unit=None, null=None, bscale=None, bzero=None, disp=None, start=None, dim=None, array=None, ascii=None)\n",
      "     |      Construct a `Column` by specifying attributes.  All attributes\n",
      "     |      except ``format`` can be optional; see :ref:`column_creation` and\n",
      "     |      :ref:`creating_ascii_table` for more information regarding\n",
      "     |      ``TFORM`` keyword.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : str, optional\n",
      "     |          column name, corresponding to ``TTYPE`` keyword\n",
      "     |      \n",
      "     |      format : str\n",
      "     |          column format, corresponding to ``TFORM`` keyword\n",
      "     |      \n",
      "     |      unit : str, optional\n",
      "     |          column unit, corresponding to ``TUNIT`` keyword\n",
      "     |      \n",
      "     |      null : str, optional\n",
      "     |          null value, corresponding to ``TNULL`` keyword\n",
      "     |      \n",
      "     |      bscale : int-like, optional\n",
      "     |          bscale value, corresponding to ``TSCAL`` keyword\n",
      "     |      \n",
      "     |      bzero : int-like, optional\n",
      "     |          bzero value, corresponding to ``TZERO`` keyword\n",
      "     |      \n",
      "     |      disp : str, optional\n",
      "     |          display format, corresponding to ``TDISP`` keyword\n",
      "     |      \n",
      "     |      start : int, optional\n",
      "     |          column starting position (ASCII table only), corresponding\n",
      "     |          to ``TBCOL`` keyword\n",
      "     |      \n",
      "     |      dim : str, optional\n",
      "     |          column dimension corresponding to ``TDIM`` keyword\n",
      "     |      \n",
      "     |      array : iterable, optional\n",
      "     |          a `list`, `numpy.ndarray` (or other iterable that can be used to\n",
      "     |          initialize an ndarray) providing initial data for this column.\n",
      "     |          The array will be automatically converted, if possible, to the data\n",
      "     |          format of the column.  In the case were non-trivial ``bscale``\n",
      "     |          and/or ``bzero`` arguments are given, the values in the array must\n",
      "     |          be the *physical* values--that is, the values of column as if the\n",
      "     |          scaling has already been applied (the array stored on the column\n",
      "     |          object will then be converted back to its storage values).\n",
      "     |      \n",
      "     |      ascii : bool, optional\n",
      "     |          set `True` if this describes a column for an ASCII table; this\n",
      "     |          may be required to disambiguate the column format\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Return a copy of this `Column`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  array\n",
      "     |      The Numpy `~numpy.ndarray` associated with this `Column`.\n",
      "     |      \n",
      "     |      If the column was instantiated with an array passed to the ``array``\n",
      "     |      argument, this will return that array.  However, if the column is\n",
      "     |      later added to a table, such as via `BinTableHDU.from_columns` as\n",
      "     |      is typically the case, this attribute will be updated to reference\n",
      "     |      the associated field in the table, which may no longer be the same\n",
      "     |      array.\n",
      "     |  \n",
      "     |  ascii\n",
      "     |      Whether this `Column` represents an column in an ASCII table.\n",
      "     |  \n",
      "     |  bscale\n",
      "     |      Descriptor for attributes of `Column` that are associated with keywords\n",
      "     |      in the FITS header and describe properties of the column as specified in\n",
      "     |      the FITS standard.\n",
      "     |      \n",
      "     |      Each `ColumnAttribute` may have a ``validator`` method defined on it.\n",
      "     |      This validates values set on this attribute to ensure that they meet the\n",
      "     |      FITS standard.  Invalid values will raise a warning and will not be used in\n",
      "     |      formatting the column.  The validator should take two arguments--the\n",
      "     |      `Column` it is being assigned to, and the new value for the attribute, and\n",
      "     |      it must raise an `AssertionError` if the value is invalid.\n",
      "     |      \n",
      "     |      The `ColumnAttribute` itself is a decorator that can be used to define the\n",
      "     |      ``validator`` for each column attribute.  For example::\n",
      "     |      \n",
      "     |          @ColumnAttribute('TTYPE')\n",
      "     |          def name(col, name):\n",
      "     |              if not isinstance(name, str):\n",
      "     |                  raise AssertionError\n",
      "     |      \n",
      "     |      The actual object returned by this decorator is the `ColumnAttribute`\n",
      "     |      instance though, not the ``name`` function.  As such ``name`` is not a\n",
      "     |      method of the class it is defined in.\n",
      "     |      \n",
      "     |      The setter for `ColumnAttribute` also updates the header of any table\n",
      "     |      HDU this column is attached to in order to reflect the change.  The\n",
      "     |      ``validator`` should ensure that the value is valid for inclusion in a FITS\n",
      "     |      header.\n",
      "     |  \n",
      "     |  bzero\n",
      "     |      Descriptor for attributes of `Column` that are associated with keywords\n",
      "     |      in the FITS header and describe properties of the column as specified in\n",
      "     |      the FITS standard.\n",
      "     |      \n",
      "     |      Each `ColumnAttribute` may have a ``validator`` method defined on it.\n",
      "     |      This validates values set on this attribute to ensure that they meet the\n",
      "     |      FITS standard.  Invalid values will raise a warning and will not be used in\n",
      "     |      formatting the column.  The validator should take two arguments--the\n",
      "     |      `Column` it is being assigned to, and the new value for the attribute, and\n",
      "     |      it must raise an `AssertionError` if the value is invalid.\n",
      "     |      \n",
      "     |      The `ColumnAttribute` itself is a decorator that can be used to define the\n",
      "     |      ``validator`` for each column attribute.  For example::\n",
      "     |      \n",
      "     |          @ColumnAttribute('TTYPE')\n",
      "     |          def name(col, name):\n",
      "     |              if not isinstance(name, str):\n",
      "     |                  raise AssertionError\n",
      "     |      \n",
      "     |      The actual object returned by this decorator is the `ColumnAttribute`\n",
      "     |      instance though, not the ``name`` function.  As such ``name`` is not a\n",
      "     |      method of the class it is defined in.\n",
      "     |      \n",
      "     |      The setter for `ColumnAttribute` also updates the header of any table\n",
      "     |      HDU this column is attached to in order to reflect the change.  The\n",
      "     |      ``validator`` should ensure that the value is valid for inclusion in a FITS\n",
      "     |      header.\n",
      "     |  \n",
      "     |  dim\n",
      "     |      Descriptor for attributes of `Column` that are associated with keywords\n",
      "     |      in the FITS header and describe properties of the column as specified in\n",
      "     |      the FITS standard.\n",
      "     |      \n",
      "     |      Each `ColumnAttribute` may have a ``validator`` method defined on it.\n",
      "     |      This validates values set on this attribute to ensure that they meet the\n",
      "     |      FITS standard.  Invalid values will raise a warning and will not be used in\n",
      "     |      formatting the column.  The validator should take two arguments--the\n",
      "     |      `Column` it is being assigned to, and the new value for the attribute, and\n",
      "     |      it must raise an `AssertionError` if the value is invalid.\n",
      "     |      \n",
      "     |      The `ColumnAttribute` itself is a decorator that can be used to define the\n",
      "     |      ``validator`` for each column attribute.  For example::\n",
      "     |      \n",
      "     |          @ColumnAttribute('TTYPE')\n",
      "     |          def name(col, name):\n",
      "     |              if not isinstance(name, str):\n",
      "     |                  raise AssertionError\n",
      "     |      \n",
      "     |      The actual object returned by this decorator is the `ColumnAttribute`\n",
      "     |      instance though, not the ``name`` function.  As such ``name`` is not a\n",
      "     |      method of the class it is defined in.\n",
      "     |      \n",
      "     |      The setter for `ColumnAttribute` also updates the header of any table\n",
      "     |      HDU this column is attached to in order to reflect the change.  The\n",
      "     |      ``validator`` should ensure that the value is valid for inclusion in a FITS\n",
      "     |      header.\n",
      "     |  \n",
      "     |  disp\n",
      "     |      Descriptor for attributes of `Column` that are associated with keywords\n",
      "     |      in the FITS header and describe properties of the column as specified in\n",
      "     |      the FITS standard.\n",
      "     |      \n",
      "     |      Each `ColumnAttribute` may have a ``validator`` method defined on it.\n",
      "     |      This validates values set on this attribute to ensure that they meet the\n",
      "     |      FITS standard.  Invalid values will raise a warning and will not be used in\n",
      "     |      formatting the column.  The validator should take two arguments--the\n",
      "     |      `Column` it is being assigned to, and the new value for the attribute, and\n",
      "     |      it must raise an `AssertionError` if the value is invalid.\n",
      "     |      \n",
      "     |      The `ColumnAttribute` itself is a decorator that can be used to define the\n",
      "     |      ``validator`` for each column attribute.  For example::\n",
      "     |      \n",
      "     |          @ColumnAttribute('TTYPE')\n",
      "     |          def name(col, name):\n",
      "     |              if not isinstance(name, str):\n",
      "     |                  raise AssertionError\n",
      "     |      \n",
      "     |      The actual object returned by this decorator is the `ColumnAttribute`\n",
      "     |      instance though, not the ``name`` function.  As such ``name`` is not a\n",
      "     |      method of the class it is defined in.\n",
      "     |      \n",
      "     |      The setter for `ColumnAttribute` also updates the header of any table\n",
      "     |      HDU this column is attached to in order to reflect the change.  The\n",
      "     |      ``validator`` should ensure that the value is valid for inclusion in a FITS\n",
      "     |      header.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  format\n",
      "     |      Descriptor for attributes of `Column` that are associated with keywords\n",
      "     |      in the FITS header and describe properties of the column as specified in\n",
      "     |      the FITS standard.\n",
      "     |      \n",
      "     |      Each `ColumnAttribute` may have a ``validator`` method defined on it.\n",
      "     |      This validates values set on this attribute to ensure that they meet the\n",
      "     |      FITS standard.  Invalid values will raise a warning and will not be used in\n",
      "     |      formatting the column.  The validator should take two arguments--the\n",
      "     |      `Column` it is being assigned to, and the new value for the attribute, and\n",
      "     |      it must raise an `AssertionError` if the value is invalid.\n",
      "     |      \n",
      "     |      The `ColumnAttribute` itself is a decorator that can be used to define the\n",
      "     |      ``validator`` for each column attribute.  For example::\n",
      "     |      \n",
      "     |          @ColumnAttribute('TTYPE')\n",
      "     |          def name(col, name):\n",
      "     |              if not isinstance(name, str):\n",
      "     |                  raise AssertionError\n",
      "     |      \n",
      "     |      The actual object returned by this decorator is the `ColumnAttribute`\n",
      "     |      instance though, not the ``name`` function.  As such ``name`` is not a\n",
      "     |      method of the class it is defined in.\n",
      "     |      \n",
      "     |      The setter for `ColumnAttribute` also updates the header of any table\n",
      "     |      HDU this column is attached to in order to reflect the change.  The\n",
      "     |      ``validator`` should ensure that the value is valid for inclusion in a FITS\n",
      "     |      header.\n",
      "     |  \n",
      "     |  name\n",
      "     |      Descriptor for attributes of `Column` that are associated with keywords\n",
      "     |      in the FITS header and describe properties of the column as specified in\n",
      "     |      the FITS standard.\n",
      "     |      \n",
      "     |      Each `ColumnAttribute` may have a ``validator`` method defined on it.\n",
      "     |      This validates values set on this attribute to ensure that they meet the\n",
      "     |      FITS standard.  Invalid values will raise a warning and will not be used in\n",
      "     |      formatting the column.  The validator should take two arguments--the\n",
      "     |      `Column` it is being assigned to, and the new value for the attribute, and\n",
      "     |      it must raise an `AssertionError` if the value is invalid.\n",
      "     |      \n",
      "     |      The `ColumnAttribute` itself is a decorator that can be used to define the\n",
      "     |      ``validator`` for each column attribute.  For example::\n",
      "     |      \n",
      "     |          @ColumnAttribute('TTYPE')\n",
      "     |          def name(col, name):\n",
      "     |              if not isinstance(name, str):\n",
      "     |                  raise AssertionError\n",
      "     |      \n",
      "     |      The actual object returned by this decorator is the `ColumnAttribute`\n",
      "     |      instance though, not the ``name`` function.  As such ``name`` is not a\n",
      "     |      method of the class it is defined in.\n",
      "     |      \n",
      "     |      The setter for `ColumnAttribute` also updates the header of any table\n",
      "     |      HDU this column is attached to in order to reflect the change.  The\n",
      "     |      ``validator`` should ensure that the value is valid for inclusion in a FITS\n",
      "     |      header.\n",
      "     |  \n",
      "     |  null\n",
      "     |      Descriptor for attributes of `Column` that are associated with keywords\n",
      "     |      in the FITS header and describe properties of the column as specified in\n",
      "     |      the FITS standard.\n",
      "     |      \n",
      "     |      Each `ColumnAttribute` may have a ``validator`` method defined on it.\n",
      "     |      This validates values set on this attribute to ensure that they meet the\n",
      "     |      FITS standard.  Invalid values will raise a warning and will not be used in\n",
      "     |      formatting the column.  The validator should take two arguments--the\n",
      "     |      `Column` it is being assigned to, and the new value for the attribute, and\n",
      "     |      it must raise an `AssertionError` if the value is invalid.\n",
      "     |      \n",
      "     |      The `ColumnAttribute` itself is a decorator that can be used to define the\n",
      "     |      ``validator`` for each column attribute.  For example::\n",
      "     |      \n",
      "     |          @ColumnAttribute('TTYPE')\n",
      "     |          def name(col, name):\n",
      "     |              if not isinstance(name, str):\n",
      "     |                  raise AssertionError\n",
      "     |      \n",
      "     |      The actual object returned by this decorator is the `ColumnAttribute`\n",
      "     |      instance though, not the ``name`` function.  As such ``name`` is not a\n",
      "     |      method of the class it is defined in.\n",
      "     |      \n",
      "     |      The setter for `ColumnAttribute` also updates the header of any table\n",
      "     |      HDU this column is attached to in order to reflect the change.  The\n",
      "     |      ``validator`` should ensure that the value is valid for inclusion in a FITS\n",
      "     |      header.\n",
      "     |  \n",
      "     |  start\n",
      "     |      Descriptor for attributes of `Column` that are associated with keywords\n",
      "     |      in the FITS header and describe properties of the column as specified in\n",
      "     |      the FITS standard.\n",
      "     |      \n",
      "     |      Each `ColumnAttribute` may have a ``validator`` method defined on it.\n",
      "     |      This validates values set on this attribute to ensure that they meet the\n",
      "     |      FITS standard.  Invalid values will raise a warning and will not be used in\n",
      "     |      formatting the column.  The validator should take two arguments--the\n",
      "     |      `Column` it is being assigned to, and the new value for the attribute, and\n",
      "     |      it must raise an `AssertionError` if the value is invalid.\n",
      "     |      \n",
      "     |      The `ColumnAttribute` itself is a decorator that can be used to define the\n",
      "     |      ``validator`` for each column attribute.  For example::\n",
      "     |      \n",
      "     |          @ColumnAttribute('TTYPE')\n",
      "     |          def name(col, name):\n",
      "     |              if not isinstance(name, str):\n",
      "     |                  raise AssertionError\n",
      "     |      \n",
      "     |      The actual object returned by this decorator is the `ColumnAttribute`\n",
      "     |      instance though, not the ``name`` function.  As such ``name`` is not a\n",
      "     |      method of the class it is defined in.\n",
      "     |      \n",
      "     |      The setter for `ColumnAttribute` also updates the header of any table\n",
      "     |      HDU this column is attached to in order to reflect the change.  The\n",
      "     |      ``validator`` should ensure that the value is valid for inclusion in a FITS\n",
      "     |      header.\n",
      "     |  \n",
      "     |  unit\n",
      "     |      Descriptor for attributes of `Column` that are associated with keywords\n",
      "     |      in the FITS header and describe properties of the column as specified in\n",
      "     |      the FITS standard.\n",
      "     |      \n",
      "     |      Each `ColumnAttribute` may have a ``validator`` method defined on it.\n",
      "     |      This validates values set on this attribute to ensure that they meet the\n",
      "     |      FITS standard.  Invalid values will raise a warning and will not be used in\n",
      "     |      formatting the column.  The validator should take two arguments--the\n",
      "     |      `Column` it is being assigned to, and the new value for the attribute, and\n",
      "     |      it must raise an `AssertionError` if the value is invalid.\n",
      "     |      \n",
      "     |      The `ColumnAttribute` itself is a decorator that can be used to define the\n",
      "     |      ``validator`` for each column attribute.  For example::\n",
      "     |      \n",
      "     |          @ColumnAttribute('TTYPE')\n",
      "     |          def name(col, name):\n",
      "     |              if not isinstance(name, str):\n",
      "     |                  raise AssertionError\n",
      "     |      \n",
      "     |      The actual object returned by this decorator is the `ColumnAttribute`\n",
      "     |      instance though, not the ``name`` function.  As such ``name`` is not a\n",
      "     |      method of the class it is defined in.\n",
      "     |      \n",
      "     |      The setter for `ColumnAttribute` also updates the header of any table\n",
      "     |      HDU this column is attached to in order to reflect the change.  The\n",
      "     |      ``validator`` should ensure that the value is valid for inclusion in a FITS\n",
      "     |      header.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.util.NotifierMixin:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Exclude listeners when saving the listener's state, since they may be\n",
      "     |      ephemeral.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.util.NotifierMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class CompImageHDU(astropy.io.fits.hdu.table.BinTableHDU)\n",
      "     |  Compressed Image HDU class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CompImageHDU\n",
      "     |      astropy.io.fits.hdu.table.BinTableHDU\n",
      "     |      astropy.io.fits.hdu.table._TableBaseHDU\n",
      "     |      astropy.io.fits.hdu.base.ExtensionHDU\n",
      "     |      astropy.io.fits.hdu.table._TableLikeHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None, name=None, compression_type='RICE_1', tile_size=None, hcomp_scale=0, hcomp_smooth=0, quantize_level=16.0, quantize_method=-1, dither_seed=0, do_not_scale_image_data=False, uint=False, scale_back=False, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array, optional\n",
      "     |          Uncompressed image data\n",
      "     |      \n",
      "     |      header : Header instance, optional\n",
      "     |          Header to be associated with the image; when reading the HDU from a\n",
      "     |          file (data=DELAYED), the header read from the file\n",
      "     |      \n",
      "     |      name : str, optional\n",
      "     |          The ``EXTNAME`` value; if this value is `None`, then the name from\n",
      "     |          the input image header will be used; if there is no name in the\n",
      "     |          input image header then the default name ``COMPRESSED_IMAGE`` is\n",
      "     |          used.\n",
      "     |      \n",
      "     |      compression_type : str, optional\n",
      "     |          Compression algorithm: one of\n",
      "     |          ``'RICE_1'``, ``'RICE_ONE'``, ``'PLIO_1'``, ``'GZIP_1'``,\n",
      "     |          ``'GZIP_2'``, ``'HCOMPRESS_1'``\n",
      "     |      \n",
      "     |      tile_size : int, optional\n",
      "     |          Compression tile sizes.  Default treats each row of image as a\n",
      "     |          tile.\n",
      "     |      \n",
      "     |      hcomp_scale : float, optional\n",
      "     |          HCOMPRESS scale parameter\n",
      "     |      \n",
      "     |      hcomp_smooth : float, optional\n",
      "     |          HCOMPRESS smooth parameter\n",
      "     |      \n",
      "     |      quantize_level : float, optional\n",
      "     |          Floating point quantization level; see note below\n",
      "     |      \n",
      "     |      quantize_method : int, optional\n",
      "     |          Floating point quantization dithering method; can be either\n",
      "     |          ``NO_DITHER`` (-1), ``SUBTRACTIVE_DITHER_1`` (1; default), or\n",
      "     |          ``SUBTRACTIVE_DITHER_2`` (2); see note below\n",
      "     |      \n",
      "     |      dither_seed : int, optional\n",
      "     |          Random seed to use for dithering; can be either an integer in the\n",
      "     |          range 1 to 1000 (inclusive), ``DITHER_SEED_CLOCK`` (0; default), or\n",
      "     |          ``DITHER_SEED_CHECKSUM`` (-1); see note below\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The astropy.io.fits package supports 2 methods of image compression:\n",
      "     |      \n",
      "     |          1) The entire FITS file may be externally compressed with the gzip\n",
      "     |             or pkzip utility programs, producing a ``*.gz`` or ``*.zip``\n",
      "     |             file, respectively.  When reading compressed files of this type,\n",
      "     |             Astropy first uncompresses the entire file into a temporary file\n",
      "     |             before performing the requested read operations.  The\n",
      "     |             astropy.io.fits package does not support writing to these types\n",
      "     |             of compressed files.  This type of compression is supported in\n",
      "     |             the ``_File`` class, not in the `CompImageHDU` class.  The file\n",
      "     |             compression type is recognized by the ``.gz`` or ``.zip`` file\n",
      "     |             name extension.\n",
      "     |      \n",
      "     |          2) The `CompImageHDU` class supports the FITS tiled image\n",
      "     |             compression convention in which the image is subdivided into a\n",
      "     |             grid of rectangular tiles, and each tile of pixels is\n",
      "     |             individually compressed.  The details of this FITS compression\n",
      "     |             convention are described at the `FITS Support Office web site\n",
      "     |             <http://fits.gsfc.nasa.gov/registry/tilecompression.html>`_.\n",
      "     |             Basically, the compressed image tiles are stored in rows of a\n",
      "     |             variable length array column in a FITS binary table.  The\n",
      "     |             astropy.io.fits recognizes that this binary table extension\n",
      "     |             contains an image and treats it as if it were an image\n",
      "     |             extension.  Under this tile-compression format, FITS header\n",
      "     |             keywords remain uncompressed.  At this time, Astropy does not\n",
      "     |             support the ability to extract and uncompress sections of the\n",
      "     |             image without having to uncompress the entire image.\n",
      "     |      \n",
      "     |      The astropy.io.fits package supports 3 general-purpose compression\n",
      "     |      algorithms plus one other special-purpose compression technique that is\n",
      "     |      designed for data masks with positive integer pixel values.  The 3\n",
      "     |      general purpose algorithms are GZIP, Rice, and HCOMPRESS, and the\n",
      "     |      special-purpose technique is the IRAF pixel list compression technique\n",
      "     |      (PLIO).  The ``compression_type`` parameter defines the compression\n",
      "     |      algorithm to be used.\n",
      "     |      \n",
      "     |      The FITS image can be subdivided into any desired rectangular grid of\n",
      "     |      compression tiles.  With the GZIP, Rice, and PLIO algorithms, the\n",
      "     |      default is to take each row of the image as a tile.  The HCOMPRESS\n",
      "     |      algorithm is inherently 2-dimensional in nature, so the default in this\n",
      "     |      case is to take 16 rows of the image per tile.  In most cases, it makes\n",
      "     |      little difference what tiling pattern is used, so the default tiles are\n",
      "     |      usually adequate.  In the case of very small images, it could be more\n",
      "     |      efficient to compress the whole image as a single tile.  Note that the\n",
      "     |      image dimensions are not required to be an integer multiple of the tile\n",
      "     |      dimensions; if not, then the tiles at the edges of the image will be\n",
      "     |      smaller than the other tiles.  The ``tile_size`` parameter may be\n",
      "     |      provided as a list of tile sizes, one for each dimension in the image.\n",
      "     |      For example a ``tile_size`` value of ``[100,100]`` would divide a 300 X\n",
      "     |      300 image into 9 100 X 100 tiles.\n",
      "     |      \n",
      "     |      The 4 supported image compression algorithms are all 'lossless' when\n",
      "     |      applied to integer FITS images; the pixel values are preserved exactly\n",
      "     |      with no loss of information during the compression and uncompression\n",
      "     |      process.  In addition, the HCOMPRESS algorithm supports a 'lossy'\n",
      "     |      compression mode that will produce larger amount of image compression.\n",
      "     |      This is achieved by specifying a non-zero value for the ``hcomp_scale``\n",
      "     |      parameter.  Since the amount of compression that is achieved depends\n",
      "     |      directly on the RMS noise in the image, it is usually more convenient\n",
      "     |      to specify the ``hcomp_scale`` factor relative to the RMS noise.\n",
      "     |      Setting ``hcomp_scale = 2.5`` means use a scale factor that is 2.5\n",
      "     |      times the calculated RMS noise in the image tile.  In some cases it may\n",
      "     |      be desirable to specify the exact scaling to be used, instead of\n",
      "     |      specifying it relative to the calculated noise value.  This may be done\n",
      "     |      by specifying the negative of the desired scale value (typically in the\n",
      "     |      range -2 to -100).\n",
      "     |      \n",
      "     |      Very high compression factors (of 100 or more) can be achieved by using\n",
      "     |      large ``hcomp_scale`` values, however, this can produce undesirable\n",
      "     |      'blocky' artifacts in the compressed image.  A variation of the\n",
      "     |      HCOMPRESS algorithm (called HSCOMPRESS) can be used in this case to\n",
      "     |      apply a small amount of smoothing of the image when it is uncompressed\n",
      "     |      to help cover up these artifacts.  This smoothing is purely cosmetic\n",
      "     |      and does not cause any significant change to the image pixel values.\n",
      "     |      Setting the ``hcomp_smooth`` parameter to 1 will engage the smoothing\n",
      "     |      algorithm.\n",
      "     |      \n",
      "     |      Floating point FITS images (which have ``BITPIX`` = -32 or -64) usually\n",
      "     |      contain too much 'noise' in the least significant bits of the mantissa\n",
      "     |      of the pixel values to be effectively compressed with any lossless\n",
      "     |      algorithm.  Consequently, floating point images are first quantized\n",
      "     |      into scaled integer pixel values (and thus throwing away much of the\n",
      "     |      noise) before being compressed with the specified algorithm (either\n",
      "     |      GZIP, RICE, or HCOMPRESS).  This technique produces much higher\n",
      "     |      compression factors than simply using the GZIP utility to externally\n",
      "     |      compress the whole FITS file, but it also means that the original\n",
      "     |      floating point value pixel values are not exactly preserved.  When done\n",
      "     |      properly, this integer scaling technique will only discard the\n",
      "     |      insignificant noise while still preserving all the real information in\n",
      "     |      the image.  The amount of precision that is retained in the pixel\n",
      "     |      values is controlled by the ``quantize_level`` parameter.  Larger\n",
      "     |      values will result in compressed images whose pixels more closely match\n",
      "     |      the floating point pixel values, but at the same time the amount of\n",
      "     |      compression that is achieved will be reduced.  Users should experiment\n",
      "     |      with different values for this parameter to determine the optimal value\n",
      "     |      that preserves all the useful information in the image, without\n",
      "     |      needlessly preserving all the 'noise' which will hurt the compression\n",
      "     |      efficiency.\n",
      "     |      \n",
      "     |      The default value for the ``quantize_level`` scale factor is 16, which\n",
      "     |      means that scaled integer pixel values will be quantized such that the\n",
      "     |      difference between adjacent integer values will be 1/16th of the noise\n",
      "     |      level in the image background.  An optimized algorithm is used to\n",
      "     |      accurately estimate the noise in the image.  As an example, if the RMS\n",
      "     |      noise in the background pixels of an image = 32.0, then the spacing\n",
      "     |      between adjacent scaled integer pixel values will equal 2.0 by default.\n",
      "     |      Note that the RMS noise is independently calculated for each tile of\n",
      "     |      the image, so the resulting integer scaling factor may fluctuate\n",
      "     |      slightly for each tile.  In some cases, it may be desirable to specify\n",
      "     |      the exact quantization level to be used, instead of specifying it\n",
      "     |      relative to the calculated noise value.  This may be done by specifying\n",
      "     |      the negative of desired quantization level for the value of\n",
      "     |      ``quantize_level``.  In the previous example, one could specify\n",
      "     |      ``quantize_level = -2.0`` so that the quantized integer levels differ\n",
      "     |      by 2.0.  Larger negative values for ``quantize_level`` means that the\n",
      "     |      levels are more coarsely-spaced, and will produce higher compression\n",
      "     |      factors.\n",
      "     |      \n",
      "     |      The quantization algorithm can also apply one of two random dithering\n",
      "     |      methods in order to reduce bias in the measured intensity of background\n",
      "     |      regions.  The default method, specified with the constant\n",
      "     |      ``SUBTRACTIVE_DITHER_1`` adds dithering to the zero-point of the\n",
      "     |      quantization array itself rather than adding noise to the actual image.\n",
      "     |      The random noise is added on a pixel-by-pixel basis, so in order\n",
      "     |      restore each pixel from its integer value to its floating point value\n",
      "     |      it is necessary to replay the same sequence of random numbers for each\n",
      "     |      pixel (see below).  The other method, ``SUBTRACTIVE_DITHER_2``, is\n",
      "     |      exactly like the first except that before dithering any pixel with a\n",
      "     |      floating point value of ``0.0`` is replaced with the special integer\n",
      "     |      value ``-2147483647``.  When the image is uncompressed, pixels with\n",
      "     |      this value are restored back to ``0.0`` exactly.  Finally, a value of\n",
      "     |      ``NO_DITHER`` disables dithering entirely.\n",
      "     |      \n",
      "     |      As mentioned above, when using the subtractive dithering algorithm it\n",
      "     |      is necessary to be able to generate a (pseudo-)random sequence of noise\n",
      "     |      for each pixel, and replay that same sequence upon decompressing.  To\n",
      "     |      facilitate this, a random seed between 1 and 10000 (inclusive) is used\n",
      "     |      to seed a random number generator, and that seed is stored in the\n",
      "     |      ``ZDITHER0`` keyword in the header of the compressed HDU.  In order to\n",
      "     |      use that seed to generate the same sequence of random numbers the same\n",
      "     |      random number generator must be used at compression and decompression\n",
      "     |      time; for that reason the tiled image convention provides an\n",
      "     |      implementation of a very simple pseudo-random number generator.  The\n",
      "     |      seed itself can be provided in one of three ways, controllable by the\n",
      "     |      ``dither_seed`` argument:  It may be specified manually, or it may be\n",
      "     |      generated arbitrarily based on the system's clock\n",
      "     |      (``DITHER_SEED_CLOCK``) or based on a checksum of the pixels in the\n",
      "     |      image's first tile (``DITHER_SEED_CHECKSUM``).  The clock-based method\n",
      "     |      is the default, and is sufficient to ensure that the value is\n",
      "     |      reasonably \"arbitrary\" and that the same seed is unlikely to be\n",
      "     |      generated sequentially.  The checksum method, on the other hand,\n",
      "     |      ensures that the same seed is used every time for a specific image.\n",
      "     |      This is particularly useful for software testing as it ensures that the\n",
      "     |      same image will always use the same seed.\n",
      "     |  \n",
      "     |  scale(self, type=None, option='old', bscale=1, bzero=0)\n",
      "     |      Scale image data by using ``BSCALE`` and ``BZERO``.\n",
      "     |      \n",
      "     |      Calling this method will scale ``self.data`` and update the keywords of\n",
      "     |      ``BSCALE`` and ``BZERO`` in ``self._header`` and ``self._image_header``.\n",
      "     |      This method should only be used right before writing to the output\n",
      "     |      file, as the data will be scaled and is therefore not very usable after\n",
      "     |      the call.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      type : str, optional\n",
      "     |          destination data type, use a string representing a numpy dtype\n",
      "     |          name, (e.g. ``'uint8'``, ``'int16'``, ``'float32'`` etc.).  If is\n",
      "     |          `None`, use the current data type.\n",
      "     |      \n",
      "     |      option : str, optional\n",
      "     |          how to scale the data: if ``\"old\"``, use the original ``BSCALE``\n",
      "     |          and ``BZERO`` values when the data was read/created. If\n",
      "     |          ``\"minmax\"``, use the minimum and maximum of the data to scale.\n",
      "     |          The option will be overwritten by any user-specified bscale/bzero\n",
      "     |          values.\n",
      "     |      \n",
      "     |      bscale, bzero : int, optional\n",
      "     |          user specified ``BSCALE`` and ``BZERO`` values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      This is an abstract type that implements the shared functionality of\n",
      "     |      the ASCII and Binary Table HDU types, which should be used instead of\n",
      "     |      this.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  compressed_data\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Shape of the image array--should be equivalent to ``self.data.shape``.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DEPRECATED_KWARGS = {'compressionType': 'compression_type', 'hcompScal...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.table.BinTableHDU:\n",
      "     |  \n",
      "     |  dump(self, datafile=None, cdfile=None, hfile=None, overwrite=False)\n",
      "     |      Dump the table HDU to a file in ASCII format.  The table may be dumped\n",
      "     |      in three separate files, one containing column definitions, one\n",
      "     |      containing header parameters, and one for table data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      datafile : file path, file object or file-like object, optional\n",
      "     |          Output data file.  The default is the root name of the\n",
      "     |          fits file associated with this HDU appended with the\n",
      "     |          extension ``.txt``.\n",
      "     |      \n",
      "     |      cdfile : file path, file object or file-like object, optional\n",
      "     |          Output column definitions file.  The default is `None`, no\n",
      "     |          column definitions output is produced.\n",
      "     |      \n",
      "     |      hfile : file path, file object or file-like object, optional\n",
      "     |          Output header parameters file.  The default is `None`,\n",
      "     |          no header parameters output is produced.\n",
      "     |      \n",
      "     |      overwrite : bool, optional\n",
      "     |          If ``True``, overwrite the output file if it exists. Raises an\n",
      "     |          ``OSError`` (``IOError`` for Python 2) if ``False`` and the\n",
      "     |          output file exists. Default is ``False``.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.3\n",
      "     |             ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The primary use for the `dump` method is to allow viewing and editing\n",
      "     |      the table data and parameters in a standard text editor.\n",
      "     |      The `load` method can be used to create a new table from the three\n",
      "     |      plain text (ASCII) files.\n",
      "     |      \n",
      "     |      \n",
      "     |      - **datafile:** Each line of the data file represents one row of table\n",
      "     |        data.  The data is output one column at a time in column order.  If\n",
      "     |        a column contains an array, each element of the column array in the\n",
      "     |        current row is output before moving on to the next column.  Each row\n",
      "     |        ends with a new line.\n",
      "     |      \n",
      "     |        Integer data is output right-justified in a 21-character field\n",
      "     |        followed by a blank.  Floating point data is output right justified\n",
      "     |        using 'g' format in a 21-character field with 15 digits of\n",
      "     |        precision, followed by a blank.  String data that does not contain\n",
      "     |        whitespace is output left-justified in a field whose width matches\n",
      "     |        the width specified in the ``TFORM`` header parameter for the\n",
      "     |        column, followed by a blank.  When the string data contains\n",
      "     |        whitespace characters, the string is enclosed in quotation marks\n",
      "     |        (``\"\"``).  For the last data element in a row, the trailing blank in\n",
      "     |        the field is replaced by a new line character.\n",
      "     |      \n",
      "     |        For column data containing variable length arrays ('P' format), the\n",
      "     |        array data is preceded by the string ``'VLA_Length= '`` and the\n",
      "     |        integer length of the array for that row, left-justified in a\n",
      "     |        21-character field, followed by a blank.\n",
      "     |      \n",
      "     |        .. note::\n",
      "     |      \n",
      "     |            This format does *not* support variable length arrays using the\n",
      "     |            ('Q' format) due to difficult to overcome ambiguities. What this\n",
      "     |            means is that this file format cannot support VLA columns in\n",
      "     |            tables stored in files that are over 2 GB in size.\n",
      "     |      \n",
      "     |        For column data representing a bit field ('X' format), each bit\n",
      "     |        value in the field is output right-justified in a 21-character field\n",
      "     |        as 1 (for true) or 0 (for false).\n",
      "     |      \n",
      "     |      - **cdfile:** Each line of the column definitions file provides the\n",
      "     |        definitions for one column in the table.  The line is broken up into\n",
      "     |        8, sixteen-character fields.  The first field provides the column\n",
      "     |        name (``TTYPEn``).  The second field provides the column format\n",
      "     |        (``TFORMn``).  The third field provides the display format\n",
      "     |        (``TDISPn``).  The fourth field provides the physical units\n",
      "     |        (``TUNITn``).  The fifth field provides the dimensions for a\n",
      "     |        multidimensional array (``TDIMn``).  The sixth field provides the\n",
      "     |        value that signifies an undefined value (``TNULLn``).  The seventh\n",
      "     |        field provides the scale factor (``TSCALn``).  The eighth field\n",
      "     |        provides the offset value (``TZEROn``).  A field value of ``\"\"`` is\n",
      "     |        used to represent the case where no value is provided.\n",
      "     |      \n",
      "     |      - **hfile:** Each line of the header parameters file provides the\n",
      "     |        definition of a single HDU header card as represented by the card\n",
      "     |        image.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.table.BinTableHDU:\n",
      "     |  \n",
      "     |  load(datafile, cdfile=None, hfile=None, replace=False, header=None) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Create a table from the input ASCII files.  The input is from up to\n",
      "     |      three separate files, one containing column definitions, one containing\n",
      "     |      header parameters, and one containing column data.\n",
      "     |      \n",
      "     |      The column definition and header parameters files are not required.\n",
      "     |      When absent the column definitions and/or header parameters are taken\n",
      "     |      from the header object given in the header argument; otherwise sensible\n",
      "     |      defaults are inferred (though this mode is not recommended).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      datafile : file path, file object or file-like object\n",
      "     |          Input data file containing the table data in ASCII format.\n",
      "     |      \n",
      "     |      cdfile : file path, file object, file-like object, optional\n",
      "     |          Input column definition file containing the names,\n",
      "     |          formats, display formats, physical units, multidimensional\n",
      "     |          array dimensions, undefined values, scale factors, and\n",
      "     |          offsets associated with the columns in the table.  If\n",
      "     |          `None`, the column definitions are taken from the current\n",
      "     |          values in this object.\n",
      "     |      \n",
      "     |      hfile : file path, file object, file-like object, optional\n",
      "     |          Input parameter definition file containing the header\n",
      "     |          parameter definitions to be associated with the table.  If\n",
      "     |          `None`, the header parameter definitions are taken from\n",
      "     |          the current values in this objects header.\n",
      "     |      \n",
      "     |      replace : bool\n",
      "     |          When `True`, indicates that the entire header should be\n",
      "     |          replaced with the contents of the ASCII file instead of\n",
      "     |          just updating the current header.\n",
      "     |      \n",
      "     |      header : Header object\n",
      "     |          When the cdfile and hfile are missing, use this Header object in\n",
      "     |          the creation of the new table and HDU.  Otherwise this Header\n",
      "     |          supercedes the keywords from hfile, which is only used to update\n",
      "     |          values not present in this Header, unless ``replace=True`` in which\n",
      "     |          this Header's values are completely replaced with the values from\n",
      "     |          hfile.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The primary use for the `load` method is to allow the input of ASCII\n",
      "     |      data that was edited in a standard text editor of the table data and\n",
      "     |      parameters.  The `dump` method can be used to create the initial ASCII\n",
      "     |      files.\n",
      "     |      \n",
      "     |      \n",
      "     |      - **datafile:** Each line of the data file represents one row of table\n",
      "     |        data.  The data is output one column at a time in column order.  If\n",
      "     |        a column contains an array, each element of the column array in the\n",
      "     |        current row is output before moving on to the next column.  Each row\n",
      "     |        ends with a new line.\n",
      "     |      \n",
      "     |        Integer data is output right-justified in a 21-character field\n",
      "     |        followed by a blank.  Floating point data is output right justified\n",
      "     |        using 'g' format in a 21-character field with 15 digits of\n",
      "     |        precision, followed by a blank.  String data that does not contain\n",
      "     |        whitespace is output left-justified in a field whose width matches\n",
      "     |        the width specified in the ``TFORM`` header parameter for the\n",
      "     |        column, followed by a blank.  When the string data contains\n",
      "     |        whitespace characters, the string is enclosed in quotation marks\n",
      "     |        (``\"\"``).  For the last data element in a row, the trailing blank in\n",
      "     |        the field is replaced by a new line character.\n",
      "     |      \n",
      "     |        For column data containing variable length arrays ('P' format), the\n",
      "     |        array data is preceded by the string ``'VLA_Length= '`` and the\n",
      "     |        integer length of the array for that row, left-justified in a\n",
      "     |        21-character field, followed by a blank.\n",
      "     |      \n",
      "     |        .. note::\n",
      "     |      \n",
      "     |            This format does *not* support variable length arrays using the\n",
      "     |            ('Q' format) due to difficult to overcome ambiguities. What this\n",
      "     |            means is that this file format cannot support VLA columns in\n",
      "     |            tables stored in files that are over 2 GB in size.\n",
      "     |      \n",
      "     |        For column data representing a bit field ('X' format), each bit\n",
      "     |        value in the field is output right-justified in a 21-character field\n",
      "     |        as 1 (for true) or 0 (for false).\n",
      "     |      \n",
      "     |      - **cdfile:** Each line of the column definitions file provides the\n",
      "     |        definitions for one column in the table.  The line is broken up into\n",
      "     |        8, sixteen-character fields.  The first field provides the column\n",
      "     |        name (``TTYPEn``).  The second field provides the column format\n",
      "     |        (``TFORMn``).  The third field provides the display format\n",
      "     |        (``TDISPn``).  The fourth field provides the physical units\n",
      "     |        (``TUNITn``).  The fifth field provides the dimensions for a\n",
      "     |        multidimensional array (``TDIMn``).  The sixth field provides the\n",
      "     |        value that signifies an undefined value (``TNULLn``).  The seventh\n",
      "     |        field provides the scale factor (``TSCALn``).  The eighth field\n",
      "     |        provides the offset value (``TZEROn``).  A field value of ``\"\"`` is\n",
      "     |        used to represent the case where no value is provided.\n",
      "     |      \n",
      "     |      - **hfile:** Each line of the header parameters file provides the\n",
      "     |        definition of a single HDU header card as represented by the card\n",
      "     |        image.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.table._TableBaseHDU:\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the table HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  update(self)\n",
      "     |      Update header keywords to reflect recent changes of columns.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.table._TableBaseHDU:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      The :class:`ColDefs` objects describing the columns in this table.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base.ExtensionHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Works similarly to the normal writeto(), but prepends a default\n",
      "     |      `PrimaryHDU` are required by extension HDUs (which cannot stand on\n",
      "     |      their own).\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |         ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.table._TableLikeHDU:\n",
      "     |  \n",
      "     |  from_columns(columns, header=None, nrows=0, fill=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Given either a `ColDefs` object, a sequence of `Column` objects,\n",
      "     |      or another table HDU or table data (a `FITS_rec` or multi-field\n",
      "     |      `numpy.ndarray` or `numpy.recarray` object, return a new table HDU of\n",
      "     |      the class this method was called on using the column definition from\n",
      "     |      the input.\n",
      "     |      \n",
      "     |      See also `FITS_rec.from_columns`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns : sequence of `Column`, `ColDefs`, or other\n",
      "     |          The columns from which to create the table data, or an object with\n",
      "     |          a column-like structure from which a `ColDefs` can be instantiated.\n",
      "     |          This includes an existing `BinTableHDU` or `TableHDU`, or a\n",
      "     |          `numpy.recarray` to give some examples.\n",
      "     |      \n",
      "     |          If these columns have data arrays attached that data may be used in\n",
      "     |          initializing the new table.  Otherwise the input columns will be\n",
      "     |          used as a template for a new table with the requested number of\n",
      "     |          rows.\n",
      "     |      \n",
      "     |      header : `Header`\n",
      "     |          An optional `Header` object to instantiate the new HDU yet.  Header\n",
      "     |          keywords specifically related to defining the table structure (such\n",
      "     |          as the \"TXXXn\" keywords like TTYPEn) will be overridden by the\n",
      "     |          supplied column definitions, but all other informational and data\n",
      "     |          model-specific keywords are kept.\n",
      "     |      \n",
      "     |      nrows : int\n",
      "     |          Number of rows in the new table.  If the input columns have data\n",
      "     |          associated with them, the size of the largest input column is used.\n",
      "     |          Otherwise the default is 0.\n",
      "     |      \n",
      "     |      fill : bool\n",
      "     |          If `True`, will fill all cells with zeros or blanks.  If `False`,\n",
      "     |          copy the data from input, undefined cells will still be filled with\n",
      "     |          zeros/blanks.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      Any additional keyword arguments accepted by the HDU class's\n",
      "     |      ``__init__`` may also be passed in as keyword arguments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, blocking='standard', checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, blocking='standard', datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file object or file-like object\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __new__(cls, data=None, header=None, *args, **kwargs)\n",
      "     |      Iterates through the subclasses of _BaseHDU and uses that class's\n",
      "     |      match_header() method to determine which subclass to instantiate.\n",
      "     |      \n",
      "     |      It's important to be aware that the class hierarchy is traversed in a\n",
      "     |      depth-last order.  Each match_header() should identify an HDU type as\n",
      "     |      uniquely as possible.  Abstract types may choose to simply return False\n",
      "     |      or raise NotImplementedError to be skipped.\n",
      "     |      \n",
      "     |      If any unexpected exceptions are raised while evaluating\n",
      "     |      match_header(), the type is taken to be _CorruptedHDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class Conf(astropy.config.configuration.ConfigNamespace)\n",
      "     |  Configuration parameters for `astropy.io.fits`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Conf\n",
      "     |      astropy.config.configuration.ConfigNamespace\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  enable_record_valued_keyword_cards\n",
      "     |      If True, enable support for record-valued keywords as described by FITS WCS distortion paper. Otherwise they are treated as normal keywords.\n",
      "     |  \n",
      "     |  enable_uint\n",
      "     |      If True, default to recognizing the convention for representing unsigned integers in FITS--if an array has BITPIX > 0, BSCALE = 1, and BZERO = 2**BITPIX, represent the data as unsigned integers per this convention.\n",
      "     |  \n",
      "     |  extension_name_case_sensitive\n",
      "     |      If True, extension names (i.e. the ``EXTNAME`` keyword) should be treated as case-sensitive.\n",
      "     |  \n",
      "     |  lazy_load_hdus\n",
      "     |      If True, use lazy loading of HDUs when opening FITS files by default; that is fits.open() will only seek for and read HDUs on demand rather than reading all HDUs at once.  See the documentation for fits.open() for more datails.\n",
      "     |  \n",
      "     |  strip_header_whitespace\n",
      "     |      If True, automatically remove trailing whitespace for string values in headers.  Otherwise the values are returned verbatim, with all whitespace intact.\n",
      "     |  \n",
      "     |  use_memmap\n",
      "     |      If True, use memory-mapped file access to read/write the data in FITS files. This generally provides better performance, especially for large files, but may affect performance in I/O-heavy applications.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.config.configuration.ConfigNamespace:\n",
      "     |  \n",
      "     |  reload(self, attr=None)\n",
      "     |      Reload a configuration item from the configuration file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      attr : str, optional\n",
      "     |          The name of the configuration parameter to reload.  If not\n",
      "     |          provided, reload all configuration parameters.\n",
      "     |  \n",
      "     |  reset(self, attr=None)\n",
      "     |      Reset a configuration item to its default.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      attr : str, optional\n",
      "     |          The name of the configuration parameter to reload.  If not\n",
      "     |          provided, reset all configuration parameters.\n",
      "     |  \n",
      "     |  set_temp(self, attr, value)\n",
      "     |      Temporarily set a configuration value.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      attr : str\n",
      "     |          Configuration item name\n",
      "     |      \n",
      "     |      value : object\n",
      "     |          The value to set temporarily.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import astropy\n",
      "     |      >>> with astropy.conf.set_temp('use_color', False):\n",
      "     |      ...     pass\n",
      "     |      ...     # console output will not contain color\n",
      "     |      >>> # console output contains color again...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.config.configuration.ConfigNamespace:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Delayed(builtins.object)\n",
      "     |  Delayed file-reading data.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __init__(self, hdu=None, field=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class FITS_rec(numpy.recarray)\n",
      "     |  FITS record array class.\n",
      "     |  \n",
      "     |  `FITS_rec` is the data part of a table HDU's data part.  This is a layer\n",
      "     |  over the `~numpy.recarray`, so we can deal with scaled columns.\n",
      "     |  \n",
      "     |  It inherits all of the standard methods from `numpy.ndarray`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FITS_rec\n",
      "     |      numpy.recarray\n",
      "     |      numpy.ndarray\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __array_finalize__(self, obj)\n",
      "     |      None.\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Return a 3-tuple for pickling a FITS_rec. Use the super-class\n",
      "     |      functionality but then add in a tuple of FITS_rec-specific\n",
      "     |      values that get used in __setstate__.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      a.__setstate__(version, shape, dtype, isfortran, rawdata)\n",
      "     |      \n",
      "     |      For unpickling.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      version : int\n",
      "     |          optional pickle version. If omitted defaults to 0.\n",
      "     |      shape : tuple\n",
      "     |      dtype : data-type\n",
      "     |      isFortran : bool\n",
      "     |      rawdata : string or list\n",
      "     |          a binary string with the data (or a list if 'a' is an object array)\n",
      "     |  \n",
      "     |  copy(self, order='C')\n",
      "     |      The Numpy documentation lies; `numpy.ndarray.copy` is not equivalent to\n",
      "     |      `numpy.copy`.  Differences include that it re-views the copied array as\n",
      "     |      self's ndarray subclass, as though it were taking a slice; this means\n",
      "     |      ``__array_finalize__`` is called and the copy shares all the array\n",
      "     |      attributes (including ``._converted``!).  So we need to make a deep\n",
      "     |      copy of all those attributes so that the two arrays truly do not share\n",
      "     |      any data.\n",
      "     |  \n",
      "     |  field(self, key)\n",
      "     |      A view of a `Column`'s data as an array.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_columns(columns, nrows=0, fill=False) from builtins.type\n",
      "     |      Given a `ColDefs` object of unknown origin, initialize a new `FITS_rec`\n",
      "     |      object.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This was originally part of the ``new_table`` function in the table\n",
      "     |          module but was moved into a class method since most of its\n",
      "     |          functionality always had more to do with initializing a `FITS_rec`\n",
      "     |          object than anything else, and much of it also overlapped with\n",
      "     |          ``FITS_rec._scale_back``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns : sequence of `Column` or a `ColDefs`\n",
      "     |          The columns from which to create the table data.  If these\n",
      "     |          columns have data arrays attached that data may be used in\n",
      "     |          initializing the new table.  Otherwise the input columns\n",
      "     |          will be used as a template for a new table with the requested\n",
      "     |          number of rows.\n",
      "     |      \n",
      "     |      nrows : int\n",
      "     |          Number of rows in the new table.  If the input columns have data\n",
      "     |          associated with them, the size of the largest input column is used.\n",
      "     |          Otherwise the default is 0.\n",
      "     |      \n",
      "     |      fill : bool\n",
      "     |          If `True`, will fill all cells with zeros or blanks.  If\n",
      "     |          `False`, copy the data from input, undefined cells will still\n",
      "     |          be filled with zeros/blanks.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(subtype, input)\n",
      "     |      Construct a FITS record array from a recarray.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      A user-visible accessor for the coldefs.\n",
      "     |      \n",
      "     |      See https://aeon.stsci.edu/ssb/trac/pyfits/ticket/44\n",
      "     |  \n",
      "     |  formats\n",
      "     |      List of column FITS formats.\n",
      "     |  \n",
      "     |  names\n",
      "     |      List of column names.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from numpy.recarray:\n",
      "     |  \n",
      "     |  __getattribute__(self, attr)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from numpy.recarray:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from numpy.ndarray:\n",
      "     |  \n",
      "     |  __abs__(self, /)\n",
      "     |      abs(self)\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __and__(self, value, /)\n",
      "     |      Return self&value.\n",
      "     |  \n",
      "     |  __array__(...)\n",
      "     |      a.__array__(|dtype) -> reference if type unchanged, copy otherwise.\n",
      "     |      \n",
      "     |      Returns either a new reference to self if dtype is not given or a new array\n",
      "     |      of provided data type if dtype is different from the current dtype of the\n",
      "     |      array.\n",
      "     |  \n",
      "     |  __array_prepare__(...)\n",
      "     |      a.__array_prepare__(obj) -> Object of same type as ndarray object obj.\n",
      "     |  \n",
      "     |  __array_ufunc__(...)\n",
      "     |  \n",
      "     |  __array_wrap__(...)\n",
      "     |      a.__array_wrap__(obj) -> Object of same type as ndarray object a.\n",
      "     |  \n",
      "     |  __bool__(self, /)\n",
      "     |      self != 0\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __copy__(...)\n",
      "     |      a.__copy__([order])\n",
      "     |      \n",
      "     |      Return a copy of the array.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : {'C', 'F', 'A'}, optional\n",
      "     |          If order is 'C' (False) then the result is contiguous (default).\n",
      "     |          If order is 'Fortran' (True) then the result has fortran order.\n",
      "     |          If order is 'Any' (None) then the result has fortran order\n",
      "     |          only if the array already is in fortran order.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      a.__deepcopy__() -> Deep copy of array.\n",
      "     |      \n",
      "     |      Used if copy.deepcopy is called on an array.\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __divmod__(self, value, /)\n",
      "     |      Return divmod(self, value).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(self, /)\n",
      "     |      float(self)\n",
      "     |  \n",
      "     |  __floordiv__(self, value, /)\n",
      "     |      Return self//value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __iadd__(self, value, /)\n",
      "     |      Return self+=value.\n",
      "     |  \n",
      "     |  __iand__(self, value, /)\n",
      "     |      Return self&=value.\n",
      "     |  \n",
      "     |  __ifloordiv__(self, value, /)\n",
      "     |      Return self//=value.\n",
      "     |  \n",
      "     |  __ilshift__(self, value, /)\n",
      "     |      Return self<<=value.\n",
      "     |  \n",
      "     |  __imatmul__(self, value, /)\n",
      "     |      Return self@=value.\n",
      "     |  \n",
      "     |  __imod__(self, value, /)\n",
      "     |      Return self%=value.\n",
      "     |  \n",
      "     |  __imul__(self, value, /)\n",
      "     |      Return self*=value.\n",
      "     |  \n",
      "     |  __index__(self, /)\n",
      "     |      Return self converted to an integer, if self is suitable for use as an index into a list.\n",
      "     |  \n",
      "     |  __int__(self, /)\n",
      "     |      int(self)\n",
      "     |  \n",
      "     |  __invert__(self, /)\n",
      "     |      ~self\n",
      "     |  \n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |  \n",
      "     |  __ipow__(self, value, /)\n",
      "     |      Return self**=value.\n",
      "     |  \n",
      "     |  __irshift__(self, value, /)\n",
      "     |      Return self>>=value.\n",
      "     |  \n",
      "     |  __isub__(self, value, /)\n",
      "     |      Return self-=value.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __itruediv__(self, value, /)\n",
      "     |      Return self/=value.\n",
      "     |  \n",
      "     |  __ixor__(self, value, /)\n",
      "     |      Return self^=value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lshift__(self, value, /)\n",
      "     |      Return self<<value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(self, value, /)\n",
      "     |      Return self@value.\n",
      "     |  \n",
      "     |  __mod__(self, value, /)\n",
      "     |      Return self%value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__(self, /)\n",
      "     |      -self\n",
      "     |  \n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |  \n",
      "     |  __pos__(self, /)\n",
      "     |      +self\n",
      "     |  \n",
      "     |  __pow__(self, value, mod=None, /)\n",
      "     |      Return pow(self, value, mod).\n",
      "     |  \n",
      "     |  __radd__(self, value, /)\n",
      "     |      Return value+self.\n",
      "     |  \n",
      "     |  __rand__(self, value, /)\n",
      "     |      Return value&self.\n",
      "     |  \n",
      "     |  __rdivmod__(self, value, /)\n",
      "     |      Return divmod(value, self).\n",
      "     |  \n",
      "     |  __rfloordiv__(self, value, /)\n",
      "     |      Return value//self.\n",
      "     |  \n",
      "     |  __rlshift__(self, value, /)\n",
      "     |      Return value<<self.\n",
      "     |  \n",
      "     |  __rmatmul__(self, value, /)\n",
      "     |      Return value@self.\n",
      "     |  \n",
      "     |  __rmod__(self, value, /)\n",
      "     |      Return value%self.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |  \n",
      "     |  __rpow__(self, value, mod=None, /)\n",
      "     |      Return pow(value, self, mod).\n",
      "     |  \n",
      "     |  __rrshift__(self, value, /)\n",
      "     |      Return value>>self.\n",
      "     |  \n",
      "     |  __rshift__(self, value, /)\n",
      "     |      Return self>>value.\n",
      "     |  \n",
      "     |  __rsub__(self, value, /)\n",
      "     |      Return value-self.\n",
      "     |  \n",
      "     |  __rtruediv__(self, value, /)\n",
      "     |      Return value/self.\n",
      "     |  \n",
      "     |  __rxor__(self, value, /)\n",
      "     |      Return value^self.\n",
      "     |  \n",
      "     |  __sizeof__(...)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __sub__(self, value, /)\n",
      "     |      Return self-value.\n",
      "     |  \n",
      "     |  __truediv__(self, value, /)\n",
      "     |      Return self/value.\n",
      "     |  \n",
      "     |  __xor__(self, value, /)\n",
      "     |      Return self^value.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      a.all(axis=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Returns True if all elements evaluate to True.\n",
      "     |      \n",
      "     |      Refer to `numpy.all` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.all : equivalent function\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      a.any(axis=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Returns True if any of the elements of `a` evaluate to True.\n",
      "     |      \n",
      "     |      Refer to `numpy.any` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.any : equivalent function\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      a.argmax(axis=None, out=None)\n",
      "     |      \n",
      "     |      Return indices of the maximum values along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.argmax` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argmax : equivalent function\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      a.argmin(axis=None, out=None)\n",
      "     |      \n",
      "     |      Return indices of the minimum values along the given axis of `a`.\n",
      "     |      \n",
      "     |      Refer to `numpy.argmin` for detailed documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argmin : equivalent function\n",
      "     |  \n",
      "     |  argpartition(...)\n",
      "     |      a.argpartition(kth, axis=-1, kind='introselect', order=None)\n",
      "     |      \n",
      "     |      Returns the indices that would partition this array.\n",
      "     |      \n",
      "     |      Refer to `numpy.argpartition` for full documentation.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.8.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argpartition : equivalent function\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      a.argsort(axis=-1, kind='quicksort', order=None)\n",
      "     |      \n",
      "     |      Returns the indices that would sort this array.\n",
      "     |      \n",
      "     |      Refer to `numpy.argsort` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argsort : equivalent function\n",
      "     |  \n",
      "     |  astype(...)\n",
      "     |      a.astype(dtype, order='K', casting='unsafe', subok=True, copy=True)\n",
      "     |      \n",
      "     |      Copy of the array, cast to a specified type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or dtype\n",
      "     |          Typecode or data-type to which the array is cast.\n",
      "     |      order : {'C', 'F', 'A', 'K'}, optional\n",
      "     |          Controls the memory layout order of the result.\n",
      "     |          'C' means C order, 'F' means Fortran order, 'A'\n",
      "     |          means 'F' order if all the arrays are Fortran contiguous,\n",
      "     |          'C' order otherwise, and 'K' means as close to the\n",
      "     |          order the array elements appear in memory as possible.\n",
      "     |          Default is 'K'.\n",
      "     |      casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "     |          Controls what kind of data casting may occur. Defaults to 'unsafe'\n",
      "     |          for backwards compatibility.\n",
      "     |      \n",
      "     |            * 'no' means the data types should not be cast at all.\n",
      "     |            * 'equiv' means only byte-order changes are allowed.\n",
      "     |            * 'safe' means only casts which can preserve values are allowed.\n",
      "     |            * 'same_kind' means only safe casts or casts within a kind,\n",
      "     |              like float64 to float32, are allowed.\n",
      "     |            * 'unsafe' means any data conversions may be done.\n",
      "     |      subok : bool, optional\n",
      "     |          If True, then sub-classes will be passed-through (default), otherwise\n",
      "     |          the returned array will be forced to be a base-class array.\n",
      "     |      copy : bool, optional\n",
      "     |          By default, astype always returns a newly allocated array. If this\n",
      "     |          is set to false, and the `dtype`, `order`, and `subok`\n",
      "     |          requirements are satisfied, the input array is returned instead\n",
      "     |          of a copy.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      arr_t : ndarray\n",
      "     |          Unless `copy` is False and the other conditions for returning the input\n",
      "     |          array are satisfied (see description for `copy` input parameter), `arr_t`\n",
      "     |          is a new array of the same shape as the input array, with dtype, order\n",
      "     |          given by `dtype`, `order`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Starting in NumPy 1.9, astype method now returns an error if the string\n",
      "     |      dtype to cast to is not long enough in 'safe' casting mode to hold the max\n",
      "     |      value of integer/float array that is being casted. Previously the casting\n",
      "     |      was allowed even if the result was truncated.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ComplexWarning\n",
      "     |          When casting from complex to float or int. To avoid this,\n",
      "     |          one should use ``a.real.astype(t)``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1, 2, 2.5])\n",
      "     |      >>> x\n",
      "     |      array([ 1. ,  2. ,  2.5])\n",
      "     |      \n",
      "     |      >>> x.astype(int)\n",
      "     |      array([1, 2, 2])\n",
      "     |  \n",
      "     |  byteswap(...)\n",
      "     |      a.byteswap(inplace)\n",
      "     |      \n",
      "     |      Swap the bytes of the array elements\n",
      "     |      \n",
      "     |      Toggle between low-endian and big-endian data representation by\n",
      "     |      returning a byteswapped array, optionally swapped in-place.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inplace : bool, optional\n",
      "     |          If ``True``, swap bytes in-place, default is ``False``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          The byteswapped array. If `inplace` is ``True``, this is\n",
      "     |          a view to self.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> A = np.array([1, 256, 8755], dtype=np.int16)\n",
      "     |      >>> map(hex, A)\n",
      "     |      ['0x1', '0x100', '0x2233']\n",
      "     |      >>> A.byteswap(True)\n",
      "     |      array([  256,     1, 13090], dtype=int16)\n",
      "     |      >>> map(hex, A)\n",
      "     |      ['0x100', '0x1', '0x3322']\n",
      "     |      \n",
      "     |      Arrays of strings are not swapped\n",
      "     |      \n",
      "     |      >>> A = np.array(['ceg', 'fac'])\n",
      "     |      >>> A.byteswap()\n",
      "     |      array(['ceg', 'fac'],\n",
      "     |            dtype='|S3')\n",
      "     |  \n",
      "     |  choose(...)\n",
      "     |      a.choose(choices, out=None, mode='raise')\n",
      "     |      \n",
      "     |      Use an index array to construct a new array from a set of choices.\n",
      "     |      \n",
      "     |      Refer to `numpy.choose` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.choose : equivalent function\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      a.clip(min=None, max=None, out=None)\n",
      "     |      \n",
      "     |      Return an array whose values are limited to ``[min, max]``.\n",
      "     |      One of max or min must be given.\n",
      "     |      \n",
      "     |      Refer to `numpy.clip` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.clip : equivalent function\n",
      "     |  \n",
      "     |  compress(...)\n",
      "     |      a.compress(condition, axis=None, out=None)\n",
      "     |      \n",
      "     |      Return selected slices of this array along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.compress` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.compress : equivalent function\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      a.conj()\n",
      "     |      \n",
      "     |      Complex-conjugate all elements.\n",
      "     |      \n",
      "     |      Refer to `numpy.conjugate` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.conjugate : equivalent function\n",
      "     |  \n",
      "     |  conjugate(...)\n",
      "     |      a.conjugate()\n",
      "     |      \n",
      "     |      Return the complex conjugate, element-wise.\n",
      "     |      \n",
      "     |      Refer to `numpy.conjugate` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.conjugate : equivalent function\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      a.cumprod(axis=None, dtype=None, out=None)\n",
      "     |      \n",
      "     |      Return the cumulative product of the elements along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.cumprod` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.cumprod : equivalent function\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      a.cumsum(axis=None, dtype=None, out=None)\n",
      "     |      \n",
      "     |      Return the cumulative sum of the elements along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.cumsum` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.cumsum : equivalent function\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      a.diagonal(offset=0, axis1=0, axis2=1)\n",
      "     |      \n",
      "     |      Return specified diagonals. In NumPy 1.9 the returned array is a\n",
      "     |      read-only view instead of a copy as in previous NumPy versions.  In\n",
      "     |      a future version the read-only restriction will be removed.\n",
      "     |      \n",
      "     |      Refer to :func:`numpy.diagonal` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.diagonal : equivalent function\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      a.dot(b, out=None)\n",
      "     |      \n",
      "     |      Dot product of two arrays.\n",
      "     |      \n",
      "     |      Refer to `numpy.dot` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.dot : equivalent function\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.eye(2)\n",
      "     |      >>> b = np.ones((2, 2)) * 2\n",
      "     |      >>> a.dot(b)\n",
      "     |      array([[ 2.,  2.],\n",
      "     |             [ 2.,  2.]])\n",
      "     |      \n",
      "     |      This array method can be conveniently chained:\n",
      "     |      \n",
      "     |      >>> a.dot(b).dot(b)\n",
      "     |      array([[ 8.,  8.],\n",
      "     |             [ 8.,  8.]])\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      a.dump(file)\n",
      "     |      \n",
      "     |      Dump a pickle of the array to the specified file.\n",
      "     |      The array can be read back with pickle.load or numpy.load.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      file : str\n",
      "     |          A string naming the dump file.\n",
      "     |  \n",
      "     |  dumps(...)\n",
      "     |      a.dumps()\n",
      "     |      \n",
      "     |      Returns the pickle of the array as a string.\n",
      "     |      pickle.loads or numpy.loads will convert the string back to an array.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      None\n",
      "     |  \n",
      "     |  fill(...)\n",
      "     |      a.fill(value)\n",
      "     |      \n",
      "     |      Fill the array with a scalar value.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : scalar\n",
      "     |          All elements of `a` will be assigned this value.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([1, 2])\n",
      "     |      >>> a.fill(0)\n",
      "     |      >>> a\n",
      "     |      array([0, 0])\n",
      "     |      >>> a = np.empty(2)\n",
      "     |      >>> a.fill(1)\n",
      "     |      >>> a\n",
      "     |      array([ 1.,  1.])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      a.flatten(order='C')\n",
      "     |      \n",
      "     |      Return a copy of the array collapsed into one dimension.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : {'C', 'F', 'A', 'K'}, optional\n",
      "     |          'C' means to flatten in row-major (C-style) order.\n",
      "     |          'F' means to flatten in column-major (Fortran-\n",
      "     |          style) order. 'A' means to flatten in column-major\n",
      "     |          order if `a` is Fortran *contiguous* in memory,\n",
      "     |          row-major order otherwise. 'K' means to flatten\n",
      "     |          `a` in the order the elements occur in memory.\n",
      "     |          The default is 'C'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : ndarray\n",
      "     |          A copy of the input array, flattened to one dimension.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      ravel : Return a flattened array.\n",
      "     |      flat : A 1-D flat iterator over the array.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([[1,2], [3,4]])\n",
      "     |      >>> a.flatten()\n",
      "     |      array([1, 2, 3, 4])\n",
      "     |      >>> a.flatten('F')\n",
      "     |      array([1, 3, 2, 4])\n",
      "     |  \n",
      "     |  getfield(...)\n",
      "     |      a.getfield(dtype, offset=0)\n",
      "     |      \n",
      "     |      Returns a field of the given array as a certain type.\n",
      "     |      \n",
      "     |      A field is a view of the array data with a given data-type. The values in\n",
      "     |      the view are determined by the given type and the offset into the current\n",
      "     |      array in bytes. The offset needs to be such that the view dtype fits in the\n",
      "     |      array dtype; for example an array of dtype complex128 has 16-byte elements.\n",
      "     |      If taking a view with a 32-bit integer (4 bytes), the offset needs to be\n",
      "     |      between 0 and 12 bytes.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or dtype\n",
      "     |          The data type of the view. The dtype size of the view can not be larger\n",
      "     |          than that of the array itself.\n",
      "     |      offset : int\n",
      "     |          Number of bytes to skip before beginning the element view.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.diag([1.+1.j]*2)\n",
      "     |      >>> x[1, 1] = 2 + 4.j\n",
      "     |      >>> x\n",
      "     |      array([[ 1.+1.j,  0.+0.j],\n",
      "     |             [ 0.+0.j,  2.+4.j]])\n",
      "     |      >>> x.getfield(np.float64)\n",
      "     |      array([[ 1.,  0.],\n",
      "     |             [ 0.,  2.]])\n",
      "     |      \n",
      "     |      By choosing an offset of 8 bytes we can select the complex part of the\n",
      "     |      array for our view:\n",
      "     |      \n",
      "     |      >>> x.getfield(np.float64, offset=8)\n",
      "     |      array([[ 1.,  0.],\n",
      "     |         [ 0.,  4.]])\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      a.item(*args)\n",
      "     |      \n",
      "     |      Copy an element of an array to a standard Python scalar and return it.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \\*args : Arguments (variable number and type)\n",
      "     |      \n",
      "     |          * none: in this case, the method only works for arrays\n",
      "     |            with one element (`a.size == 1`), which element is\n",
      "     |            copied into a standard Python scalar object and returned.\n",
      "     |      \n",
      "     |          * int_type: this argument is interpreted as a flat index into\n",
      "     |            the array, specifying which element to copy and return.\n",
      "     |      \n",
      "     |          * tuple of int_types: functions as does a single int_type argument,\n",
      "     |            except that the argument is interpreted as an nd-index into the\n",
      "     |            array.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      z : Standard Python scalar object\n",
      "     |          A copy of the specified element of the array as a suitable\n",
      "     |          Python scalar\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      When the data type of `a` is longdouble or clongdouble, item() returns\n",
      "     |      a scalar array object because there is no available Python scalar that\n",
      "     |      would not lose information. Void arrays return a buffer object for item(),\n",
      "     |      unless fields are defined, in which case a tuple is returned.\n",
      "     |      \n",
      "     |      `item` is very similar to a[args], except, instead of an array scalar,\n",
      "     |      a standard Python scalar is returned. This can be useful for speeding up\n",
      "     |      access to elements of the array and doing arithmetic on elements of the\n",
      "     |      array using Python's optimized math.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.random.randint(9, size=(3, 3))\n",
      "     |      >>> x\n",
      "     |      array([[3, 1, 7],\n",
      "     |             [2, 8, 3],\n",
      "     |             [8, 5, 3]])\n",
      "     |      >>> x.item(3)\n",
      "     |      2\n",
      "     |      >>> x.item(7)\n",
      "     |      5\n",
      "     |      >>> x.item((0, 1))\n",
      "     |      1\n",
      "     |      >>> x.item((2, 2))\n",
      "     |      3\n",
      "     |  \n",
      "     |  itemset(...)\n",
      "     |      a.itemset(*args)\n",
      "     |      \n",
      "     |      Insert scalar into an array (scalar is cast to array's dtype, if possible)\n",
      "     |      \n",
      "     |      There must be at least 1 argument, and define the last argument\n",
      "     |      as *item*.  Then, ``a.itemset(*args)`` is equivalent to but faster\n",
      "     |      than ``a[args] = item``.  The item should be a scalar value and `args`\n",
      "     |      must select a single item in the array `a`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \\*args : Arguments\n",
      "     |          If one argument: a scalar, only used in case `a` is of size 1.\n",
      "     |          If two arguments: the last argument is the value to be set\n",
      "     |          and must be a scalar, the first argument specifies a single array\n",
      "     |          element location. It is either an int or a tuple.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Compared to indexing syntax, `itemset` provides some speed increase\n",
      "     |      for placing a scalar into a particular location in an `ndarray`,\n",
      "     |      if you must do this.  However, generally this is discouraged:\n",
      "     |      among other problems, it complicates the appearance of the code.\n",
      "     |      Also, when using `itemset` (and `item`) inside a loop, be sure\n",
      "     |      to assign the methods to a local variable to avoid the attribute\n",
      "     |      look-up at each loop iteration.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.random.randint(9, size=(3, 3))\n",
      "     |      >>> x\n",
      "     |      array([[3, 1, 7],\n",
      "     |             [2, 8, 3],\n",
      "     |             [8, 5, 3]])\n",
      "     |      >>> x.itemset(4, 0)\n",
      "     |      >>> x.itemset((2, 2), 9)\n",
      "     |      >>> x\n",
      "     |      array([[3, 1, 7],\n",
      "     |             [2, 0, 3],\n",
      "     |             [8, 5, 9]])\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      a.max(axis=None, out=None)\n",
      "     |      \n",
      "     |      Return the maximum along a given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.amax` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.amax : equivalent function\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      a.mean(axis=None, dtype=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Returns the average of the array elements along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.mean` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.mean : equivalent function\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      a.min(axis=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Return the minimum along a given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.amin` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.amin : equivalent function\n",
      "     |  \n",
      "     |  newbyteorder(...)\n",
      "     |      arr.newbyteorder(new_order='S')\n",
      "     |      \n",
      "     |      Return the array with the same data viewed with a different byte order.\n",
      "     |      \n",
      "     |      Equivalent to::\n",
      "     |      \n",
      "     |          arr.view(arr.dtype.newbytorder(new_order))\n",
      "     |      \n",
      "     |      Changes are also made in all fields and sub-arrays of the array data\n",
      "     |      type.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_order : string, optional\n",
      "     |          Byte order to force; a value from the byte order specifications\n",
      "     |          below. `new_order` codes can be any of:\n",
      "     |      \n",
      "     |          * 'S' - swap dtype from current to opposite endian\n",
      "     |          * {'<', 'L'} - little endian\n",
      "     |          * {'>', 'B'} - big endian\n",
      "     |          * {'=', 'N'} - native order\n",
      "     |          * {'|', 'I'} - ignore (no change to byte order)\n",
      "     |      \n",
      "     |          The default value ('S') results in swapping the current\n",
      "     |          byte order. The code does a case-insensitive check on the first\n",
      "     |          letter of `new_order` for the alternatives above.  For example,\n",
      "     |          any of 'B' or 'b' or 'biggish' are valid to specify big-endian.\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      new_arr : array\n",
      "     |          New array object with the dtype reflecting given change to the\n",
      "     |          byte order.\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      a.nonzero()\n",
      "     |      \n",
      "     |      Return the indices of the elements that are non-zero.\n",
      "     |      \n",
      "     |      Refer to `numpy.nonzero` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.nonzero : equivalent function\n",
      "     |  \n",
      "     |  partition(...)\n",
      "     |      a.partition(kth, axis=-1, kind='introselect', order=None)\n",
      "     |      \n",
      "     |      Rearranges the elements in the array in such a way that value of the\n",
      "     |      element in kth position is in the position it would be in a sorted array.\n",
      "     |      All elements smaller than the kth element are moved before this element and\n",
      "     |      all equal or greater are moved behind it. The ordering of the elements in\n",
      "     |      the two partitions is undefined.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.8.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      kth : int or sequence of ints\n",
      "     |          Element index to partition by. The kth element value will be in its\n",
      "     |          final sorted position and all smaller elements will be moved before it\n",
      "     |          and all equal or greater elements behind it.\n",
      "     |          The order all elements in the partitions is undefined.\n",
      "     |          If provided with a sequence of kth it will partition all elements\n",
      "     |          indexed by kth of them into their sorted position at once.\n",
      "     |      axis : int, optional\n",
      "     |          Axis along which to sort. Default is -1, which means sort along the\n",
      "     |          last axis.\n",
      "     |      kind : {'introselect'}, optional\n",
      "     |          Selection algorithm. Default is 'introselect'.\n",
      "     |      order : str or list of str, optional\n",
      "     |          When `a` is an array with fields defined, this argument specifies\n",
      "     |          which fields to compare first, second, etc.  A single field can\n",
      "     |          be specified as a string, and not all fields need be specified,\n",
      "     |          but unspecified fields will still be used, in the order in which\n",
      "     |          they come up in the dtype, to break ties.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.partition : Return a parititioned copy of an array.\n",
      "     |      argpartition : Indirect partition.\n",
      "     |      sort : Full sort.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See ``np.partition`` for notes on the different algorithms.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([3, 4, 2, 1])\n",
      "     |      >>> a.partition(3)\n",
      "     |      >>> a\n",
      "     |      array([2, 1, 3, 4])\n",
      "     |      \n",
      "     |      >>> a.partition((1, 3))\n",
      "     |      array([1, 2, 3, 4])\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      a.prod(axis=None, dtype=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Return the product of the array elements over the given axis\n",
      "     |      \n",
      "     |      Refer to `numpy.prod` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.prod : equivalent function\n",
      "     |  \n",
      "     |  ptp(...)\n",
      "     |      a.ptp(axis=None, out=None)\n",
      "     |      \n",
      "     |      Peak to peak (maximum - minimum) value along a given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.ptp` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ptp : equivalent function\n",
      "     |  \n",
      "     |  put(...)\n",
      "     |      a.put(indices, values, mode='raise')\n",
      "     |      \n",
      "     |      Set ``a.flat[n] = values[n]`` for all `n` in indices.\n",
      "     |      \n",
      "     |      Refer to `numpy.put` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.put : equivalent function\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      a.ravel([order])\n",
      "     |      \n",
      "     |      Return a flattened array.\n",
      "     |      \n",
      "     |      Refer to `numpy.ravel` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ravel : equivalent function\n",
      "     |      \n",
      "     |      ndarray.flat : a flat iterator on the array.\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      a.repeat(repeats, axis=None)\n",
      "     |      \n",
      "     |      Repeat elements of an array.\n",
      "     |      \n",
      "     |      Refer to `numpy.repeat` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.repeat : equivalent function\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      a.reshape(shape, order='C')\n",
      "     |      \n",
      "     |      Returns an array containing the same data with a new shape.\n",
      "     |      \n",
      "     |      Refer to `numpy.reshape` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.reshape : equivalent function\n",
      "     |  \n",
      "     |  resize(...)\n",
      "     |      a.resize(new_shape, refcheck=True)\n",
      "     |      \n",
      "     |      Change shape and size of array in-place.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_shape : tuple of ints, or `n` ints\n",
      "     |          Shape of resized array.\n",
      "     |      refcheck : bool, optional\n",
      "     |          If False, reference count will not be checked. Default is True.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If `a` does not own its own data or references or views to it exist,\n",
      "     |          and the data memory must be changed.\n",
      "     |          PyPy only: will always raise if the data memory must be changed, since\n",
      "     |          there is no reliable way to determine if references or views to it\n",
      "     |          exist.\n",
      "     |      \n",
      "     |      SystemError\n",
      "     |          If the `order` keyword argument is specified. This behaviour is a\n",
      "     |          bug in NumPy.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      resize : Return a new array with the specified shape.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This reallocates space for the data area if necessary.\n",
      "     |      \n",
      "     |      Only contiguous arrays (data elements consecutive in memory) can be\n",
      "     |      resized.\n",
      "     |      \n",
      "     |      The purpose of the reference count check is to make sure you\n",
      "     |      do not use this array as a buffer for another Python object and then\n",
      "     |      reallocate the memory. However, reference counts can increase in\n",
      "     |      other ways so if you are sure that you have not shared the memory\n",
      "     |      for this array with another Python object, then you may safely set\n",
      "     |      `refcheck` to False.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Shrinking an array: array is flattened (in the order that the data are\n",
      "     |      stored in memory), resized, and reshaped:\n",
      "     |      \n",
      "     |      >>> a = np.array([[0, 1], [2, 3]], order='C')\n",
      "     |      >>> a.resize((2, 1))\n",
      "     |      >>> a\n",
      "     |      array([[0],\n",
      "     |             [1]])\n",
      "     |      \n",
      "     |      >>> a = np.array([[0, 1], [2, 3]], order='F')\n",
      "     |      >>> a.resize((2, 1))\n",
      "     |      >>> a\n",
      "     |      array([[0],\n",
      "     |             [2]])\n",
      "     |      \n",
      "     |      Enlarging an array: as above, but missing entries are filled with zeros:\n",
      "     |      \n",
      "     |      >>> b = np.array([[0, 1], [2, 3]])\n",
      "     |      >>> b.resize(2, 3) # new_shape parameter doesn't have to be a tuple\n",
      "     |      >>> b\n",
      "     |      array([[0, 1, 2],\n",
      "     |             [3, 0, 0]])\n",
      "     |      \n",
      "     |      Referencing an array prevents resizing...\n",
      "     |      \n",
      "     |      >>> c = a\n",
      "     |      >>> a.resize((1, 1))\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: cannot resize an array that has been referenced ...\n",
      "     |      \n",
      "     |      Unless `refcheck` is False:\n",
      "     |      \n",
      "     |      >>> a.resize((1, 1), refcheck=False)\n",
      "     |      >>> a\n",
      "     |      array([[0]])\n",
      "     |      >>> c\n",
      "     |      array([[0]])\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      a.round(decimals=0, out=None)\n",
      "     |      \n",
      "     |      Return `a` with each element rounded to the given number of decimals.\n",
      "     |      \n",
      "     |      Refer to `numpy.around` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.around : equivalent function\n",
      "     |  \n",
      "     |  searchsorted(...)\n",
      "     |      a.searchsorted(v, side='left', sorter=None)\n",
      "     |      \n",
      "     |      Find indices where elements of v should be inserted in a to maintain order.\n",
      "     |      \n",
      "     |      For full documentation, see `numpy.searchsorted`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.searchsorted : equivalent function\n",
      "     |  \n",
      "     |  setfield(...)\n",
      "     |      a.setfield(val, dtype, offset=0)\n",
      "     |      \n",
      "     |      Put a value into a specified place in a field defined by a data-type.\n",
      "     |      \n",
      "     |      Place `val` into `a`'s field defined by `dtype` and beginning `offset`\n",
      "     |      bytes into the field.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      val : object\n",
      "     |          Value to be placed in field.\n",
      "     |      dtype : dtype object\n",
      "     |          Data-type of the field in which to place `val`.\n",
      "     |      offset : int, optional\n",
      "     |          The number of bytes into the field at which to place `val`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      None\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      getfield\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.eye(3)\n",
      "     |      >>> x.getfield(np.float64)\n",
      "     |      array([[ 1.,  0.,  0.],\n",
      "     |             [ 0.,  1.,  0.],\n",
      "     |             [ 0.,  0.,  1.]])\n",
      "     |      >>> x.setfield(3, np.int32)\n",
      "     |      >>> x.getfield(np.int32)\n",
      "     |      array([[3, 3, 3],\n",
      "     |             [3, 3, 3],\n",
      "     |             [3, 3, 3]])\n",
      "     |      >>> x\n",
      "     |      array([[  1.00000000e+000,   1.48219694e-323,   1.48219694e-323],\n",
      "     |             [  1.48219694e-323,   1.00000000e+000,   1.48219694e-323],\n",
      "     |             [  1.48219694e-323,   1.48219694e-323,   1.00000000e+000]])\n",
      "     |      >>> x.setfield(np.eye(3), np.int32)\n",
      "     |      >>> x\n",
      "     |      array([[ 1.,  0.,  0.],\n",
      "     |             [ 0.,  1.,  0.],\n",
      "     |             [ 0.,  0.,  1.]])\n",
      "     |  \n",
      "     |  setflags(...)\n",
      "     |      a.setflags(write=None, align=None, uic=None)\n",
      "     |      \n",
      "     |      Set array flags WRITEABLE, ALIGNED, and UPDATEIFCOPY, respectively.\n",
      "     |      \n",
      "     |      These Boolean-valued flags affect how numpy interprets the memory\n",
      "     |      area used by `a` (see Notes below). The ALIGNED flag can only\n",
      "     |      be set to True if the data is actually aligned according to the type.\n",
      "     |      The UPDATEIFCOPY flag can never be set to True. The flag WRITEABLE\n",
      "     |      can only be set to True if the array owns its own memory, or the\n",
      "     |      ultimate owner of the memory exposes a writeable buffer interface,\n",
      "     |      or is a string. (The exception for string is made so that unpickling\n",
      "     |      can be done without copying memory.)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      write : bool, optional\n",
      "     |          Describes whether or not `a` can be written to.\n",
      "     |      align : bool, optional\n",
      "     |          Describes whether or not `a` is aligned properly for its type.\n",
      "     |      uic : bool, optional\n",
      "     |          Describes whether or not `a` is a copy of another \"base\" array.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Array flags provide information about how the memory area used\n",
      "     |      for the array is to be interpreted. There are 6 Boolean flags\n",
      "     |      in use, only three of which can be changed by the user:\n",
      "     |      UPDATEIFCOPY, WRITEABLE, and ALIGNED.\n",
      "     |      \n",
      "     |      WRITEABLE (W) the data area can be written to;\n",
      "     |      \n",
      "     |      ALIGNED (A) the data and strides are aligned appropriately for the hardware\n",
      "     |      (as determined by the compiler);\n",
      "     |      \n",
      "     |      UPDATEIFCOPY (U) this array is a copy of some other array (referenced\n",
      "     |      by .base). When this array is deallocated, the base array will be\n",
      "     |      updated with the contents of this array.\n",
      "     |      \n",
      "     |      All flags can be accessed using their first (upper case) letter as well\n",
      "     |      as the full name.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> y\n",
      "     |      array([[3, 1, 7],\n",
      "     |             [2, 0, 0],\n",
      "     |             [8, 5, 9]])\n",
      "     |      >>> y.flags\n",
      "     |        C_CONTIGUOUS : True\n",
      "     |        F_CONTIGUOUS : False\n",
      "     |        OWNDATA : True\n",
      "     |        WRITEABLE : True\n",
      "     |        ALIGNED : True\n",
      "     |        UPDATEIFCOPY : False\n",
      "     |      >>> y.setflags(write=0, align=0)\n",
      "     |      >>> y.flags\n",
      "     |        C_CONTIGUOUS : True\n",
      "     |        F_CONTIGUOUS : False\n",
      "     |        OWNDATA : True\n",
      "     |        WRITEABLE : False\n",
      "     |        ALIGNED : False\n",
      "     |        UPDATEIFCOPY : False\n",
      "     |      >>> y.setflags(uic=1)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |      ValueError: cannot set UPDATEIFCOPY flag to True\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      a.sort(axis=-1, kind='quicksort', order=None)\n",
      "     |      \n",
      "     |      Sort an array, in-place.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional\n",
      "     |          Axis along which to sort. Default is -1, which means sort along the\n",
      "     |          last axis.\n",
      "     |      kind : {'quicksort', 'mergesort', 'heapsort'}, optional\n",
      "     |          Sorting algorithm. Default is 'quicksort'.\n",
      "     |      order : str or list of str, optional\n",
      "     |          When `a` is an array with fields defined, this argument specifies\n",
      "     |          which fields to compare first, second, etc.  A single field can\n",
      "     |          be specified as a string, and not all fields need be specified,\n",
      "     |          but unspecified fields will still be used, in the order in which\n",
      "     |          they come up in the dtype, to break ties.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.sort : Return a sorted copy of an array.\n",
      "     |      argsort : Indirect sort.\n",
      "     |      lexsort : Indirect stable sort on multiple keys.\n",
      "     |      searchsorted : Find elements in sorted array.\n",
      "     |      partition: Partial sort.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See ``sort`` for notes on the different sorting algorithms.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([[1,4], [3,1]])\n",
      "     |      >>> a.sort(axis=1)\n",
      "     |      >>> a\n",
      "     |      array([[1, 4],\n",
      "     |             [1, 3]])\n",
      "     |      >>> a.sort(axis=0)\n",
      "     |      >>> a\n",
      "     |      array([[1, 3],\n",
      "     |             [1, 4]])\n",
      "     |      \n",
      "     |      Use the `order` keyword to specify a field to use when sorting a\n",
      "     |      structured array:\n",
      "     |      \n",
      "     |      >>> a = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)])\n",
      "     |      >>> a.sort(order='y')\n",
      "     |      >>> a\n",
      "     |      array([('c', 1), ('a', 2)],\n",
      "     |            dtype=[('x', '|S1'), ('y', '<i4')])\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      a.squeeze(axis=None)\n",
      "     |      \n",
      "     |      Remove single-dimensional entries from the shape of `a`.\n",
      "     |      \n",
      "     |      Refer to `numpy.squeeze` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.squeeze : equivalent function\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      a.std(axis=None, dtype=None, out=None, ddof=0, keepdims=False)\n",
      "     |      \n",
      "     |      Returns the standard deviation of the array elements along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.std` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.std : equivalent function\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      a.sum(axis=None, dtype=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Return the sum of the array elements over the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.sum` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.sum : equivalent function\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      a.swapaxes(axis1, axis2)\n",
      "     |      \n",
      "     |      Return a view of the array with `axis1` and `axis2` interchanged.\n",
      "     |      \n",
      "     |      Refer to `numpy.swapaxes` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.swapaxes : equivalent function\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      a.take(indices, axis=None, out=None, mode='raise')\n",
      "     |      \n",
      "     |      Return an array formed from the elements of `a` at the given indices.\n",
      "     |      \n",
      "     |      Refer to `numpy.take` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.take : equivalent function\n",
      "     |  \n",
      "     |  tobytes(...)\n",
      "     |      a.tobytes(order='C')\n",
      "     |      \n",
      "     |      Construct Python bytes containing the raw data bytes in the array.\n",
      "     |      \n",
      "     |      Constructs Python bytes showing a copy of the raw contents of\n",
      "     |      data memory. The bytes object can be produced in either 'C' or 'Fortran',\n",
      "     |      or 'Any' order (the default is 'C'-order). 'Any' order means C-order\n",
      "     |      unless the F_CONTIGUOUS flag in the array is set, in which case it\n",
      "     |      means 'Fortran' order.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.9.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : {'C', 'F', None}, optional\n",
      "     |          Order of the data for multidimensional arrays:\n",
      "     |          C, Fortran, or the same as for the original array.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      s : bytes\n",
      "     |          Python bytes exhibiting a copy of `a`'s raw data.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([[0, 1], [2, 3]])\n",
      "     |      >>> x.tobytes()\n",
      "     |      b'\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n",
      "     |      >>> x.tobytes('C') == x.tobytes()\n",
      "     |      True\n",
      "     |      >>> x.tobytes('F')\n",
      "     |      b'\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n",
      "     |  \n",
      "     |  tofile(...)\n",
      "     |      a.tofile(fid, sep=\"\", format=\"%s\")\n",
      "     |      \n",
      "     |      Write array to a file as text or binary (default).\n",
      "     |      \n",
      "     |      Data is always written in 'C' order, independent of the order of `a`.\n",
      "     |      The data produced by this method can be recovered using the function\n",
      "     |      fromfile().\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fid : file or str\n",
      "     |          An open file object, or a string containing a filename.\n",
      "     |      sep : str\n",
      "     |          Separator between array items for text output.\n",
      "     |          If \"\" (empty), a binary file is written, equivalent to\n",
      "     |          ``file.write(a.tobytes())``.\n",
      "     |      format : str\n",
      "     |          Format string for text file output.\n",
      "     |          Each entry in the array is formatted to text by first converting\n",
      "     |          it to the closest Python type, and then using \"format\" % item.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a convenience function for quick storage of array data.\n",
      "     |      Information on endianness and precision is lost, so this method is not a\n",
      "     |      good choice for files intended to archive data or transport data between\n",
      "     |      machines with different endianness. Some of these problems can be overcome\n",
      "     |      by outputting the data as text files, at the expense of speed and file\n",
      "     |      size.\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      a.tolist()\n",
      "     |      \n",
      "     |      Return the array as a (possibly nested) list.\n",
      "     |      \n",
      "     |      Return a copy of the array data as a (nested) Python list.\n",
      "     |      Data items are converted to the nearest compatible Python type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      none\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : list\n",
      "     |          The possibly nested list of array elements.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The array may be recreated, ``a = np.array(a.tolist())``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([1, 2])\n",
      "     |      >>> a.tolist()\n",
      "     |      [1, 2]\n",
      "     |      >>> a = np.array([[1, 2], [3, 4]])\n",
      "     |      >>> list(a)\n",
      "     |      [array([1, 2]), array([3, 4])]\n",
      "     |      >>> a.tolist()\n",
      "     |      [[1, 2], [3, 4]]\n",
      "     |  \n",
      "     |  tostring(...)\n",
      "     |      a.tostring(order='C')\n",
      "     |      \n",
      "     |      Construct Python bytes containing the raw data bytes in the array.\n",
      "     |      \n",
      "     |      Constructs Python bytes showing a copy of the raw contents of\n",
      "     |      data memory. The bytes object can be produced in either 'C' or 'Fortran',\n",
      "     |      or 'Any' order (the default is 'C'-order). 'Any' order means C-order\n",
      "     |      unless the F_CONTIGUOUS flag in the array is set, in which case it\n",
      "     |      means 'Fortran' order.\n",
      "     |      \n",
      "     |      This function is a compatibility alias for tobytes. Despite its name it returns bytes not strings.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : {'C', 'F', None}, optional\n",
      "     |          Order of the data for multidimensional arrays:\n",
      "     |          C, Fortran, or the same as for the original array.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      s : bytes\n",
      "     |          Python bytes exhibiting a copy of `a`'s raw data.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([[0, 1], [2, 3]])\n",
      "     |      >>> x.tobytes()\n",
      "     |      b'\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n",
      "     |      >>> x.tobytes('C') == x.tobytes()\n",
      "     |      True\n",
      "     |      >>> x.tobytes('F')\n",
      "     |      b'\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      a.trace(offset=0, axis1=0, axis2=1, dtype=None, out=None)\n",
      "     |      \n",
      "     |      Return the sum along diagonals of the array.\n",
      "     |      \n",
      "     |      Refer to `numpy.trace` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.trace : equivalent function\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      a.transpose(*axes)\n",
      "     |      \n",
      "     |      Returns a view of the array with axes transposed.\n",
      "     |      \n",
      "     |      For a 1-D array, this has no effect. (To change between column and\n",
      "     |      row vectors, first cast the 1-D array into a matrix object.)\n",
      "     |      For a 2-D array, this is the usual matrix transpose.\n",
      "     |      For an n-D array, if axes are given, their order indicates how the\n",
      "     |      axes are permuted (see Examples). If axes are not provided and\n",
      "     |      ``a.shape = (i[0], i[1], ... i[n-2], i[n-1])``, then\n",
      "     |      ``a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axes : None, tuple of ints, or `n` ints\n",
      "     |      \n",
      "     |       * None or no argument: reverses the order of the axes.\n",
      "     |      \n",
      "     |       * tuple of ints: `i` in the `j`-th place in the tuple means `a`'s\n",
      "     |         `i`-th axis becomes `a.transpose()`'s `j`-th axis.\n",
      "     |      \n",
      "     |       * `n` ints: same as an n-tuple of the same ints (this form is\n",
      "     |         intended simply as a \"convenience\" alternative to the tuple form)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          View of `a`, with axes suitably permuted.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      ndarray.T : Array property returning the array transposed.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([[1, 2], [3, 4]])\n",
      "     |      >>> a\n",
      "     |      array([[1, 2],\n",
      "     |             [3, 4]])\n",
      "     |      >>> a.transpose()\n",
      "     |      array([[1, 3],\n",
      "     |             [2, 4]])\n",
      "     |      >>> a.transpose((1, 0))\n",
      "     |      array([[1, 3],\n",
      "     |             [2, 4]])\n",
      "     |      >>> a.transpose(1, 0)\n",
      "     |      array([[1, 3],\n",
      "     |             [2, 4]])\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      a.var(axis=None, dtype=None, out=None, ddof=0, keepdims=False)\n",
      "     |      \n",
      "     |      Returns the variance of the array elements, along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.var` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.var : equivalent function\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      a.view(dtype=None, type=None)\n",
      "     |      \n",
      "     |      New view of array with the same data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : data-type or ndarray sub-class, optional\n",
      "     |          Data-type descriptor of the returned view, e.g., float32 or int16. The\n",
      "     |          default, None, results in the view having the same data-type as `a`.\n",
      "     |          This argument can also be specified as an ndarray sub-class, which\n",
      "     |          then specifies the type of the returned object (this is equivalent to\n",
      "     |          setting the ``type`` parameter).\n",
      "     |      type : Python type, optional\n",
      "     |          Type of the returned view, e.g., ndarray or matrix.  Again, the\n",
      "     |          default None results in type preservation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      ``a.view()`` is used two different ways:\n",
      "     |      \n",
      "     |      ``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view\n",
      "     |      of the array's memory with a different data-type.  This can cause a\n",
      "     |      reinterpretation of the bytes of memory.\n",
      "     |      \n",
      "     |      ``a.view(ndarray_subclass)`` or ``a.view(type=ndarray_subclass)`` just\n",
      "     |      returns an instance of `ndarray_subclass` that looks at the same array\n",
      "     |      (same shape, dtype, etc.)  This does not cause a reinterpretation of the\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      For ``a.view(some_dtype)``, if ``some_dtype`` has a different number of\n",
      "     |      bytes per entry than the previous dtype (for example, converting a\n",
      "     |      regular array to a structured array), then the behavior of the view\n",
      "     |      cannot be predicted just from the superficial appearance of ``a`` (shown\n",
      "     |      by ``print(a)``). It also depends on exactly how ``a`` is stored in\n",
      "     |      memory. Therefore if ``a`` is C-ordered versus fortran-ordered, versus\n",
      "     |      defined as a slice or transpose, etc., the view may give different\n",
      "     |      results.\n",
      "     |      \n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([(1, 2)], dtype=[('a', np.int8), ('b', np.int8)])\n",
      "     |      \n",
      "     |      Viewing array data using a different type and dtype:\n",
      "     |      \n",
      "     |      >>> y = x.view(dtype=np.int16, type=np.matrix)\n",
      "     |      >>> y\n",
      "     |      matrix([[513]], dtype=int16)\n",
      "     |      >>> print(type(y))\n",
      "     |      <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "     |      \n",
      "     |      Creating a view on a structured array so it can be used in calculations\n",
      "     |      \n",
      "     |      >>> x = np.array([(1, 2),(3,4)], dtype=[('a', np.int8), ('b', np.int8)])\n",
      "     |      >>> xv = x.view(dtype=np.int8).reshape(-1,2)\n",
      "     |      >>> xv\n",
      "     |      array([[1, 2],\n",
      "     |             [3, 4]], dtype=int8)\n",
      "     |      >>> xv.mean(0)\n",
      "     |      array([ 2.,  3.])\n",
      "     |      \n",
      "     |      Making changes to the view changes the underlying array\n",
      "     |      \n",
      "     |      >>> xv[0,1] = 20\n",
      "     |      >>> print(x)\n",
      "     |      [(1, 20) (3, 4)]\n",
      "     |      \n",
      "     |      Using a view to convert an array to a recarray:\n",
      "     |      \n",
      "     |      >>> z = x.view(np.recarray)\n",
      "     |      >>> z.a\n",
      "     |      array([1], dtype=int8)\n",
      "     |      \n",
      "     |      Views share data:\n",
      "     |      \n",
      "     |      >>> x[0] = (9, 10)\n",
      "     |      >>> z[0]\n",
      "     |      (9, 10)\n",
      "     |      \n",
      "     |      Views that change the dtype size (bytes per entry) should normally be\n",
      "     |      avoided on arrays defined by slices, transposes, fortran-ordering, etc.:\n",
      "     |      \n",
      "     |      >>> x = np.array([[1,2,3],[4,5,6]], dtype=np.int16)\n",
      "     |      >>> y = x[:, 0:2]\n",
      "     |      >>> y\n",
      "     |      array([[1, 2],\n",
      "     |             [4, 5]], dtype=int16)\n",
      "     |      >>> y.view(dtype=[('width', np.int16), ('length', np.int16)])\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |      ValueError: new type not compatible with array.\n",
      "     |      >>> z = y.copy()\n",
      "     |      >>> z.view(dtype=[('width', np.int16), ('length', np.int16)])\n",
      "     |      array([[(1, 2)],\n",
      "     |             [(4, 5)]], dtype=[('width', '<i2'), ('length', '<i2')])\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from numpy.ndarray:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Same as self.transpose(), except that self is returned if\n",
      "     |      self.ndim < 2.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([[1.,2.],[3.,4.]])\n",
      "     |      >>> x\n",
      "     |      array([[ 1.,  2.],\n",
      "     |             [ 3.,  4.]])\n",
      "     |      >>> x.T\n",
      "     |      array([[ 1.,  3.],\n",
      "     |             [ 2.,  4.]])\n",
      "     |      >>> x = np.array([1.,2.,3.,4.])\n",
      "     |      >>> x\n",
      "     |      array([ 1.,  2.,  3.,  4.])\n",
      "     |      >>> x.T\n",
      "     |      array([ 1.,  2.,  3.,  4.])\n",
      "     |  \n",
      "     |  __array_interface__\n",
      "     |      Array protocol: Python side.\n",
      "     |  \n",
      "     |  __array_priority__\n",
      "     |      Array priority.\n",
      "     |  \n",
      "     |  __array_struct__\n",
      "     |      Array protocol: C-struct side.\n",
      "     |  \n",
      "     |  base\n",
      "     |      Base object if memory is from some other object.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      The base of an array that owns its memory is None:\n",
      "     |      \n",
      "     |      >>> x = np.array([1,2,3,4])\n",
      "     |      >>> x.base is None\n",
      "     |      True\n",
      "     |      \n",
      "     |      Slicing creates a view, whose memory is shared with x:\n",
      "     |      \n",
      "     |      >>> y = x[2:]\n",
      "     |      >>> y.base is x\n",
      "     |      True\n",
      "     |  \n",
      "     |  ctypes\n",
      "     |      An object to simplify the interaction of the array with the ctypes\n",
      "     |      module.\n",
      "     |      \n",
      "     |      This attribute creates an object that makes it easier to use arrays\n",
      "     |      when calling shared libraries with the ctypes module. The returned\n",
      "     |      object has, among others, data, shape, and strides attributes (see\n",
      "     |      Notes below) which themselves return ctypes objects that can be used\n",
      "     |      as arguments to a shared library.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      c : Python object\n",
      "     |          Possessing attributes data, shape, strides, etc.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ctypeslib\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Below are the public attributes of this object which were documented\n",
      "     |      in \"Guide to NumPy\" (we have omitted undocumented public attributes,\n",
      "     |      as well as documented private attributes):\n",
      "     |      \n",
      "     |      * data: A pointer to the memory area of the array as a Python integer.\n",
      "     |        This memory area may contain data that is not aligned, or not in correct\n",
      "     |        byte-order. The memory area may not even be writeable. The array\n",
      "     |        flags and data-type of this array should be respected when passing this\n",
      "     |        attribute to arbitrary C-code to avoid trouble that can include Python\n",
      "     |        crashing. User Beware! The value of this attribute is exactly the same\n",
      "     |        as self._array_interface_['data'][0].\n",
      "     |      \n",
      "     |      * shape (c_intp*self.ndim): A ctypes array of length self.ndim where\n",
      "     |        the basetype is the C-integer corresponding to dtype('p') on this\n",
      "     |        platform. This base-type could be c_int, c_long, or c_longlong\n",
      "     |        depending on the platform. The c_intp type is defined accordingly in\n",
      "     |        numpy.ctypeslib. The ctypes array contains the shape of the underlying\n",
      "     |        array.\n",
      "     |      \n",
      "     |      * strides (c_intp*self.ndim): A ctypes array of length self.ndim where\n",
      "     |        the basetype is the same as for the shape attribute. This ctypes array\n",
      "     |        contains the strides information from the underlying array. This strides\n",
      "     |        information is important for showing how many bytes must be jumped to\n",
      "     |        get to the next element in the array.\n",
      "     |      \n",
      "     |      * data_as(obj): Return the data pointer cast to a particular c-types object.\n",
      "     |        For example, calling self._as_parameter_ is equivalent to\n",
      "     |        self.data_as(ctypes.c_void_p). Perhaps you want to use the data as a\n",
      "     |        pointer to a ctypes array of floating-point data:\n",
      "     |        self.data_as(ctypes.POINTER(ctypes.c_double)).\n",
      "     |      \n",
      "     |      * shape_as(obj): Return the shape tuple as an array of some other c-types\n",
      "     |        type. For example: self.shape_as(ctypes.c_short).\n",
      "     |      \n",
      "     |      * strides_as(obj): Return the strides tuple as an array of some other\n",
      "     |        c-types type. For example: self.strides_as(ctypes.c_longlong).\n",
      "     |      \n",
      "     |      Be careful using the ctypes attribute - especially on temporary\n",
      "     |      arrays or arrays constructed on the fly. For example, calling\n",
      "     |      ``(a+b).ctypes.data_as(ctypes.c_void_p)`` returns a pointer to memory\n",
      "     |      that is invalid because the array created as (a+b) is deallocated\n",
      "     |      before the next Python statement. You can avoid this problem using\n",
      "     |      either ``c=a+b`` or ``ct=(a+b).ctypes``. In the latter case, ct will\n",
      "     |      hold a reference to the array until ct is deleted or re-assigned.\n",
      "     |      \n",
      "     |      If the ctypes module is not available, then the ctypes attribute\n",
      "     |      of array objects still returns something useful, but ctypes objects\n",
      "     |      are not returned and errors may be raised instead. In particular,\n",
      "     |      the object will still have the as parameter attribute which will\n",
      "     |      return an integer equal to the data attribute.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import ctypes\n",
      "     |      >>> x\n",
      "     |      array([[0, 1],\n",
      "     |             [2, 3]])\n",
      "     |      >>> x.ctypes.data\n",
      "     |      30439712\n",
      "     |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_long))\n",
      "     |      <ctypes.LP_c_long object at 0x01F01300>\n",
      "     |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_long)).contents\n",
      "     |      c_long(0)\n",
      "     |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_longlong)).contents\n",
      "     |      c_longlong(4294967296L)\n",
      "     |      >>> x.ctypes.shape\n",
      "     |      <numpy.core._internal.c_long_Array_2 object at 0x01FFD580>\n",
      "     |      >>> x.ctypes.shape_as(ctypes.c_long)\n",
      "     |      <numpy.core._internal.c_long_Array_2 object at 0x01FCE620>\n",
      "     |      >>> x.ctypes.strides\n",
      "     |      <numpy.core._internal.c_long_Array_2 object at 0x01FCE620>\n",
      "     |      >>> x.ctypes.strides_as(ctypes.c_longlong)\n",
      "     |      <numpy.core._internal.c_longlong_Array_2 object at 0x01F01300>\n",
      "     |  \n",
      "     |  data\n",
      "     |      Python buffer object pointing to the start of the array's data.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Data-type of the array's elements.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      d : numpy dtype object\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.dtype\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x\n",
      "     |      array([[0, 1],\n",
      "     |             [2, 3]])\n",
      "     |      >>> x.dtype\n",
      "     |      dtype('int32')\n",
      "     |      >>> type(x.dtype)\n",
      "     |      <type 'numpy.dtype'>\n",
      "     |  \n",
      "     |  flags\n",
      "     |      Information about the memory layout of the array.\n",
      "     |      \n",
      "     |      Attributes\n",
      "     |      ----------\n",
      "     |      C_CONTIGUOUS (C)\n",
      "     |          The data is in a single, C-style contiguous segment.\n",
      "     |      F_CONTIGUOUS (F)\n",
      "     |          The data is in a single, Fortran-style contiguous segment.\n",
      "     |      OWNDATA (O)\n",
      "     |          The array owns the memory it uses or borrows it from another object.\n",
      "     |      WRITEABLE (W)\n",
      "     |          The data area can be written to.  Setting this to False locks\n",
      "     |          the data, making it read-only.  A view (slice, etc.) inherits WRITEABLE\n",
      "     |          from its base array at creation time, but a view of a writeable\n",
      "     |          array may be subsequently locked while the base array remains writeable.\n",
      "     |          (The opposite is not true, in that a view of a locked array may not\n",
      "     |          be made writeable.  However, currently, locking a base object does not\n",
      "     |          lock any views that already reference it, so under that circumstance it\n",
      "     |          is possible to alter the contents of a locked array via a previously\n",
      "     |          created writeable view onto it.)  Attempting to change a non-writeable\n",
      "     |          array raises a RuntimeError exception.\n",
      "     |      ALIGNED (A)\n",
      "     |          The data and all elements are aligned appropriately for the hardware.\n",
      "     |      UPDATEIFCOPY (U)\n",
      "     |          This array is a copy of some other array. When this array is\n",
      "     |          deallocated, the base array will be updated with the contents of\n",
      "     |          this array.\n",
      "     |      FNC\n",
      "     |          F_CONTIGUOUS and not C_CONTIGUOUS.\n",
      "     |      FORC\n",
      "     |          F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n",
      "     |      BEHAVED (B)\n",
      "     |          ALIGNED and WRITEABLE.\n",
      "     |      CARRAY (CA)\n",
      "     |          BEHAVED and C_CONTIGUOUS.\n",
      "     |      FARRAY (FA)\n",
      "     |          BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The `flags` object can be accessed dictionary-like (as in ``a.flags['WRITEABLE']``),\n",
      "     |      or by using lowercased attribute names (as in ``a.flags.writeable``). Short flag\n",
      "     |      names are only supported in dictionary access.\n",
      "     |      \n",
      "     |      Only the UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be changed by\n",
      "     |      the user, via direct assignment to the attribute or dictionary entry,\n",
      "     |      or by calling `ndarray.setflags`.\n",
      "     |      \n",
      "     |      The array flags cannot be set arbitrarily:\n",
      "     |      \n",
      "     |      - UPDATEIFCOPY can only be set ``False``.\n",
      "     |      - ALIGNED can only be set ``True`` if the data is truly aligned.\n",
      "     |      - WRITEABLE can only be set ``True`` if the array owns its own memory\n",
      "     |        or the ultimate owner of the memory exposes a writeable buffer\n",
      "     |        interface or is a string.\n",
      "     |      \n",
      "     |      Arrays can be both C-style and Fortran-style contiguous simultaneously.\n",
      "     |      This is clear for 1-dimensional arrays, but can also be true for higher\n",
      "     |      dimensional arrays.\n",
      "     |      \n",
      "     |      Even for contiguous arrays a stride for a given dimension\n",
      "     |      ``arr.strides[dim]`` may be *arbitrary* if ``arr.shape[dim] == 1``\n",
      "     |      or the array has no elements.\n",
      "     |      It does *not* generally hold that ``self.strides[-1] == self.itemsize``\n",
      "     |      for C-style contiguous arrays or ``self.strides[0] == self.itemsize`` for\n",
      "     |      Fortran-style contiguous arrays is true.\n",
      "     |  \n",
      "     |  flat\n",
      "     |      A 1-D iterator over the array.\n",
      "     |      \n",
      "     |      This is a `numpy.flatiter` instance, which acts similarly to, but is not\n",
      "     |      a subclass of, Python's built-in iterator object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      flatten : Return a copy of the array collapsed into one dimension.\n",
      "     |      \n",
      "     |      flatiter\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.arange(1, 7).reshape(2, 3)\n",
      "     |      >>> x\n",
      "     |      array([[1, 2, 3],\n",
      "     |             [4, 5, 6]])\n",
      "     |      >>> x.flat[3]\n",
      "     |      4\n",
      "     |      >>> x.T\n",
      "     |      array([[1, 4],\n",
      "     |             [2, 5],\n",
      "     |             [3, 6]])\n",
      "     |      >>> x.T.flat[3]\n",
      "     |      5\n",
      "     |      >>> type(x.flat)\n",
      "     |      <type 'numpy.flatiter'>\n",
      "     |      \n",
      "     |      An assignment example:\n",
      "     |      \n",
      "     |      >>> x.flat = 3; x\n",
      "     |      array([[3, 3, 3],\n",
      "     |             [3, 3, 3]])\n",
      "     |      >>> x.flat[[1,4]] = 1; x\n",
      "     |      array([[3, 1, 3],\n",
      "     |             [3, 1, 3]])\n",
      "     |  \n",
      "     |  imag\n",
      "     |      The imaginary part of the array.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.sqrt([1+0j, 0+1j])\n",
      "     |      >>> x.imag\n",
      "     |      array([ 0.        ,  0.70710678])\n",
      "     |      >>> x.imag.dtype\n",
      "     |      dtype('float64')\n",
      "     |  \n",
      "     |  itemsize\n",
      "     |      Length of one array element in bytes.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1,2,3], dtype=np.float64)\n",
      "     |      >>> x.itemsize\n",
      "     |      8\n",
      "     |      >>> x = np.array([1,2,3], dtype=np.complex128)\n",
      "     |      >>> x.itemsize\n",
      "     |      16\n",
      "     |  \n",
      "     |  nbytes\n",
      "     |      Total bytes consumed by the elements of the array.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Does not include memory consumed by non-element attributes of the\n",
      "     |      array object.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.zeros((3,5,2), dtype=np.complex128)\n",
      "     |      >>> x.nbytes\n",
      "     |      480\n",
      "     |      >>> np.prod(x.shape) * x.itemsize\n",
      "     |      480\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Number of array dimensions.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1, 2, 3])\n",
      "     |      >>> x.ndim\n",
      "     |      1\n",
      "     |      >>> y = np.zeros((2, 3, 4))\n",
      "     |      >>> y.ndim\n",
      "     |      3\n",
      "     |  \n",
      "     |  real\n",
      "     |      The real part of the array.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.sqrt([1+0j, 0+1j])\n",
      "     |      >>> x.real\n",
      "     |      array([ 1.        ,  0.70710678])\n",
      "     |      >>> x.real.dtype\n",
      "     |      dtype('float64')\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.real : equivalent function\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Tuple of array dimensions.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      May be used to \"reshape\" the array, as long as this would not\n",
      "     |      require a change in the total number of elements\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1, 2, 3, 4])\n",
      "     |      >>> x.shape\n",
      "     |      (4,)\n",
      "     |      >>> y = np.zeros((2, 3, 4))\n",
      "     |      >>> y.shape\n",
      "     |      (2, 3, 4)\n",
      "     |      >>> y.shape = (3, 8)\n",
      "     |      >>> y\n",
      "     |      array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "     |             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "     |             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "     |      >>> y.shape = (3, 6)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |      ValueError: total size of new array must be unchanged\n",
      "     |  \n",
      "     |  size\n",
      "     |      Number of elements in the array.\n",
      "     |      \n",
      "     |      Equivalent to ``np.prod(a.shape)``, i.e., the product of the array's\n",
      "     |      dimensions.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.zeros((3, 5, 2), dtype=np.complex128)\n",
      "     |      >>> x.size\n",
      "     |      30\n",
      "     |      >>> np.prod(x.shape)\n",
      "     |      30\n",
      "     |  \n",
      "     |  strides\n",
      "     |      Tuple of bytes to step in each dimension when traversing an array.\n",
      "     |      \n",
      "     |      The byte offset of element ``(i[0], i[1], ..., i[n])`` in an array `a`\n",
      "     |      is::\n",
      "     |      \n",
      "     |          offset = sum(np.array(i) * a.strides)\n",
      "     |      \n",
      "     |      A more detailed explanation of strides can be found in the\n",
      "     |      \"ndarray.rst\" file in the NumPy reference guide.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Imagine an array of 32-bit integers (each 4 bytes)::\n",
      "     |      \n",
      "     |        x = np.array([[0, 1, 2, 3, 4],\n",
      "     |                      [5, 6, 7, 8, 9]], dtype=np.int32)\n",
      "     |      \n",
      "     |      This array is stored in memory as 40 bytes, one after the other\n",
      "     |      (known as a contiguous block of memory).  The strides of an array tell\n",
      "     |      us how many bytes we have to skip in memory to move to the next position\n",
      "     |      along a certain axis.  For example, we have to skip 4 bytes (1 value) to\n",
      "     |      move to the next column, but 20 bytes (5 values) to get to the same\n",
      "     |      position in the next row.  As such, the strides for the array `x` will be\n",
      "     |      ``(20, 4)``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.lib.stride_tricks.as_strided\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> y = np.reshape(np.arange(2*3*4), (2,3,4))\n",
      "     |      >>> y\n",
      "     |      array([[[ 0,  1,  2,  3],\n",
      "     |              [ 4,  5,  6,  7],\n",
      "     |              [ 8,  9, 10, 11]],\n",
      "     |             [[12, 13, 14, 15],\n",
      "     |              [16, 17, 18, 19],\n",
      "     |              [20, 21, 22, 23]]])\n",
      "     |      >>> y.strides\n",
      "     |      (48, 16, 4)\n",
      "     |      >>> y[1,1,1]\n",
      "     |      17\n",
      "     |      >>> offset=sum(y.strides * np.array((1,1,1)))\n",
      "     |      >>> offset/y.itemsize\n",
      "     |      17\n",
      "     |      \n",
      "     |      >>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0)\n",
      "     |      >>> x.strides\n",
      "     |      (32, 4, 224, 1344)\n",
      "     |      >>> i = np.array([3,5,2,2])\n",
      "     |      >>> offset = sum(i * x.strides)\n",
      "     |      >>> x[3,5,2,2]\n",
      "     |      813\n",
      "     |      >>> offset / x.itemsize\n",
      "     |      813\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from numpy.ndarray:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class FITS_record(builtins.object)\n",
      "     |  FITS record class.\n",
      "     |  \n",
      "     |  `FITS_record` is used to access records of the `FITS_rec` object.\n",
      "     |  This will allow us to deal with scaled columns.  It also handles\n",
      "     |  conversion/scaling of columns in ASCII tables.  The `FITS_record`\n",
      "     |  class expects a `FITS_rec` object as input.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __init__(self, input, row=0, start=None, end=None, step=None, base=None, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input : array\n",
      "     |         The array to wrap.\n",
      "     |      \n",
      "     |      row : int, optional\n",
      "     |         The starting logical row of the array.\n",
      "     |      \n",
      "     |      start : int, optional\n",
      "     |         The starting column in the row associated with this object.\n",
      "     |         Used for subsetting the columns of the `FITS_rec` object.\n",
      "     |      \n",
      "     |      end : int, optional\n",
      "     |         The ending column in the row associated with this object.\n",
      "     |         Used for subsetting the columns of the `FITS_rec` object.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Display a single row.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  field(self, field)\n",
      "     |      Get the field data of the record.\n",
      "     |  \n",
      "     |  setfield(self, field, value)\n",
      "     |      Set the field data of the record.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class FitsHDU(astropy.io.fits.hdu.base.NonstandardExtHDU)\n",
      "     |  A non-standard extension HDU for encapsulating entire FITS files within a\n",
      "     |  single HDU of a container FITS file.  These HDUs have an extension (that is\n",
      "     |  an XTENSION keyword) of FITS.\n",
      "     |  \n",
      "     |  The FITS file contained in the HDU's data can be accessed by the `hdulist`\n",
      "     |  attribute which returns the contained FITS file as an `HDUList` object.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FitsHDU\n",
      "     |      astropy.io.fits.hdu.base.NonstandardExtHDU\n",
      "     |      astropy.io.fits.hdu.base.ExtensionHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  fromfile(filename, compress=False) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Like `FitsHDU.fromhdulist()`, but creates a FitsHDU from a file on\n",
      "     |      disk.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          The path to the file to read into a FitsHDU\n",
      "     |      compress : bool, optional\n",
      "     |          Gzip compress the FITS file\n",
      "     |  \n",
      "     |  fromhdulist(hdulist, compress=False) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new FitsHDU from a given HDUList object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hdulist : HDUList\n",
      "     |          A valid Headerlet object.\n",
      "     |      compress : bool, optional\n",
      "     |          Gzip compress the FITS file\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Matches any extension HDU that is not one of the standard extension HDU\n",
      "     |      types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  hdulist\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base.NonstandardExtHDU:\n",
      "     |  \n",
      "     |  data\n",
      "     |      Return the file data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base.ExtensionHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Works similarly to the normal writeto(), but prepends a default\n",
      "     |      `PrimaryHDU` are required by extension HDUs (which cannot stand on\n",
      "     |      their own).\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |         ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None, name=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, blocking='standard', checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, blocking='standard', datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file object or file-like object\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __new__(cls, data=None, header=None, *args, **kwargs)\n",
      "     |      Iterates through the subclasses of _BaseHDU and uses that class's\n",
      "     |      match_header() method to determine which subclass to instantiate.\n",
      "     |      \n",
      "     |      It's important to be aware that the class hierarchy is traversed in a\n",
      "     |      depth-last order.  Each match_header() should identify an HDU type as\n",
      "     |      uniquely as possible.  Abstract types may choose to simply return False\n",
      "     |      or raise NotImplementedError to be skipped.\n",
      "     |      \n",
      "     |      If any unexpected exceptions are raised while evaluating\n",
      "     |      match_header(), the type is taken to be _CorruptedHDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class Group(astropy.io.fits.fitsrec.FITS_record)\n",
      "     |  One group of the random group data.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Group\n",
      "     |      astropy.io.fits.fitsrec.FITS_record\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, input, row=0, start=None, end=None, step=None, base=None)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input : array\n",
      "     |         The array to wrap.\n",
      "     |      \n",
      "     |      row : int, optional\n",
      "     |         The starting logical row of the array.\n",
      "     |      \n",
      "     |      start : int, optional\n",
      "     |         The starting column in the row associated with this object.\n",
      "     |         Used for subsetting the columns of the `FITS_rec` object.\n",
      "     |      \n",
      "     |      end : int, optional\n",
      "     |         The ending column in the row associated with this object.\n",
      "     |         Used for subsetting the columns of the `FITS_rec` object.\n",
      "     |  \n",
      "     |  par(self, parname)\n",
      "     |      Get the group parameter value.\n",
      "     |  \n",
      "     |  setpar(self, parname, value)\n",
      "     |      Set the group parameter value.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  parnames\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.fitsrec.FITS_record:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Display a single row.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  field(self, field)\n",
      "     |      Get the field data of the record.\n",
      "     |  \n",
      "     |  setfield(self, field, value)\n",
      "     |      Set the field data of the record.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.fitsrec.FITS_record:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GroupData(astropy.io.fits.fitsrec.FITS_rec)\n",
      "     |  Random groups data object.\n",
      "     |  \n",
      "     |  Allows structured access to FITS Group data in a manner analogous\n",
      "     |  to tables.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GroupData\n",
      "     |      astropy.io.fits.fitsrec.FITS_rec\n",
      "     |      numpy.recarray\n",
      "     |      numpy.ndarray\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __array_finalize__(self, obj)\n",
      "     |      None.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  par(self, parname)\n",
      "     |      Get the group parameter values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, input=None, bitpix=None, pardata=None, parnames=[], bscale=None, bzero=None, parbscales=None, parbzeros=None)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input : array or FITS_rec instance\n",
      "     |          input data, either the group data itself (a\n",
      "     |          `numpy.ndarray`) or a record array (`FITS_rec`) which will\n",
      "     |          contain both group parameter info and the data.  The rest\n",
      "     |          of the arguments are used only for the first case.\n",
      "     |      \n",
      "     |      bitpix : int\n",
      "     |          data type as expressed in FITS ``BITPIX`` value (8, 16, 32,\n",
      "     |          64, -32, or -64)\n",
      "     |      \n",
      "     |      pardata : sequence of arrays\n",
      "     |          parameter data, as a list of (numeric) arrays.\n",
      "     |      \n",
      "     |      parnames : sequence of str\n",
      "     |          list of parameter names.\n",
      "     |      \n",
      "     |      bscale : int\n",
      "     |          ``BSCALE`` of the data\n",
      "     |      \n",
      "     |      bzero : int\n",
      "     |          ``BZERO`` of the data\n",
      "     |      \n",
      "     |      parbscales : sequence of int\n",
      "     |          list of bscales for the parameters\n",
      "     |      \n",
      "     |      parbzeros : sequence of int\n",
      "     |          list of bzeros for the parameters\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  data\n",
      "     |      The raw group data represented as a multi-dimensional `numpy.ndarray`\n",
      "     |      array.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.fitsrec.FITS_rec:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Return a 3-tuple for pickling a FITS_rec. Use the super-class\n",
      "     |      functionality but then add in a tuple of FITS_rec-specific\n",
      "     |      values that get used in __setstate__.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      a.__setstate__(version, shape, dtype, isfortran, rawdata)\n",
      "     |      \n",
      "     |      For unpickling.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      version : int\n",
      "     |          optional pickle version. If omitted defaults to 0.\n",
      "     |      shape : tuple\n",
      "     |      dtype : data-type\n",
      "     |      isFortran : bool\n",
      "     |      rawdata : string or list\n",
      "     |          a binary string with the data (or a list if 'a' is an object array)\n",
      "     |  \n",
      "     |  copy(self, order='C')\n",
      "     |      The Numpy documentation lies; `numpy.ndarray.copy` is not equivalent to\n",
      "     |      `numpy.copy`.  Differences include that it re-views the copied array as\n",
      "     |      self's ndarray subclass, as though it were taking a slice; this means\n",
      "     |      ``__array_finalize__`` is called and the copy shares all the array\n",
      "     |      attributes (including ``._converted``!).  So we need to make a deep\n",
      "     |      copy of all those attributes so that the two arrays truly do not share\n",
      "     |      any data.\n",
      "     |  \n",
      "     |  field(self, key)\n",
      "     |      A view of a `Column`'s data as an array.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.fitsrec.FITS_rec:\n",
      "     |  \n",
      "     |  from_columns(columns, nrows=0, fill=False) from builtins.type\n",
      "     |      Given a `ColDefs` object of unknown origin, initialize a new `FITS_rec`\n",
      "     |      object.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This was originally part of the ``new_table`` function in the table\n",
      "     |          module but was moved into a class method since most of its\n",
      "     |          functionality always had more to do with initializing a `FITS_rec`\n",
      "     |          object than anything else, and much of it also overlapped with\n",
      "     |          ``FITS_rec._scale_back``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns : sequence of `Column` or a `ColDefs`\n",
      "     |          The columns from which to create the table data.  If these\n",
      "     |          columns have data arrays attached that data may be used in\n",
      "     |          initializing the new table.  Otherwise the input columns\n",
      "     |          will be used as a template for a new table with the requested\n",
      "     |          number of rows.\n",
      "     |      \n",
      "     |      nrows : int\n",
      "     |          Number of rows in the new table.  If the input columns have data\n",
      "     |          associated with them, the size of the largest input column is used.\n",
      "     |          Otherwise the default is 0.\n",
      "     |      \n",
      "     |      fill : bool\n",
      "     |          If `True`, will fill all cells with zeros or blanks.  If\n",
      "     |          `False`, copy the data from input, undefined cells will still\n",
      "     |          be filled with zeros/blanks.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.fitsrec.FITS_rec:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      A user-visible accessor for the coldefs.\n",
      "     |      \n",
      "     |      See https://aeon.stsci.edu/ssb/trac/pyfits/ticket/44\n",
      "     |  \n",
      "     |  formats\n",
      "     |      List of column FITS formats.\n",
      "     |  \n",
      "     |  names\n",
      "     |      List of column names.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from numpy.recarray:\n",
      "     |  \n",
      "     |  __getattribute__(self, attr)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from numpy.recarray:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from numpy.ndarray:\n",
      "     |  \n",
      "     |  __abs__(self, /)\n",
      "     |      abs(self)\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __and__(self, value, /)\n",
      "     |      Return self&value.\n",
      "     |  \n",
      "     |  __array__(...)\n",
      "     |      a.__array__(|dtype) -> reference if type unchanged, copy otherwise.\n",
      "     |      \n",
      "     |      Returns either a new reference to self if dtype is not given or a new array\n",
      "     |      of provided data type if dtype is different from the current dtype of the\n",
      "     |      array.\n",
      "     |  \n",
      "     |  __array_prepare__(...)\n",
      "     |      a.__array_prepare__(obj) -> Object of same type as ndarray object obj.\n",
      "     |  \n",
      "     |  __array_ufunc__(...)\n",
      "     |  \n",
      "     |  __array_wrap__(...)\n",
      "     |      a.__array_wrap__(obj) -> Object of same type as ndarray object a.\n",
      "     |  \n",
      "     |  __bool__(self, /)\n",
      "     |      self != 0\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __copy__(...)\n",
      "     |      a.__copy__([order])\n",
      "     |      \n",
      "     |      Return a copy of the array.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : {'C', 'F', 'A'}, optional\n",
      "     |          If order is 'C' (False) then the result is contiguous (default).\n",
      "     |          If order is 'Fortran' (True) then the result has fortran order.\n",
      "     |          If order is 'Any' (None) then the result has fortran order\n",
      "     |          only if the array already is in fortran order.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      a.__deepcopy__() -> Deep copy of array.\n",
      "     |      \n",
      "     |      Used if copy.deepcopy is called on an array.\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __divmod__(self, value, /)\n",
      "     |      Return divmod(self, value).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(self, /)\n",
      "     |      float(self)\n",
      "     |  \n",
      "     |  __floordiv__(self, value, /)\n",
      "     |      Return self//value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __iadd__(self, value, /)\n",
      "     |      Return self+=value.\n",
      "     |  \n",
      "     |  __iand__(self, value, /)\n",
      "     |      Return self&=value.\n",
      "     |  \n",
      "     |  __ifloordiv__(self, value, /)\n",
      "     |      Return self//=value.\n",
      "     |  \n",
      "     |  __ilshift__(self, value, /)\n",
      "     |      Return self<<=value.\n",
      "     |  \n",
      "     |  __imatmul__(self, value, /)\n",
      "     |      Return self@=value.\n",
      "     |  \n",
      "     |  __imod__(self, value, /)\n",
      "     |      Return self%=value.\n",
      "     |  \n",
      "     |  __imul__(self, value, /)\n",
      "     |      Return self*=value.\n",
      "     |  \n",
      "     |  __index__(self, /)\n",
      "     |      Return self converted to an integer, if self is suitable for use as an index into a list.\n",
      "     |  \n",
      "     |  __int__(self, /)\n",
      "     |      int(self)\n",
      "     |  \n",
      "     |  __invert__(self, /)\n",
      "     |      ~self\n",
      "     |  \n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |  \n",
      "     |  __ipow__(self, value, /)\n",
      "     |      Return self**=value.\n",
      "     |  \n",
      "     |  __irshift__(self, value, /)\n",
      "     |      Return self>>=value.\n",
      "     |  \n",
      "     |  __isub__(self, value, /)\n",
      "     |      Return self-=value.\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __itruediv__(self, value, /)\n",
      "     |      Return self/=value.\n",
      "     |  \n",
      "     |  __ixor__(self, value, /)\n",
      "     |      Return self^=value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lshift__(self, value, /)\n",
      "     |      Return self<<value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(self, value, /)\n",
      "     |      Return self@value.\n",
      "     |  \n",
      "     |  __mod__(self, value, /)\n",
      "     |      Return self%value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__(self, /)\n",
      "     |      -self\n",
      "     |  \n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |  \n",
      "     |  __pos__(self, /)\n",
      "     |      +self\n",
      "     |  \n",
      "     |  __pow__(self, value, mod=None, /)\n",
      "     |      Return pow(self, value, mod).\n",
      "     |  \n",
      "     |  __radd__(self, value, /)\n",
      "     |      Return value+self.\n",
      "     |  \n",
      "     |  __rand__(self, value, /)\n",
      "     |      Return value&self.\n",
      "     |  \n",
      "     |  __rdivmod__(self, value, /)\n",
      "     |      Return divmod(value, self).\n",
      "     |  \n",
      "     |  __rfloordiv__(self, value, /)\n",
      "     |      Return value//self.\n",
      "     |  \n",
      "     |  __rlshift__(self, value, /)\n",
      "     |      Return value<<self.\n",
      "     |  \n",
      "     |  __rmatmul__(self, value, /)\n",
      "     |      Return value@self.\n",
      "     |  \n",
      "     |  __rmod__(self, value, /)\n",
      "     |      Return value%self.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |  \n",
      "     |  __rpow__(self, value, mod=None, /)\n",
      "     |      Return pow(value, self, mod).\n",
      "     |  \n",
      "     |  __rrshift__(self, value, /)\n",
      "     |      Return value>>self.\n",
      "     |  \n",
      "     |  __rshift__(self, value, /)\n",
      "     |      Return self>>value.\n",
      "     |  \n",
      "     |  __rsub__(self, value, /)\n",
      "     |      Return value-self.\n",
      "     |  \n",
      "     |  __rtruediv__(self, value, /)\n",
      "     |      Return value/self.\n",
      "     |  \n",
      "     |  __rxor__(self, value, /)\n",
      "     |      Return value^self.\n",
      "     |  \n",
      "     |  __sizeof__(...)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __sub__(self, value, /)\n",
      "     |      Return self-value.\n",
      "     |  \n",
      "     |  __truediv__(self, value, /)\n",
      "     |      Return self/value.\n",
      "     |  \n",
      "     |  __xor__(self, value, /)\n",
      "     |      Return self^value.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      a.all(axis=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Returns True if all elements evaluate to True.\n",
      "     |      \n",
      "     |      Refer to `numpy.all` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.all : equivalent function\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      a.any(axis=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Returns True if any of the elements of `a` evaluate to True.\n",
      "     |      \n",
      "     |      Refer to `numpy.any` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.any : equivalent function\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      a.argmax(axis=None, out=None)\n",
      "     |      \n",
      "     |      Return indices of the maximum values along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.argmax` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argmax : equivalent function\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      a.argmin(axis=None, out=None)\n",
      "     |      \n",
      "     |      Return indices of the minimum values along the given axis of `a`.\n",
      "     |      \n",
      "     |      Refer to `numpy.argmin` for detailed documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argmin : equivalent function\n",
      "     |  \n",
      "     |  argpartition(...)\n",
      "     |      a.argpartition(kth, axis=-1, kind='introselect', order=None)\n",
      "     |      \n",
      "     |      Returns the indices that would partition this array.\n",
      "     |      \n",
      "     |      Refer to `numpy.argpartition` for full documentation.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.8.0\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argpartition : equivalent function\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      a.argsort(axis=-1, kind='quicksort', order=None)\n",
      "     |      \n",
      "     |      Returns the indices that would sort this array.\n",
      "     |      \n",
      "     |      Refer to `numpy.argsort` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argsort : equivalent function\n",
      "     |  \n",
      "     |  astype(...)\n",
      "     |      a.astype(dtype, order='K', casting='unsafe', subok=True, copy=True)\n",
      "     |      \n",
      "     |      Copy of the array, cast to a specified type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or dtype\n",
      "     |          Typecode or data-type to which the array is cast.\n",
      "     |      order : {'C', 'F', 'A', 'K'}, optional\n",
      "     |          Controls the memory layout order of the result.\n",
      "     |          'C' means C order, 'F' means Fortran order, 'A'\n",
      "     |          means 'F' order if all the arrays are Fortran contiguous,\n",
      "     |          'C' order otherwise, and 'K' means as close to the\n",
      "     |          order the array elements appear in memory as possible.\n",
      "     |          Default is 'K'.\n",
      "     |      casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "     |          Controls what kind of data casting may occur. Defaults to 'unsafe'\n",
      "     |          for backwards compatibility.\n",
      "     |      \n",
      "     |            * 'no' means the data types should not be cast at all.\n",
      "     |            * 'equiv' means only byte-order changes are allowed.\n",
      "     |            * 'safe' means only casts which can preserve values are allowed.\n",
      "     |            * 'same_kind' means only safe casts or casts within a kind,\n",
      "     |              like float64 to float32, are allowed.\n",
      "     |            * 'unsafe' means any data conversions may be done.\n",
      "     |      subok : bool, optional\n",
      "     |          If True, then sub-classes will be passed-through (default), otherwise\n",
      "     |          the returned array will be forced to be a base-class array.\n",
      "     |      copy : bool, optional\n",
      "     |          By default, astype always returns a newly allocated array. If this\n",
      "     |          is set to false, and the `dtype`, `order`, and `subok`\n",
      "     |          requirements are satisfied, the input array is returned instead\n",
      "     |          of a copy.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      arr_t : ndarray\n",
      "     |          Unless `copy` is False and the other conditions for returning the input\n",
      "     |          array are satisfied (see description for `copy` input parameter), `arr_t`\n",
      "     |          is a new array of the same shape as the input array, with dtype, order\n",
      "     |          given by `dtype`, `order`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Starting in NumPy 1.9, astype method now returns an error if the string\n",
      "     |      dtype to cast to is not long enough in 'safe' casting mode to hold the max\n",
      "     |      value of integer/float array that is being casted. Previously the casting\n",
      "     |      was allowed even if the result was truncated.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ComplexWarning\n",
      "     |          When casting from complex to float or int. To avoid this,\n",
      "     |          one should use ``a.real.astype(t)``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1, 2, 2.5])\n",
      "     |      >>> x\n",
      "     |      array([ 1. ,  2. ,  2.5])\n",
      "     |      \n",
      "     |      >>> x.astype(int)\n",
      "     |      array([1, 2, 2])\n",
      "     |  \n",
      "     |  byteswap(...)\n",
      "     |      a.byteswap(inplace)\n",
      "     |      \n",
      "     |      Swap the bytes of the array elements\n",
      "     |      \n",
      "     |      Toggle between low-endian and big-endian data representation by\n",
      "     |      returning a byteswapped array, optionally swapped in-place.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inplace : bool, optional\n",
      "     |          If ``True``, swap bytes in-place, default is ``False``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          The byteswapped array. If `inplace` is ``True``, this is\n",
      "     |          a view to self.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> A = np.array([1, 256, 8755], dtype=np.int16)\n",
      "     |      >>> map(hex, A)\n",
      "     |      ['0x1', '0x100', '0x2233']\n",
      "     |      >>> A.byteswap(True)\n",
      "     |      array([  256,     1, 13090], dtype=int16)\n",
      "     |      >>> map(hex, A)\n",
      "     |      ['0x100', '0x1', '0x3322']\n",
      "     |      \n",
      "     |      Arrays of strings are not swapped\n",
      "     |      \n",
      "     |      >>> A = np.array(['ceg', 'fac'])\n",
      "     |      >>> A.byteswap()\n",
      "     |      array(['ceg', 'fac'],\n",
      "     |            dtype='|S3')\n",
      "     |  \n",
      "     |  choose(...)\n",
      "     |      a.choose(choices, out=None, mode='raise')\n",
      "     |      \n",
      "     |      Use an index array to construct a new array from a set of choices.\n",
      "     |      \n",
      "     |      Refer to `numpy.choose` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.choose : equivalent function\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      a.clip(min=None, max=None, out=None)\n",
      "     |      \n",
      "     |      Return an array whose values are limited to ``[min, max]``.\n",
      "     |      One of max or min must be given.\n",
      "     |      \n",
      "     |      Refer to `numpy.clip` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.clip : equivalent function\n",
      "     |  \n",
      "     |  compress(...)\n",
      "     |      a.compress(condition, axis=None, out=None)\n",
      "     |      \n",
      "     |      Return selected slices of this array along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.compress` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.compress : equivalent function\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      a.conj()\n",
      "     |      \n",
      "     |      Complex-conjugate all elements.\n",
      "     |      \n",
      "     |      Refer to `numpy.conjugate` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.conjugate : equivalent function\n",
      "     |  \n",
      "     |  conjugate(...)\n",
      "     |      a.conjugate()\n",
      "     |      \n",
      "     |      Return the complex conjugate, element-wise.\n",
      "     |      \n",
      "     |      Refer to `numpy.conjugate` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.conjugate : equivalent function\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      a.cumprod(axis=None, dtype=None, out=None)\n",
      "     |      \n",
      "     |      Return the cumulative product of the elements along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.cumprod` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.cumprod : equivalent function\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      a.cumsum(axis=None, dtype=None, out=None)\n",
      "     |      \n",
      "     |      Return the cumulative sum of the elements along the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.cumsum` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.cumsum : equivalent function\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      a.diagonal(offset=0, axis1=0, axis2=1)\n",
      "     |      \n",
      "     |      Return specified diagonals. In NumPy 1.9 the returned array is a\n",
      "     |      read-only view instead of a copy as in previous NumPy versions.  In\n",
      "     |      a future version the read-only restriction will be removed.\n",
      "     |      \n",
      "     |      Refer to :func:`numpy.diagonal` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.diagonal : equivalent function\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      a.dot(b, out=None)\n",
      "     |      \n",
      "     |      Dot product of two arrays.\n",
      "     |      \n",
      "     |      Refer to `numpy.dot` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.dot : equivalent function\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.eye(2)\n",
      "     |      >>> b = np.ones((2, 2)) * 2\n",
      "     |      >>> a.dot(b)\n",
      "     |      array([[ 2.,  2.],\n",
      "     |             [ 2.,  2.]])\n",
      "     |      \n",
      "     |      This array method can be conveniently chained:\n",
      "     |      \n",
      "     |      >>> a.dot(b).dot(b)\n",
      "     |      array([[ 8.,  8.],\n",
      "     |             [ 8.,  8.]])\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      a.dump(file)\n",
      "     |      \n",
      "     |      Dump a pickle of the array to the specified file.\n",
      "     |      The array can be read back with pickle.load or numpy.load.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      file : str\n",
      "     |          A string naming the dump file.\n",
      "     |  \n",
      "     |  dumps(...)\n",
      "     |      a.dumps()\n",
      "     |      \n",
      "     |      Returns the pickle of the array as a string.\n",
      "     |      pickle.loads or numpy.loads will convert the string back to an array.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      None\n",
      "     |  \n",
      "     |  fill(...)\n",
      "     |      a.fill(value)\n",
      "     |      \n",
      "     |      Fill the array with a scalar value.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : scalar\n",
      "     |          All elements of `a` will be assigned this value.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([1, 2])\n",
      "     |      >>> a.fill(0)\n",
      "     |      >>> a\n",
      "     |      array([0, 0])\n",
      "     |      >>> a = np.empty(2)\n",
      "     |      >>> a.fill(1)\n",
      "     |      >>> a\n",
      "     |      array([ 1.,  1.])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      a.flatten(order='C')\n",
      "     |      \n",
      "     |      Return a copy of the array collapsed into one dimension.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : {'C', 'F', 'A', 'K'}, optional\n",
      "     |          'C' means to flatten in row-major (C-style) order.\n",
      "     |          'F' means to flatten in column-major (Fortran-\n",
      "     |          style) order. 'A' means to flatten in column-major\n",
      "     |          order if `a` is Fortran *contiguous* in memory,\n",
      "     |          row-major order otherwise. 'K' means to flatten\n",
      "     |          `a` in the order the elements occur in memory.\n",
      "     |          The default is 'C'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : ndarray\n",
      "     |          A copy of the input array, flattened to one dimension.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      ravel : Return a flattened array.\n",
      "     |      flat : A 1-D flat iterator over the array.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([[1,2], [3,4]])\n",
      "     |      >>> a.flatten()\n",
      "     |      array([1, 2, 3, 4])\n",
      "     |      >>> a.flatten('F')\n",
      "     |      array([1, 3, 2, 4])\n",
      "     |  \n",
      "     |  getfield(...)\n",
      "     |      a.getfield(dtype, offset=0)\n",
      "     |      \n",
      "     |      Returns a field of the given array as a certain type.\n",
      "     |      \n",
      "     |      A field is a view of the array data with a given data-type. The values in\n",
      "     |      the view are determined by the given type and the offset into the current\n",
      "     |      array in bytes. The offset needs to be such that the view dtype fits in the\n",
      "     |      array dtype; for example an array of dtype complex128 has 16-byte elements.\n",
      "     |      If taking a view with a 32-bit integer (4 bytes), the offset needs to be\n",
      "     |      between 0 and 12 bytes.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or dtype\n",
      "     |          The data type of the view. The dtype size of the view can not be larger\n",
      "     |          than that of the array itself.\n",
      "     |      offset : int\n",
      "     |          Number of bytes to skip before beginning the element view.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.diag([1.+1.j]*2)\n",
      "     |      >>> x[1, 1] = 2 + 4.j\n",
      "     |      >>> x\n",
      "     |      array([[ 1.+1.j,  0.+0.j],\n",
      "     |             [ 0.+0.j,  2.+4.j]])\n",
      "     |      >>> x.getfield(np.float64)\n",
      "     |      array([[ 1.,  0.],\n",
      "     |             [ 0.,  2.]])\n",
      "     |      \n",
      "     |      By choosing an offset of 8 bytes we can select the complex part of the\n",
      "     |      array for our view:\n",
      "     |      \n",
      "     |      >>> x.getfield(np.float64, offset=8)\n",
      "     |      array([[ 1.,  0.],\n",
      "     |         [ 0.,  4.]])\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      a.item(*args)\n",
      "     |      \n",
      "     |      Copy an element of an array to a standard Python scalar and return it.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \\*args : Arguments (variable number and type)\n",
      "     |      \n",
      "     |          * none: in this case, the method only works for arrays\n",
      "     |            with one element (`a.size == 1`), which element is\n",
      "     |            copied into a standard Python scalar object and returned.\n",
      "     |      \n",
      "     |          * int_type: this argument is interpreted as a flat index into\n",
      "     |            the array, specifying which element to copy and return.\n",
      "     |      \n",
      "     |          * tuple of int_types: functions as does a single int_type argument,\n",
      "     |            except that the argument is interpreted as an nd-index into the\n",
      "     |            array.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      z : Standard Python scalar object\n",
      "     |          A copy of the specified element of the array as a suitable\n",
      "     |          Python scalar\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      When the data type of `a` is longdouble or clongdouble, item() returns\n",
      "     |      a scalar array object because there is no available Python scalar that\n",
      "     |      would not lose information. Void arrays return a buffer object for item(),\n",
      "     |      unless fields are defined, in which case a tuple is returned.\n",
      "     |      \n",
      "     |      `item` is very similar to a[args], except, instead of an array scalar,\n",
      "     |      a standard Python scalar is returned. This can be useful for speeding up\n",
      "     |      access to elements of the array and doing arithmetic on elements of the\n",
      "     |      array using Python's optimized math.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.random.randint(9, size=(3, 3))\n",
      "     |      >>> x\n",
      "     |      array([[3, 1, 7],\n",
      "     |             [2, 8, 3],\n",
      "     |             [8, 5, 3]])\n",
      "     |      >>> x.item(3)\n",
      "     |      2\n",
      "     |      >>> x.item(7)\n",
      "     |      5\n",
      "     |      >>> x.item((0, 1))\n",
      "     |      1\n",
      "     |      >>> x.item((2, 2))\n",
      "     |      3\n",
      "     |  \n",
      "     |  itemset(...)\n",
      "     |      a.itemset(*args)\n",
      "     |      \n",
      "     |      Insert scalar into an array (scalar is cast to array's dtype, if possible)\n",
      "     |      \n",
      "     |      There must be at least 1 argument, and define the last argument\n",
      "     |      as *item*.  Then, ``a.itemset(*args)`` is equivalent to but faster\n",
      "     |      than ``a[args] = item``.  The item should be a scalar value and `args`\n",
      "     |      must select a single item in the array `a`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \\*args : Arguments\n",
      "     |          If one argument: a scalar, only used in case `a` is of size 1.\n",
      "     |          If two arguments: the last argument is the value to be set\n",
      "     |          and must be a scalar, the first argument specifies a single array\n",
      "     |          element location. It is either an int or a tuple.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Compared to indexing syntax, `itemset` provides some speed increase\n",
      "     |      for placing a scalar into a particular location in an `ndarray`,\n",
      "     |      if you must do this.  However, generally this is discouraged:\n",
      "     |      among other problems, it complicates the appearance of the code.\n",
      "     |      Also, when using `itemset` (and `item`) inside a loop, be sure\n",
      "     |      to assign the methods to a local variable to avoid the attribute\n",
      "     |      look-up at each loop iteration.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.random.randint(9, size=(3, 3))\n",
      "     |      >>> x\n",
      "     |      array([[3, 1, 7],\n",
      "     |             [2, 8, 3],\n",
      "     |             [8, 5, 3]])\n",
      "     |      >>> x.itemset(4, 0)\n",
      "     |      >>> x.itemset((2, 2), 9)\n",
      "     |      >>> x\n",
      "     |      array([[3, 1, 7],\n",
      "     |             [2, 0, 3],\n",
      "     |             [8, 5, 9]])\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      a.max(axis=None, out=None)\n",
      "     |      \n",
      "     |      Return the maximum along a given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.amax` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.amax : equivalent function\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      a.mean(axis=None, dtype=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Returns the average of the array elements along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.mean` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.mean : equivalent function\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      a.min(axis=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Return the minimum along a given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.amin` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.amin : equivalent function\n",
      "     |  \n",
      "     |  newbyteorder(...)\n",
      "     |      arr.newbyteorder(new_order='S')\n",
      "     |      \n",
      "     |      Return the array with the same data viewed with a different byte order.\n",
      "     |      \n",
      "     |      Equivalent to::\n",
      "     |      \n",
      "     |          arr.view(arr.dtype.newbytorder(new_order))\n",
      "     |      \n",
      "     |      Changes are also made in all fields and sub-arrays of the array data\n",
      "     |      type.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_order : string, optional\n",
      "     |          Byte order to force; a value from the byte order specifications\n",
      "     |          below. `new_order` codes can be any of:\n",
      "     |      \n",
      "     |          * 'S' - swap dtype from current to opposite endian\n",
      "     |          * {'<', 'L'} - little endian\n",
      "     |          * {'>', 'B'} - big endian\n",
      "     |          * {'=', 'N'} - native order\n",
      "     |          * {'|', 'I'} - ignore (no change to byte order)\n",
      "     |      \n",
      "     |          The default value ('S') results in swapping the current\n",
      "     |          byte order. The code does a case-insensitive check on the first\n",
      "     |          letter of `new_order` for the alternatives above.  For example,\n",
      "     |          any of 'B' or 'b' or 'biggish' are valid to specify big-endian.\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      new_arr : array\n",
      "     |          New array object with the dtype reflecting given change to the\n",
      "     |          byte order.\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      a.nonzero()\n",
      "     |      \n",
      "     |      Return the indices of the elements that are non-zero.\n",
      "     |      \n",
      "     |      Refer to `numpy.nonzero` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.nonzero : equivalent function\n",
      "     |  \n",
      "     |  partition(...)\n",
      "     |      a.partition(kth, axis=-1, kind='introselect', order=None)\n",
      "     |      \n",
      "     |      Rearranges the elements in the array in such a way that value of the\n",
      "     |      element in kth position is in the position it would be in a sorted array.\n",
      "     |      All elements smaller than the kth element are moved before this element and\n",
      "     |      all equal or greater are moved behind it. The ordering of the elements in\n",
      "     |      the two partitions is undefined.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.8.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      kth : int or sequence of ints\n",
      "     |          Element index to partition by. The kth element value will be in its\n",
      "     |          final sorted position and all smaller elements will be moved before it\n",
      "     |          and all equal or greater elements behind it.\n",
      "     |          The order all elements in the partitions is undefined.\n",
      "     |          If provided with a sequence of kth it will partition all elements\n",
      "     |          indexed by kth of them into their sorted position at once.\n",
      "     |      axis : int, optional\n",
      "     |          Axis along which to sort. Default is -1, which means sort along the\n",
      "     |          last axis.\n",
      "     |      kind : {'introselect'}, optional\n",
      "     |          Selection algorithm. Default is 'introselect'.\n",
      "     |      order : str or list of str, optional\n",
      "     |          When `a` is an array with fields defined, this argument specifies\n",
      "     |          which fields to compare first, second, etc.  A single field can\n",
      "     |          be specified as a string, and not all fields need be specified,\n",
      "     |          but unspecified fields will still be used, in the order in which\n",
      "     |          they come up in the dtype, to break ties.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.partition : Return a parititioned copy of an array.\n",
      "     |      argpartition : Indirect partition.\n",
      "     |      sort : Full sort.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See ``np.partition`` for notes on the different algorithms.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([3, 4, 2, 1])\n",
      "     |      >>> a.partition(3)\n",
      "     |      >>> a\n",
      "     |      array([2, 1, 3, 4])\n",
      "     |      \n",
      "     |      >>> a.partition((1, 3))\n",
      "     |      array([1, 2, 3, 4])\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      a.prod(axis=None, dtype=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Return the product of the array elements over the given axis\n",
      "     |      \n",
      "     |      Refer to `numpy.prod` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.prod : equivalent function\n",
      "     |  \n",
      "     |  ptp(...)\n",
      "     |      a.ptp(axis=None, out=None)\n",
      "     |      \n",
      "     |      Peak to peak (maximum - minimum) value along a given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.ptp` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ptp : equivalent function\n",
      "     |  \n",
      "     |  put(...)\n",
      "     |      a.put(indices, values, mode='raise')\n",
      "     |      \n",
      "     |      Set ``a.flat[n] = values[n]`` for all `n` in indices.\n",
      "     |      \n",
      "     |      Refer to `numpy.put` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.put : equivalent function\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      a.ravel([order])\n",
      "     |      \n",
      "     |      Return a flattened array.\n",
      "     |      \n",
      "     |      Refer to `numpy.ravel` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ravel : equivalent function\n",
      "     |      \n",
      "     |      ndarray.flat : a flat iterator on the array.\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      a.repeat(repeats, axis=None)\n",
      "     |      \n",
      "     |      Repeat elements of an array.\n",
      "     |      \n",
      "     |      Refer to `numpy.repeat` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.repeat : equivalent function\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      a.reshape(shape, order='C')\n",
      "     |      \n",
      "     |      Returns an array containing the same data with a new shape.\n",
      "     |      \n",
      "     |      Refer to `numpy.reshape` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.reshape : equivalent function\n",
      "     |  \n",
      "     |  resize(...)\n",
      "     |      a.resize(new_shape, refcheck=True)\n",
      "     |      \n",
      "     |      Change shape and size of array in-place.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      new_shape : tuple of ints, or `n` ints\n",
      "     |          Shape of resized array.\n",
      "     |      refcheck : bool, optional\n",
      "     |          If False, reference count will not be checked. Default is True.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If `a` does not own its own data or references or views to it exist,\n",
      "     |          and the data memory must be changed.\n",
      "     |          PyPy only: will always raise if the data memory must be changed, since\n",
      "     |          there is no reliable way to determine if references or views to it\n",
      "     |          exist.\n",
      "     |      \n",
      "     |      SystemError\n",
      "     |          If the `order` keyword argument is specified. This behaviour is a\n",
      "     |          bug in NumPy.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      resize : Return a new array with the specified shape.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This reallocates space for the data area if necessary.\n",
      "     |      \n",
      "     |      Only contiguous arrays (data elements consecutive in memory) can be\n",
      "     |      resized.\n",
      "     |      \n",
      "     |      The purpose of the reference count check is to make sure you\n",
      "     |      do not use this array as a buffer for another Python object and then\n",
      "     |      reallocate the memory. However, reference counts can increase in\n",
      "     |      other ways so if you are sure that you have not shared the memory\n",
      "     |      for this array with another Python object, then you may safely set\n",
      "     |      `refcheck` to False.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Shrinking an array: array is flattened (in the order that the data are\n",
      "     |      stored in memory), resized, and reshaped:\n",
      "     |      \n",
      "     |      >>> a = np.array([[0, 1], [2, 3]], order='C')\n",
      "     |      >>> a.resize((2, 1))\n",
      "     |      >>> a\n",
      "     |      array([[0],\n",
      "     |             [1]])\n",
      "     |      \n",
      "     |      >>> a = np.array([[0, 1], [2, 3]], order='F')\n",
      "     |      >>> a.resize((2, 1))\n",
      "     |      >>> a\n",
      "     |      array([[0],\n",
      "     |             [2]])\n",
      "     |      \n",
      "     |      Enlarging an array: as above, but missing entries are filled with zeros:\n",
      "     |      \n",
      "     |      >>> b = np.array([[0, 1], [2, 3]])\n",
      "     |      >>> b.resize(2, 3) # new_shape parameter doesn't have to be a tuple\n",
      "     |      >>> b\n",
      "     |      array([[0, 1, 2],\n",
      "     |             [3, 0, 0]])\n",
      "     |      \n",
      "     |      Referencing an array prevents resizing...\n",
      "     |      \n",
      "     |      >>> c = a\n",
      "     |      >>> a.resize((1, 1))\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: cannot resize an array that has been referenced ...\n",
      "     |      \n",
      "     |      Unless `refcheck` is False:\n",
      "     |      \n",
      "     |      >>> a.resize((1, 1), refcheck=False)\n",
      "     |      >>> a\n",
      "     |      array([[0]])\n",
      "     |      >>> c\n",
      "     |      array([[0]])\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      a.round(decimals=0, out=None)\n",
      "     |      \n",
      "     |      Return `a` with each element rounded to the given number of decimals.\n",
      "     |      \n",
      "     |      Refer to `numpy.around` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.around : equivalent function\n",
      "     |  \n",
      "     |  searchsorted(...)\n",
      "     |      a.searchsorted(v, side='left', sorter=None)\n",
      "     |      \n",
      "     |      Find indices where elements of v should be inserted in a to maintain order.\n",
      "     |      \n",
      "     |      For full documentation, see `numpy.searchsorted`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.searchsorted : equivalent function\n",
      "     |  \n",
      "     |  setfield(...)\n",
      "     |      a.setfield(val, dtype, offset=0)\n",
      "     |      \n",
      "     |      Put a value into a specified place in a field defined by a data-type.\n",
      "     |      \n",
      "     |      Place `val` into `a`'s field defined by `dtype` and beginning `offset`\n",
      "     |      bytes into the field.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      val : object\n",
      "     |          Value to be placed in field.\n",
      "     |      dtype : dtype object\n",
      "     |          Data-type of the field in which to place `val`.\n",
      "     |      offset : int, optional\n",
      "     |          The number of bytes into the field at which to place `val`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      None\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      getfield\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.eye(3)\n",
      "     |      >>> x.getfield(np.float64)\n",
      "     |      array([[ 1.,  0.,  0.],\n",
      "     |             [ 0.,  1.,  0.],\n",
      "     |             [ 0.,  0.,  1.]])\n",
      "     |      >>> x.setfield(3, np.int32)\n",
      "     |      >>> x.getfield(np.int32)\n",
      "     |      array([[3, 3, 3],\n",
      "     |             [3, 3, 3],\n",
      "     |             [3, 3, 3]])\n",
      "     |      >>> x\n",
      "     |      array([[  1.00000000e+000,   1.48219694e-323,   1.48219694e-323],\n",
      "     |             [  1.48219694e-323,   1.00000000e+000,   1.48219694e-323],\n",
      "     |             [  1.48219694e-323,   1.48219694e-323,   1.00000000e+000]])\n",
      "     |      >>> x.setfield(np.eye(3), np.int32)\n",
      "     |      >>> x\n",
      "     |      array([[ 1.,  0.,  0.],\n",
      "     |             [ 0.,  1.,  0.],\n",
      "     |             [ 0.,  0.,  1.]])\n",
      "     |  \n",
      "     |  setflags(...)\n",
      "     |      a.setflags(write=None, align=None, uic=None)\n",
      "     |      \n",
      "     |      Set array flags WRITEABLE, ALIGNED, and UPDATEIFCOPY, respectively.\n",
      "     |      \n",
      "     |      These Boolean-valued flags affect how numpy interprets the memory\n",
      "     |      area used by `a` (see Notes below). The ALIGNED flag can only\n",
      "     |      be set to True if the data is actually aligned according to the type.\n",
      "     |      The UPDATEIFCOPY flag can never be set to True. The flag WRITEABLE\n",
      "     |      can only be set to True if the array owns its own memory, or the\n",
      "     |      ultimate owner of the memory exposes a writeable buffer interface,\n",
      "     |      or is a string. (The exception for string is made so that unpickling\n",
      "     |      can be done without copying memory.)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      write : bool, optional\n",
      "     |          Describes whether or not `a` can be written to.\n",
      "     |      align : bool, optional\n",
      "     |          Describes whether or not `a` is aligned properly for its type.\n",
      "     |      uic : bool, optional\n",
      "     |          Describes whether or not `a` is a copy of another \"base\" array.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Array flags provide information about how the memory area used\n",
      "     |      for the array is to be interpreted. There are 6 Boolean flags\n",
      "     |      in use, only three of which can be changed by the user:\n",
      "     |      UPDATEIFCOPY, WRITEABLE, and ALIGNED.\n",
      "     |      \n",
      "     |      WRITEABLE (W) the data area can be written to;\n",
      "     |      \n",
      "     |      ALIGNED (A) the data and strides are aligned appropriately for the hardware\n",
      "     |      (as determined by the compiler);\n",
      "     |      \n",
      "     |      UPDATEIFCOPY (U) this array is a copy of some other array (referenced\n",
      "     |      by .base). When this array is deallocated, the base array will be\n",
      "     |      updated with the contents of this array.\n",
      "     |      \n",
      "     |      All flags can be accessed using their first (upper case) letter as well\n",
      "     |      as the full name.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> y\n",
      "     |      array([[3, 1, 7],\n",
      "     |             [2, 0, 0],\n",
      "     |             [8, 5, 9]])\n",
      "     |      >>> y.flags\n",
      "     |        C_CONTIGUOUS : True\n",
      "     |        F_CONTIGUOUS : False\n",
      "     |        OWNDATA : True\n",
      "     |        WRITEABLE : True\n",
      "     |        ALIGNED : True\n",
      "     |        UPDATEIFCOPY : False\n",
      "     |      >>> y.setflags(write=0, align=0)\n",
      "     |      >>> y.flags\n",
      "     |        C_CONTIGUOUS : True\n",
      "     |        F_CONTIGUOUS : False\n",
      "     |        OWNDATA : True\n",
      "     |        WRITEABLE : False\n",
      "     |        ALIGNED : False\n",
      "     |        UPDATEIFCOPY : False\n",
      "     |      >>> y.setflags(uic=1)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |      ValueError: cannot set UPDATEIFCOPY flag to True\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      a.sort(axis=-1, kind='quicksort', order=None)\n",
      "     |      \n",
      "     |      Sort an array, in-place.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional\n",
      "     |          Axis along which to sort. Default is -1, which means sort along the\n",
      "     |          last axis.\n",
      "     |      kind : {'quicksort', 'mergesort', 'heapsort'}, optional\n",
      "     |          Sorting algorithm. Default is 'quicksort'.\n",
      "     |      order : str or list of str, optional\n",
      "     |          When `a` is an array with fields defined, this argument specifies\n",
      "     |          which fields to compare first, second, etc.  A single field can\n",
      "     |          be specified as a string, and not all fields need be specified,\n",
      "     |          but unspecified fields will still be used, in the order in which\n",
      "     |          they come up in the dtype, to break ties.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.sort : Return a sorted copy of an array.\n",
      "     |      argsort : Indirect sort.\n",
      "     |      lexsort : Indirect stable sort on multiple keys.\n",
      "     |      searchsorted : Find elements in sorted array.\n",
      "     |      partition: Partial sort.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See ``sort`` for notes on the different sorting algorithms.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([[1,4], [3,1]])\n",
      "     |      >>> a.sort(axis=1)\n",
      "     |      >>> a\n",
      "     |      array([[1, 4],\n",
      "     |             [1, 3]])\n",
      "     |      >>> a.sort(axis=0)\n",
      "     |      >>> a\n",
      "     |      array([[1, 3],\n",
      "     |             [1, 4]])\n",
      "     |      \n",
      "     |      Use the `order` keyword to specify a field to use when sorting a\n",
      "     |      structured array:\n",
      "     |      \n",
      "     |      >>> a = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)])\n",
      "     |      >>> a.sort(order='y')\n",
      "     |      >>> a\n",
      "     |      array([('c', 1), ('a', 2)],\n",
      "     |            dtype=[('x', '|S1'), ('y', '<i4')])\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      a.squeeze(axis=None)\n",
      "     |      \n",
      "     |      Remove single-dimensional entries from the shape of `a`.\n",
      "     |      \n",
      "     |      Refer to `numpy.squeeze` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.squeeze : equivalent function\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      a.std(axis=None, dtype=None, out=None, ddof=0, keepdims=False)\n",
      "     |      \n",
      "     |      Returns the standard deviation of the array elements along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.std` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.std : equivalent function\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      a.sum(axis=None, dtype=None, out=None, keepdims=False)\n",
      "     |      \n",
      "     |      Return the sum of the array elements over the given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.sum` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.sum : equivalent function\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      a.swapaxes(axis1, axis2)\n",
      "     |      \n",
      "     |      Return a view of the array with `axis1` and `axis2` interchanged.\n",
      "     |      \n",
      "     |      Refer to `numpy.swapaxes` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.swapaxes : equivalent function\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      a.take(indices, axis=None, out=None, mode='raise')\n",
      "     |      \n",
      "     |      Return an array formed from the elements of `a` at the given indices.\n",
      "     |      \n",
      "     |      Refer to `numpy.take` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.take : equivalent function\n",
      "     |  \n",
      "     |  tobytes(...)\n",
      "     |      a.tobytes(order='C')\n",
      "     |      \n",
      "     |      Construct Python bytes containing the raw data bytes in the array.\n",
      "     |      \n",
      "     |      Constructs Python bytes showing a copy of the raw contents of\n",
      "     |      data memory. The bytes object can be produced in either 'C' or 'Fortran',\n",
      "     |      or 'Any' order (the default is 'C'-order). 'Any' order means C-order\n",
      "     |      unless the F_CONTIGUOUS flag in the array is set, in which case it\n",
      "     |      means 'Fortran' order.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.9.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : {'C', 'F', None}, optional\n",
      "     |          Order of the data for multidimensional arrays:\n",
      "     |          C, Fortran, or the same as for the original array.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      s : bytes\n",
      "     |          Python bytes exhibiting a copy of `a`'s raw data.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([[0, 1], [2, 3]])\n",
      "     |      >>> x.tobytes()\n",
      "     |      b'\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n",
      "     |      >>> x.tobytes('C') == x.tobytes()\n",
      "     |      True\n",
      "     |      >>> x.tobytes('F')\n",
      "     |      b'\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n",
      "     |  \n",
      "     |  tofile(...)\n",
      "     |      a.tofile(fid, sep=\"\", format=\"%s\")\n",
      "     |      \n",
      "     |      Write array to a file as text or binary (default).\n",
      "     |      \n",
      "     |      Data is always written in 'C' order, independent of the order of `a`.\n",
      "     |      The data produced by this method can be recovered using the function\n",
      "     |      fromfile().\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fid : file or str\n",
      "     |          An open file object, or a string containing a filename.\n",
      "     |      sep : str\n",
      "     |          Separator between array items for text output.\n",
      "     |          If \"\" (empty), a binary file is written, equivalent to\n",
      "     |          ``file.write(a.tobytes())``.\n",
      "     |      format : str\n",
      "     |          Format string for text file output.\n",
      "     |          Each entry in the array is formatted to text by first converting\n",
      "     |          it to the closest Python type, and then using \"format\" % item.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a convenience function for quick storage of array data.\n",
      "     |      Information on endianness and precision is lost, so this method is not a\n",
      "     |      good choice for files intended to archive data or transport data between\n",
      "     |      machines with different endianness. Some of these problems can be overcome\n",
      "     |      by outputting the data as text files, at the expense of speed and file\n",
      "     |      size.\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      a.tolist()\n",
      "     |      \n",
      "     |      Return the array as a (possibly nested) list.\n",
      "     |      \n",
      "     |      Return a copy of the array data as a (nested) Python list.\n",
      "     |      Data items are converted to the nearest compatible Python type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      none\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : list\n",
      "     |          The possibly nested list of array elements.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The array may be recreated, ``a = np.array(a.tolist())``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([1, 2])\n",
      "     |      >>> a.tolist()\n",
      "     |      [1, 2]\n",
      "     |      >>> a = np.array([[1, 2], [3, 4]])\n",
      "     |      >>> list(a)\n",
      "     |      [array([1, 2]), array([3, 4])]\n",
      "     |      >>> a.tolist()\n",
      "     |      [[1, 2], [3, 4]]\n",
      "     |  \n",
      "     |  tostring(...)\n",
      "     |      a.tostring(order='C')\n",
      "     |      \n",
      "     |      Construct Python bytes containing the raw data bytes in the array.\n",
      "     |      \n",
      "     |      Constructs Python bytes showing a copy of the raw contents of\n",
      "     |      data memory. The bytes object can be produced in either 'C' or 'Fortran',\n",
      "     |      or 'Any' order (the default is 'C'-order). 'Any' order means C-order\n",
      "     |      unless the F_CONTIGUOUS flag in the array is set, in which case it\n",
      "     |      means 'Fortran' order.\n",
      "     |      \n",
      "     |      This function is a compatibility alias for tobytes. Despite its name it returns bytes not strings.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      order : {'C', 'F', None}, optional\n",
      "     |          Order of the data for multidimensional arrays:\n",
      "     |          C, Fortran, or the same as for the original array.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      s : bytes\n",
      "     |          Python bytes exhibiting a copy of `a`'s raw data.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([[0, 1], [2, 3]])\n",
      "     |      >>> x.tobytes()\n",
      "     |      b'\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n",
      "     |      >>> x.tobytes('C') == x.tobytes()\n",
      "     |      True\n",
      "     |      >>> x.tobytes('F')\n",
      "     |      b'\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      a.trace(offset=0, axis1=0, axis2=1, dtype=None, out=None)\n",
      "     |      \n",
      "     |      Return the sum along diagonals of the array.\n",
      "     |      \n",
      "     |      Refer to `numpy.trace` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.trace : equivalent function\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      a.transpose(*axes)\n",
      "     |      \n",
      "     |      Returns a view of the array with axes transposed.\n",
      "     |      \n",
      "     |      For a 1-D array, this has no effect. (To change between column and\n",
      "     |      row vectors, first cast the 1-D array into a matrix object.)\n",
      "     |      For a 2-D array, this is the usual matrix transpose.\n",
      "     |      For an n-D array, if axes are given, their order indicates how the\n",
      "     |      axes are permuted (see Examples). If axes are not provided and\n",
      "     |      ``a.shape = (i[0], i[1], ... i[n-2], i[n-1])``, then\n",
      "     |      ``a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axes : None, tuple of ints, or `n` ints\n",
      "     |      \n",
      "     |       * None or no argument: reverses the order of the axes.\n",
      "     |      \n",
      "     |       * tuple of ints: `i` in the `j`-th place in the tuple means `a`'s\n",
      "     |         `i`-th axis becomes `a.transpose()`'s `j`-th axis.\n",
      "     |      \n",
      "     |       * `n` ints: same as an n-tuple of the same ints (this form is\n",
      "     |         intended simply as a \"convenience\" alternative to the tuple form)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          View of `a`, with axes suitably permuted.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      ndarray.T : Array property returning the array transposed.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> a = np.array([[1, 2], [3, 4]])\n",
      "     |      >>> a\n",
      "     |      array([[1, 2],\n",
      "     |             [3, 4]])\n",
      "     |      >>> a.transpose()\n",
      "     |      array([[1, 3],\n",
      "     |             [2, 4]])\n",
      "     |      >>> a.transpose((1, 0))\n",
      "     |      array([[1, 3],\n",
      "     |             [2, 4]])\n",
      "     |      >>> a.transpose(1, 0)\n",
      "     |      array([[1, 3],\n",
      "     |             [2, 4]])\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      a.var(axis=None, dtype=None, out=None, ddof=0, keepdims=False)\n",
      "     |      \n",
      "     |      Returns the variance of the array elements, along given axis.\n",
      "     |      \n",
      "     |      Refer to `numpy.var` for full documentation.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.var : equivalent function\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      a.view(dtype=None, type=None)\n",
      "     |      \n",
      "     |      New view of array with the same data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : data-type or ndarray sub-class, optional\n",
      "     |          Data-type descriptor of the returned view, e.g., float32 or int16. The\n",
      "     |          default, None, results in the view having the same data-type as `a`.\n",
      "     |          This argument can also be specified as an ndarray sub-class, which\n",
      "     |          then specifies the type of the returned object (this is equivalent to\n",
      "     |          setting the ``type`` parameter).\n",
      "     |      type : Python type, optional\n",
      "     |          Type of the returned view, e.g., ndarray or matrix.  Again, the\n",
      "     |          default None results in type preservation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      ``a.view()`` is used two different ways:\n",
      "     |      \n",
      "     |      ``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view\n",
      "     |      of the array's memory with a different data-type.  This can cause a\n",
      "     |      reinterpretation of the bytes of memory.\n",
      "     |      \n",
      "     |      ``a.view(ndarray_subclass)`` or ``a.view(type=ndarray_subclass)`` just\n",
      "     |      returns an instance of `ndarray_subclass` that looks at the same array\n",
      "     |      (same shape, dtype, etc.)  This does not cause a reinterpretation of the\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      For ``a.view(some_dtype)``, if ``some_dtype`` has a different number of\n",
      "     |      bytes per entry than the previous dtype (for example, converting a\n",
      "     |      regular array to a structured array), then the behavior of the view\n",
      "     |      cannot be predicted just from the superficial appearance of ``a`` (shown\n",
      "     |      by ``print(a)``). It also depends on exactly how ``a`` is stored in\n",
      "     |      memory. Therefore if ``a`` is C-ordered versus fortran-ordered, versus\n",
      "     |      defined as a slice or transpose, etc., the view may give different\n",
      "     |      results.\n",
      "     |      \n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([(1, 2)], dtype=[('a', np.int8), ('b', np.int8)])\n",
      "     |      \n",
      "     |      Viewing array data using a different type and dtype:\n",
      "     |      \n",
      "     |      >>> y = x.view(dtype=np.int16, type=np.matrix)\n",
      "     |      >>> y\n",
      "     |      matrix([[513]], dtype=int16)\n",
      "     |      >>> print(type(y))\n",
      "     |      <class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "     |      \n",
      "     |      Creating a view on a structured array so it can be used in calculations\n",
      "     |      \n",
      "     |      >>> x = np.array([(1, 2),(3,4)], dtype=[('a', np.int8), ('b', np.int8)])\n",
      "     |      >>> xv = x.view(dtype=np.int8).reshape(-1,2)\n",
      "     |      >>> xv\n",
      "     |      array([[1, 2],\n",
      "     |             [3, 4]], dtype=int8)\n",
      "     |      >>> xv.mean(0)\n",
      "     |      array([ 2.,  3.])\n",
      "     |      \n",
      "     |      Making changes to the view changes the underlying array\n",
      "     |      \n",
      "     |      >>> xv[0,1] = 20\n",
      "     |      >>> print(x)\n",
      "     |      [(1, 20) (3, 4)]\n",
      "     |      \n",
      "     |      Using a view to convert an array to a recarray:\n",
      "     |      \n",
      "     |      >>> z = x.view(np.recarray)\n",
      "     |      >>> z.a\n",
      "     |      array([1], dtype=int8)\n",
      "     |      \n",
      "     |      Views share data:\n",
      "     |      \n",
      "     |      >>> x[0] = (9, 10)\n",
      "     |      >>> z[0]\n",
      "     |      (9, 10)\n",
      "     |      \n",
      "     |      Views that change the dtype size (bytes per entry) should normally be\n",
      "     |      avoided on arrays defined by slices, transposes, fortran-ordering, etc.:\n",
      "     |      \n",
      "     |      >>> x = np.array([[1,2,3],[4,5,6]], dtype=np.int16)\n",
      "     |      >>> y = x[:, 0:2]\n",
      "     |      >>> y\n",
      "     |      array([[1, 2],\n",
      "     |             [4, 5]], dtype=int16)\n",
      "     |      >>> y.view(dtype=[('width', np.int16), ('length', np.int16)])\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |      ValueError: new type not compatible with array.\n",
      "     |      >>> z = y.copy()\n",
      "     |      >>> z.view(dtype=[('width', np.int16), ('length', np.int16)])\n",
      "     |      array([[(1, 2)],\n",
      "     |             [(4, 5)]], dtype=[('width', '<i2'), ('length', '<i2')])\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from numpy.ndarray:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Same as self.transpose(), except that self is returned if\n",
      "     |      self.ndim < 2.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([[1.,2.],[3.,4.]])\n",
      "     |      >>> x\n",
      "     |      array([[ 1.,  2.],\n",
      "     |             [ 3.,  4.]])\n",
      "     |      >>> x.T\n",
      "     |      array([[ 1.,  3.],\n",
      "     |             [ 2.,  4.]])\n",
      "     |      >>> x = np.array([1.,2.,3.,4.])\n",
      "     |      >>> x\n",
      "     |      array([ 1.,  2.,  3.,  4.])\n",
      "     |      >>> x.T\n",
      "     |      array([ 1.,  2.,  3.,  4.])\n",
      "     |  \n",
      "     |  __array_interface__\n",
      "     |      Array protocol: Python side.\n",
      "     |  \n",
      "     |  __array_priority__\n",
      "     |      Array priority.\n",
      "     |  \n",
      "     |  __array_struct__\n",
      "     |      Array protocol: C-struct side.\n",
      "     |  \n",
      "     |  base\n",
      "     |      Base object if memory is from some other object.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      The base of an array that owns its memory is None:\n",
      "     |      \n",
      "     |      >>> x = np.array([1,2,3,4])\n",
      "     |      >>> x.base is None\n",
      "     |      True\n",
      "     |      \n",
      "     |      Slicing creates a view, whose memory is shared with x:\n",
      "     |      \n",
      "     |      >>> y = x[2:]\n",
      "     |      >>> y.base is x\n",
      "     |      True\n",
      "     |  \n",
      "     |  ctypes\n",
      "     |      An object to simplify the interaction of the array with the ctypes\n",
      "     |      module.\n",
      "     |      \n",
      "     |      This attribute creates an object that makes it easier to use arrays\n",
      "     |      when calling shared libraries with the ctypes module. The returned\n",
      "     |      object has, among others, data, shape, and strides attributes (see\n",
      "     |      Notes below) which themselves return ctypes objects that can be used\n",
      "     |      as arguments to a shared library.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      c : Python object\n",
      "     |          Possessing attributes data, shape, strides, etc.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.ctypeslib\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Below are the public attributes of this object which were documented\n",
      "     |      in \"Guide to NumPy\" (we have omitted undocumented public attributes,\n",
      "     |      as well as documented private attributes):\n",
      "     |      \n",
      "     |      * data: A pointer to the memory area of the array as a Python integer.\n",
      "     |        This memory area may contain data that is not aligned, or not in correct\n",
      "     |        byte-order. The memory area may not even be writeable. The array\n",
      "     |        flags and data-type of this array should be respected when passing this\n",
      "     |        attribute to arbitrary C-code to avoid trouble that can include Python\n",
      "     |        crashing. User Beware! The value of this attribute is exactly the same\n",
      "     |        as self._array_interface_['data'][0].\n",
      "     |      \n",
      "     |      * shape (c_intp*self.ndim): A ctypes array of length self.ndim where\n",
      "     |        the basetype is the C-integer corresponding to dtype('p') on this\n",
      "     |        platform. This base-type could be c_int, c_long, or c_longlong\n",
      "     |        depending on the platform. The c_intp type is defined accordingly in\n",
      "     |        numpy.ctypeslib. The ctypes array contains the shape of the underlying\n",
      "     |        array.\n",
      "     |      \n",
      "     |      * strides (c_intp*self.ndim): A ctypes array of length self.ndim where\n",
      "     |        the basetype is the same as for the shape attribute. This ctypes array\n",
      "     |        contains the strides information from the underlying array. This strides\n",
      "     |        information is important for showing how many bytes must be jumped to\n",
      "     |        get to the next element in the array.\n",
      "     |      \n",
      "     |      * data_as(obj): Return the data pointer cast to a particular c-types object.\n",
      "     |        For example, calling self._as_parameter_ is equivalent to\n",
      "     |        self.data_as(ctypes.c_void_p). Perhaps you want to use the data as a\n",
      "     |        pointer to a ctypes array of floating-point data:\n",
      "     |        self.data_as(ctypes.POINTER(ctypes.c_double)).\n",
      "     |      \n",
      "     |      * shape_as(obj): Return the shape tuple as an array of some other c-types\n",
      "     |        type. For example: self.shape_as(ctypes.c_short).\n",
      "     |      \n",
      "     |      * strides_as(obj): Return the strides tuple as an array of some other\n",
      "     |        c-types type. For example: self.strides_as(ctypes.c_longlong).\n",
      "     |      \n",
      "     |      Be careful using the ctypes attribute - especially on temporary\n",
      "     |      arrays or arrays constructed on the fly. For example, calling\n",
      "     |      ``(a+b).ctypes.data_as(ctypes.c_void_p)`` returns a pointer to memory\n",
      "     |      that is invalid because the array created as (a+b) is deallocated\n",
      "     |      before the next Python statement. You can avoid this problem using\n",
      "     |      either ``c=a+b`` or ``ct=(a+b).ctypes``. In the latter case, ct will\n",
      "     |      hold a reference to the array until ct is deleted or re-assigned.\n",
      "     |      \n",
      "     |      If the ctypes module is not available, then the ctypes attribute\n",
      "     |      of array objects still returns something useful, but ctypes objects\n",
      "     |      are not returned and errors may be raised instead. In particular,\n",
      "     |      the object will still have the as parameter attribute which will\n",
      "     |      return an integer equal to the data attribute.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import ctypes\n",
      "     |      >>> x\n",
      "     |      array([[0, 1],\n",
      "     |             [2, 3]])\n",
      "     |      >>> x.ctypes.data\n",
      "     |      30439712\n",
      "     |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_long))\n",
      "     |      <ctypes.LP_c_long object at 0x01F01300>\n",
      "     |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_long)).contents\n",
      "     |      c_long(0)\n",
      "     |      >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_longlong)).contents\n",
      "     |      c_longlong(4294967296L)\n",
      "     |      >>> x.ctypes.shape\n",
      "     |      <numpy.core._internal.c_long_Array_2 object at 0x01FFD580>\n",
      "     |      >>> x.ctypes.shape_as(ctypes.c_long)\n",
      "     |      <numpy.core._internal.c_long_Array_2 object at 0x01FCE620>\n",
      "     |      >>> x.ctypes.strides\n",
      "     |      <numpy.core._internal.c_long_Array_2 object at 0x01FCE620>\n",
      "     |      >>> x.ctypes.strides_as(ctypes.c_longlong)\n",
      "     |      <numpy.core._internal.c_longlong_Array_2 object at 0x01F01300>\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Data-type of the array's elements.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      d : numpy dtype object\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.dtype\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x\n",
      "     |      array([[0, 1],\n",
      "     |             [2, 3]])\n",
      "     |      >>> x.dtype\n",
      "     |      dtype('int32')\n",
      "     |      >>> type(x.dtype)\n",
      "     |      <type 'numpy.dtype'>\n",
      "     |  \n",
      "     |  flags\n",
      "     |      Information about the memory layout of the array.\n",
      "     |      \n",
      "     |      Attributes\n",
      "     |      ----------\n",
      "     |      C_CONTIGUOUS (C)\n",
      "     |          The data is in a single, C-style contiguous segment.\n",
      "     |      F_CONTIGUOUS (F)\n",
      "     |          The data is in a single, Fortran-style contiguous segment.\n",
      "     |      OWNDATA (O)\n",
      "     |          The array owns the memory it uses or borrows it from another object.\n",
      "     |      WRITEABLE (W)\n",
      "     |          The data area can be written to.  Setting this to False locks\n",
      "     |          the data, making it read-only.  A view (slice, etc.) inherits WRITEABLE\n",
      "     |          from its base array at creation time, but a view of a writeable\n",
      "     |          array may be subsequently locked while the base array remains writeable.\n",
      "     |          (The opposite is not true, in that a view of a locked array may not\n",
      "     |          be made writeable.  However, currently, locking a base object does not\n",
      "     |          lock any views that already reference it, so under that circumstance it\n",
      "     |          is possible to alter the contents of a locked array via a previously\n",
      "     |          created writeable view onto it.)  Attempting to change a non-writeable\n",
      "     |          array raises a RuntimeError exception.\n",
      "     |      ALIGNED (A)\n",
      "     |          The data and all elements are aligned appropriately for the hardware.\n",
      "     |      UPDATEIFCOPY (U)\n",
      "     |          This array is a copy of some other array. When this array is\n",
      "     |          deallocated, the base array will be updated with the contents of\n",
      "     |          this array.\n",
      "     |      FNC\n",
      "     |          F_CONTIGUOUS and not C_CONTIGUOUS.\n",
      "     |      FORC\n",
      "     |          F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n",
      "     |      BEHAVED (B)\n",
      "     |          ALIGNED and WRITEABLE.\n",
      "     |      CARRAY (CA)\n",
      "     |          BEHAVED and C_CONTIGUOUS.\n",
      "     |      FARRAY (FA)\n",
      "     |          BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The `flags` object can be accessed dictionary-like (as in ``a.flags['WRITEABLE']``),\n",
      "     |      or by using lowercased attribute names (as in ``a.flags.writeable``). Short flag\n",
      "     |      names are only supported in dictionary access.\n",
      "     |      \n",
      "     |      Only the UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be changed by\n",
      "     |      the user, via direct assignment to the attribute or dictionary entry,\n",
      "     |      or by calling `ndarray.setflags`.\n",
      "     |      \n",
      "     |      The array flags cannot be set arbitrarily:\n",
      "     |      \n",
      "     |      - UPDATEIFCOPY can only be set ``False``.\n",
      "     |      - ALIGNED can only be set ``True`` if the data is truly aligned.\n",
      "     |      - WRITEABLE can only be set ``True`` if the array owns its own memory\n",
      "     |        or the ultimate owner of the memory exposes a writeable buffer\n",
      "     |        interface or is a string.\n",
      "     |      \n",
      "     |      Arrays can be both C-style and Fortran-style contiguous simultaneously.\n",
      "     |      This is clear for 1-dimensional arrays, but can also be true for higher\n",
      "     |      dimensional arrays.\n",
      "     |      \n",
      "     |      Even for contiguous arrays a stride for a given dimension\n",
      "     |      ``arr.strides[dim]`` may be *arbitrary* if ``arr.shape[dim] == 1``\n",
      "     |      or the array has no elements.\n",
      "     |      It does *not* generally hold that ``self.strides[-1] == self.itemsize``\n",
      "     |      for C-style contiguous arrays or ``self.strides[0] == self.itemsize`` for\n",
      "     |      Fortran-style contiguous arrays is true.\n",
      "     |  \n",
      "     |  flat\n",
      "     |      A 1-D iterator over the array.\n",
      "     |      \n",
      "     |      This is a `numpy.flatiter` instance, which acts similarly to, but is not\n",
      "     |      a subclass of, Python's built-in iterator object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      flatten : Return a copy of the array collapsed into one dimension.\n",
      "     |      \n",
      "     |      flatiter\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.arange(1, 7).reshape(2, 3)\n",
      "     |      >>> x\n",
      "     |      array([[1, 2, 3],\n",
      "     |             [4, 5, 6]])\n",
      "     |      >>> x.flat[3]\n",
      "     |      4\n",
      "     |      >>> x.T\n",
      "     |      array([[1, 4],\n",
      "     |             [2, 5],\n",
      "     |             [3, 6]])\n",
      "     |      >>> x.T.flat[3]\n",
      "     |      5\n",
      "     |      >>> type(x.flat)\n",
      "     |      <type 'numpy.flatiter'>\n",
      "     |      \n",
      "     |      An assignment example:\n",
      "     |      \n",
      "     |      >>> x.flat = 3; x\n",
      "     |      array([[3, 3, 3],\n",
      "     |             [3, 3, 3]])\n",
      "     |      >>> x.flat[[1,4]] = 1; x\n",
      "     |      array([[3, 1, 3],\n",
      "     |             [3, 1, 3]])\n",
      "     |  \n",
      "     |  imag\n",
      "     |      The imaginary part of the array.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.sqrt([1+0j, 0+1j])\n",
      "     |      >>> x.imag\n",
      "     |      array([ 0.        ,  0.70710678])\n",
      "     |      >>> x.imag.dtype\n",
      "     |      dtype('float64')\n",
      "     |  \n",
      "     |  itemsize\n",
      "     |      Length of one array element in bytes.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1,2,3], dtype=np.float64)\n",
      "     |      >>> x.itemsize\n",
      "     |      8\n",
      "     |      >>> x = np.array([1,2,3], dtype=np.complex128)\n",
      "     |      >>> x.itemsize\n",
      "     |      16\n",
      "     |  \n",
      "     |  nbytes\n",
      "     |      Total bytes consumed by the elements of the array.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Does not include memory consumed by non-element attributes of the\n",
      "     |      array object.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.zeros((3,5,2), dtype=np.complex128)\n",
      "     |      >>> x.nbytes\n",
      "     |      480\n",
      "     |      >>> np.prod(x.shape) * x.itemsize\n",
      "     |      480\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Number of array dimensions.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1, 2, 3])\n",
      "     |      >>> x.ndim\n",
      "     |      1\n",
      "     |      >>> y = np.zeros((2, 3, 4))\n",
      "     |      >>> y.ndim\n",
      "     |      3\n",
      "     |  \n",
      "     |  real\n",
      "     |      The real part of the array.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.sqrt([1+0j, 0+1j])\n",
      "     |      >>> x.real\n",
      "     |      array([ 1.        ,  0.70710678])\n",
      "     |      >>> x.real.dtype\n",
      "     |      dtype('float64')\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.real : equivalent function\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Tuple of array dimensions.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      May be used to \"reshape\" the array, as long as this would not\n",
      "     |      require a change in the total number of elements\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.array([1, 2, 3, 4])\n",
      "     |      >>> x.shape\n",
      "     |      (4,)\n",
      "     |      >>> y = np.zeros((2, 3, 4))\n",
      "     |      >>> y.shape\n",
      "     |      (2, 3, 4)\n",
      "     |      >>> y.shape = (3, 8)\n",
      "     |      >>> y\n",
      "     |      array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "     |             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "     |             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "     |      >>> y.shape = (3, 6)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |      ValueError: total size of new array must be unchanged\n",
      "     |  \n",
      "     |  size\n",
      "     |      Number of elements in the array.\n",
      "     |      \n",
      "     |      Equivalent to ``np.prod(a.shape)``, i.e., the product of the array's\n",
      "     |      dimensions.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> x = np.zeros((3, 5, 2), dtype=np.complex128)\n",
      "     |      >>> x.size\n",
      "     |      30\n",
      "     |      >>> np.prod(x.shape)\n",
      "     |      30\n",
      "     |  \n",
      "     |  strides\n",
      "     |      Tuple of bytes to step in each dimension when traversing an array.\n",
      "     |      \n",
      "     |      The byte offset of element ``(i[0], i[1], ..., i[n])`` in an array `a`\n",
      "     |      is::\n",
      "     |      \n",
      "     |          offset = sum(np.array(i) * a.strides)\n",
      "     |      \n",
      "     |      A more detailed explanation of strides can be found in the\n",
      "     |      \"ndarray.rst\" file in the NumPy reference guide.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Imagine an array of 32-bit integers (each 4 bytes)::\n",
      "     |      \n",
      "     |        x = np.array([[0, 1, 2, 3, 4],\n",
      "     |                      [5, 6, 7, 8, 9]], dtype=np.int32)\n",
      "     |      \n",
      "     |      This array is stored in memory as 40 bytes, one after the other\n",
      "     |      (known as a contiguous block of memory).  The strides of an array tell\n",
      "     |      us how many bytes we have to skip in memory to move to the next position\n",
      "     |      along a certain axis.  For example, we have to skip 4 bytes (1 value) to\n",
      "     |      move to the next column, but 20 bytes (5 values) to get to the same\n",
      "     |      position in the next row.  As such, the strides for the array `x` will be\n",
      "     |      ``(20, 4)``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.lib.stride_tricks.as_strided\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> y = np.reshape(np.arange(2*3*4), (2,3,4))\n",
      "     |      >>> y\n",
      "     |      array([[[ 0,  1,  2,  3],\n",
      "     |              [ 4,  5,  6,  7],\n",
      "     |              [ 8,  9, 10, 11]],\n",
      "     |             [[12, 13, 14, 15],\n",
      "     |              [16, 17, 18, 19],\n",
      "     |              [20, 21, 22, 23]]])\n",
      "     |      >>> y.strides\n",
      "     |      (48, 16, 4)\n",
      "     |      >>> y[1,1,1]\n",
      "     |      17\n",
      "     |      >>> offset=sum(y.strides * np.array((1,1,1)))\n",
      "     |      >>> offset/y.itemsize\n",
      "     |      17\n",
      "     |      \n",
      "     |      >>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0)\n",
      "     |      >>> x.strides\n",
      "     |      (32, 4, 224, 1344)\n",
      "     |      >>> i = np.array([3,5,2,2])\n",
      "     |      >>> offset = sum(i * x.strides)\n",
      "     |      >>> x[3,5,2,2]\n",
      "     |      813\n",
      "     |      >>> offset / x.itemsize\n",
      "     |      813\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from numpy.ndarray:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class GroupsHDU(astropy.io.fits.hdu.image.PrimaryHDU, astropy.io.fits.hdu.table._TableLikeHDU)\n",
      "     |  FITS Random Groups HDU class.\n",
      "     |  \n",
      "     |  See the :ref:`random-groups` section in the PyFITS documentation for more\n",
      "     |  details on working with this type of HDU.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GroupsHDU\n",
      "     |      astropy.io.fits.hdu.image.PrimaryHDU\n",
      "     |      astropy.io.fits.hdu.image._ImageBaseHDU\n",
      "     |      astropy.io.fits.hdu.table._TableLikeHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None)\n",
      "     |      Construct a primary HDU.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array or DELAYED, optional\n",
      "     |          The data in the HDU.\n",
      "     |      \n",
      "     |      header : Header instance, optional\n",
      "     |          The header to be used (as a template).  If ``header`` is `None`, a\n",
      "     |          minimal header will be provided.\n",
      "     |      \n",
      "     |      do_not_scale_image_data : bool, optional\n",
      "     |          If `True`, image data is not scaled using BSCALE/BZERO values\n",
      "     |          when read. (default: False)\n",
      "     |      \n",
      "     |      ignore_blank : bool, optional\n",
      "     |          If `True`, the BLANK header keyword will be ignored if present.\n",
      "     |          Otherwise, pixels equal to this value will be replaced with\n",
      "     |          NaNs. (default: False)\n",
      "     |      \n",
      "     |      uint : bool, optional\n",
      "     |          Interpret signed integer data where ``BZERO`` is the\n",
      "     |          central value and ``BSCALE == 1`` as unsigned integer\n",
      "     |          data.  For example, ``int16`` data with ``BZERO = 32768``\n",
      "     |          and ``BSCALE = 1`` would be treated as ``uint16`` data.\n",
      "     |          (default: True)\n",
      "     |      \n",
      "     |      scale_back : bool, optional\n",
      "     |          If `True`, when saving changes to a file that contained scaled\n",
      "     |          image data, restore the data to the original type and reapply the\n",
      "     |          original BSCALE/BZERO values.  This could lead to loss of accuracy\n",
      "     |          if scaling back to integer values after performing floating point\n",
      "     |          operations on the data.  Pseudo-unsigned integers are automatically\n",
      "     |          rescaled unless scale_back is explicitly set to `False`.\n",
      "     |          (default: None)\n",
      "     |  \n",
      "     |  update_header(self)\n",
      "     |      Update the header keywords to agree with the data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      _ImageBaseHDU is sort of an abstract class for HDUs containing image\n",
      "     |      data (as opposed to table data) and should never be used directly.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      The :class:`ColDefs` objects describing the columns in this table.\n",
      "     |  \n",
      "     |  data\n",
      "     |      The data of a random group FITS file will be like a binary table's\n",
      "     |      data.\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  parnames\n",
      "     |      The names of the group parameters as described by the header.\n",
      "     |  \n",
      "     |  size\n",
      "     |      Returns the size (in bytes) of the HDU's data part.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.image._ImageBaseHDU:\n",
      "     |  \n",
      "     |  scale(self, type=None, option='old', bscale=None, bzero=None)\n",
      "     |      Scale image data by using ``BSCALE``/``BZERO``.\n",
      "     |      \n",
      "     |      Call to this method will scale `data` and update the keywords of\n",
      "     |      ``BSCALE`` and ``BZERO`` in the HDU's header.  This method should only\n",
      "     |      be used right before writing to the output file, as the data will be\n",
      "     |      scaled and is therefore not very usable after the call.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      type : str, optional\n",
      "     |          destination data type, use a string representing a numpy\n",
      "     |          dtype name, (e.g. ``'uint8'``, ``'int16'``, ``'float32'``\n",
      "     |          etc.).  If is `None`, use the current data type.\n",
      "     |      \n",
      "     |      option : str, optional\n",
      "     |          How to scale the data: ``\"old\"`` uses the original ``BSCALE`` and\n",
      "     |          ``BZERO`` values from when the data was read/created (defaulting to\n",
      "     |          1 and 0 if they don't exist). For integer data only, ``\"minmax\"``\n",
      "     |          uses the minimum and maximum of the data to scale. User-specified\n",
      "     |          ``bscale``/``bzero`` values always take precedence.\n",
      "     |      \n",
      "     |      bscale, bzero : int, optional\n",
      "     |          User-specified ``BSCALE`` and ``BZERO`` values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.image._ImageBaseHDU:\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  section\n",
      "     |      Access a section of the image array without loading the entire array\n",
      "     |      into memory.  The :class:`Section` object returned by this attribute is\n",
      "     |      not meant to be used directly by itself.  Rather, slices of the section\n",
      "     |      return the appropriate slice of the data, and loads *only* that section\n",
      "     |      into memory.\n",
      "     |      \n",
      "     |      Sections are mostly obsoleted by memmap support, but should still be\n",
      "     |      used to deal with very large scaled images.  See the\n",
      "     |      :ref:`data-sections` section of the PyFITS documentation for more\n",
      "     |      details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Shape of the image array--should be equivalent to ``self.data.shape``.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from astropy.io.fits.hdu.image._ImageBaseHDU:\n",
      "     |  \n",
      "     |  standard_keyword_comments = {'BITPIX': 'array data type', 'GCOUNT': 'n...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.table._TableLikeHDU:\n",
      "     |  \n",
      "     |  from_columns(columns, header=None, nrows=0, fill=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Given either a `ColDefs` object, a sequence of `Column` objects,\n",
      "     |      or another table HDU or table data (a `FITS_rec` or multi-field\n",
      "     |      `numpy.ndarray` or `numpy.recarray` object, return a new table HDU of\n",
      "     |      the class this method was called on using the column definition from\n",
      "     |      the input.\n",
      "     |      \n",
      "     |      See also `FITS_rec.from_columns`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns : sequence of `Column`, `ColDefs`, or other\n",
      "     |          The columns from which to create the table data, or an object with\n",
      "     |          a column-like structure from which a `ColDefs` can be instantiated.\n",
      "     |          This includes an existing `BinTableHDU` or `TableHDU`, or a\n",
      "     |          `numpy.recarray` to give some examples.\n",
      "     |      \n",
      "     |          If these columns have data arrays attached that data may be used in\n",
      "     |          initializing the new table.  Otherwise the input columns will be\n",
      "     |          used as a template for a new table with the requested number of\n",
      "     |          rows.\n",
      "     |      \n",
      "     |      header : `Header`\n",
      "     |          An optional `Header` object to instantiate the new HDU yet.  Header\n",
      "     |          keywords specifically related to defining the table structure (such\n",
      "     |          as the \"TXXXn\" keywords like TTYPEn) will be overridden by the\n",
      "     |          supplied column definitions, but all other informational and data\n",
      "     |          model-specific keywords are kept.\n",
      "     |      \n",
      "     |      nrows : int\n",
      "     |          Number of rows in the new table.  If the input columns have data\n",
      "     |          associated with them, the size of the largest input column is used.\n",
      "     |          Otherwise the default is 0.\n",
      "     |      \n",
      "     |      fill : bool\n",
      "     |          If `True`, will fill all cells with zeros or blanks.  If `False`,\n",
      "     |          copy the data from input, undefined cells will still be filled with\n",
      "     |          zeros/blanks.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      Any additional keyword arguments accepted by the HDU class's\n",
      "     |      ``__init__`` may also be passed in as keyword arguments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, blocking='standard', checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, blocking='standard', datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Write the HDU to a new file. This is a convenience method to\n",
      "     |      provide a user easier output interface if only one HDU needs\n",
      "     |      to be written to a file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : file path, file object or file-like object\n",
      "     |          Output FITS file.  If the file object is already opened, it must\n",
      "     |          be opened in a writeable mode.\n",
      "     |      \n",
      "     |      output_verify : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      overwrite : bool, optional\n",
      "     |          If ``True``, overwrite the output file if it exists. Raises an\n",
      "     |          ``OSError`` (``IOError`` for Python 2) if ``False`` and the\n",
      "     |          output file exists. Default is ``False``.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.3\n",
      "     |             ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards\n",
      "     |          to the header of the HDU when written to the file.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file object or file-like object\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __new__(cls, data=None, header=None, *args, **kwargs)\n",
      "     |      Iterates through the subclasses of _BaseHDU and uses that class's\n",
      "     |      match_header() method to determine which subclass to instantiate.\n",
      "     |      \n",
      "     |      It's important to be aware that the class hierarchy is traversed in a\n",
      "     |      depth-last order.  Each match_header() should identify an HDU type as\n",
      "     |      uniquely as possible.  Abstract types may choose to simply return False\n",
      "     |      or raise NotImplementedError to be skipped.\n",
      "     |      \n",
      "     |      If any unexpected exceptions are raised while evaluating\n",
      "     |      match_header(), the type is taken to be _CorruptedHDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class HDUList(builtins.list, astropy.io.fits.verify._Verify)\n",
      "     |  HDU list class.  This is the top-level FITS object.  When a FITS\n",
      "     |  file is opened, a `HDUList` object is returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HDUList\n",
      "     |      builtins.list\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, item)\n",
      "     |      Returns `True` if ``HDUList.index_of(item)`` succeeds.\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |      Delete an HDU from the `HDUList`, indexed by number or name.\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |      # Support the 'with' statement\n",
      "     |  \n",
      "     |  __exit__(self, type, value, traceback)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Get an HDU from the `HDUList`, indexed by number or name.\n",
      "     |  \n",
      "     |  __init__(self, hdus=[], file=None)\n",
      "     |      Construct a `HDUList` object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hdus : sequence of HDU objects or single HDU, optional\n",
      "     |          The HDU object(s) to comprise the `HDUList`.  Should be\n",
      "     |          instances of HDU classes like `ImageHDU` or `BinTableHDU`.\n",
      "     |      \n",
      "     |      file : file object, bytes, optional\n",
      "     |          The opened physical file associated with the `HDUList`\n",
      "     |          or a bytes object containing the contents of the FITS\n",
      "     |          file.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, hdu)\n",
      "     |      Set an HDU to the `HDUList`, indexed by number or name.\n",
      "     |  \n",
      "     |  append(self, hdu)\n",
      "     |      Append a new HDU to the `HDUList`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hdu : HDU object\n",
      "     |          HDU to add to the `HDUList`.\n",
      "     |  \n",
      "     |  close(self, output_verify='exception', verbose=False, closed=True)\n",
      "     |      Close the associated FITS file and memmap object, if any.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      output_verify : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      verbose : bool\n",
      "     |          When `True`, print out verbose messages.\n",
      "     |      \n",
      "     |      closed : bool\n",
      "     |          When `True`, close the underlying file object.\n",
      "     |  \n",
      "     |  fileinfo(self, index)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of the indexed HDU within any associated file.  The values are\n",
      "     |      only valid after a read or write of the associated file with\n",
      "     |      no intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : int\n",
      "     |          Index of HDU for which info is to be returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      fileinfo : dict or None\n",
      "     |      \n",
      "     |          The dictionary details information about the locations of\n",
      "     |          the indexed HDU within an associated file.  Returns `None`\n",
      "     |          when the HDU is not associated with a file.\n",
      "     |      \n",
      "     |          Dictionary contents:\n",
      "     |      \n",
      "     |          ========== ========================================================\n",
      "     |          Key        Value\n",
      "     |          ========== ========================================================\n",
      "     |          file       File object associated with the HDU\n",
      "     |          filename   Name of associated file object\n",
      "     |          filemode   Mode in which the file was opened (readonly,\n",
      "     |                     update, append, denywrite, ostream)\n",
      "     |          resized    Flag that when `True` indicates that the data has been\n",
      "     |                     resized since the last read/write so the returned values\n",
      "     |                     may not be valid.\n",
      "     |          hdrLoc     Starting byte location of header in file\n",
      "     |          datLoc     Starting byte location of data block in file\n",
      "     |          datSpan    Data size including padding\n",
      "     |          ========== ========================================================\n",
      "     |  \n",
      "     |  filename(self)\n",
      "     |      Return the file name associated with the HDUList object if one exists.\n",
      "     |      Otherwise returns None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filename : a string containing the file name associated with the\n",
      "     |                 HDUList object if an association exists.  Otherwise returns\n",
      "     |                 None.\n",
      "     |  \n",
      "     |  flush(self, output_verify='fix', verbose=False)\n",
      "     |      Force a write of the `HDUList` back to the file (for append and\n",
      "     |      update modes only).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      output_verify : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      verbose : bool\n",
      "     |          When `True`, print verbose messages\n",
      "     |  \n",
      "     |  index_of(self, key)\n",
      "     |      Get the index of an HDU from the `HDUList`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : int, str or tuple of (string, int)\n",
      "     |         The key identifying the HDU.  If ``key`` is a tuple, it is of the\n",
      "     |         form ``(key, ver)`` where ``ver`` is an ``EXTVER`` value that must\n",
      "     |         match the HDU being searched for.\n",
      "     |      \n",
      "     |         If the key is ambiguous (e.g. there are multiple 'SCI' extensions)\n",
      "     |         the first match is returned.  For a more precise match use the\n",
      "     |         ``(name, ver)`` pair.\n",
      "     |      \n",
      "     |         If even the ``(name, ver)`` pair is ambiguous (it shouldn't be\n",
      "     |         but it's not impossible) the numeric index must be used to index\n",
      "     |         the duplicate HDU.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      index : int\n",
      "     |         The index of the HDU in the `HDUList`.\n",
      "     |  \n",
      "     |  info(self, output=None)\n",
      "     |      Summarize the info of the HDUs in this `HDUList`.\n",
      "     |      \n",
      "     |      Note that this function prints its results to the console---it\n",
      "     |      does not return a value.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      output : file, bool, optional\n",
      "     |          A file-like object to write the output to.  If `False`, does not\n",
      "     |          output to a file and instead returns a list of tuples representing\n",
      "     |          the HDU info.  Writes to ``sys.stdout`` by default.\n",
      "     |  \n",
      "     |  insert(self, index, hdu)\n",
      "     |      Insert an HDU into the `HDUList` at the given ``index``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      index : int\n",
      "     |          Index before which to insert the new HDU.\n",
      "     |      \n",
      "     |      hdu : HDU object\n",
      "     |          The HDU object to insert\n",
      "     |  \n",
      "     |  readall(self)\n",
      "     |      Read data of all HDUs into memory.\n",
      "     |  \n",
      "     |  update_extend(self)\n",
      "     |      Make sure that if the primary header needs the keyword ``EXTEND`` that\n",
      "     |      it has it and it is correct.\n",
      "     |  \n",
      "     |  writeto(self, fileobj, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Write the `HDUList` to a new file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file path, file object or file-like object\n",
      "     |          File to write to.  If a file object, must be opened in a\n",
      "     |          writeable mode.\n",
      "     |      \n",
      "     |      output_verify : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      overwrite : bool, optional\n",
      "     |          If ``True``, overwrite the output file if it exists. Raises an\n",
      "     |          ``OSError`` (``IOError`` for Python 2) if ``False`` and the\n",
      "     |          output file exists. Default is ``False``.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.3\n",
      "     |             ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards\n",
      "     |          to the headers of all HDU's written to the file.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  fromfile(fileobj, mode=None, memmap=None, save_backup=False, cache=True, lazy_load_hdus=True, **kwargs) from builtins.type\n",
      "     |      Creates an `HDUList` instance from a file-like object.\n",
      "     |      \n",
      "     |      The actual implementation of ``fitsopen()``, and generally shouldn't\n",
      "     |      be used directly.  Use :func:`open` instead (and see its\n",
      "     |      documentation for details of the parameters accepted by this method).\n",
      "     |  \n",
      "     |  fromstring(data, **kwargs) from builtins.type\n",
      "     |      Creates an `HDUList` instance from a string or other in-memory data\n",
      "     |      buffer containing an entire FITS file.  Similar to\n",
      "     |      :meth:`HDUList.fromfile`, but does not accept the mode or memmap\n",
      "     |      arguments, as they are only relevant to reading from a file on disk.\n",
      "     |      \n",
      "     |      This is useful for interfacing with other libraries such as CFITSIO,\n",
      "     |      and may also be useful for streaming applications.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, buffer, memoryview, etc.\n",
      "     |          A string or other memory buffer containing an entire FITS file.  It\n",
      "     |          should be noted that if that memory is read-only (such as a Python\n",
      "     |          string) the returned :class:`HDUList`'s data portions will also be\n",
      "     |          read-only.\n",
      "     |      \n",
      "     |      kwargs : dict\n",
      "     |          Optional keyword arguments.  See\n",
      "     |          :func:`astropy.io.fits.open` for details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hdul : HDUList\n",
      "     |          An :class:`HDUList` object representing the in-memory FITS file.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.list:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __iadd__(self, value, /)\n",
      "     |      Implement self+=value.\n",
      "     |  \n",
      "     |  __imul__(self, value, /)\n",
      "     |      Implement self*=value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.n\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __reversed__(...)\n",
      "     |      L.__reversed__() -- return a reverse iterator over the list\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __sizeof__(...)\n",
      "     |      L.__sizeof__() -- size of L in memory, in bytes\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      L.clear() -> None -- remove all items from L\n",
      "     |  \n",
      "     |  copy(...)\n",
      "     |      L.copy() -> list -- a shallow copy of L\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      L.count(value) -> integer -- return number of occurrences of value\n",
      "     |  \n",
      "     |  extend(...)\n",
      "     |      L.extend(iterable) -> None -- extend list by appending elements from the iterable\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      L.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  pop(...)\n",
      "     |      L.pop([index]) -> item -- remove and return item at index (default last).\n",
      "     |      Raises IndexError if list is empty or index is out of range.\n",
      "     |  \n",
      "     |  remove(...)\n",
      "     |      L.remove(value) -> None -- remove first occurrence of value.\n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  reverse(...)\n",
      "     |      L.reverse() -- reverse *IN PLACE*\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      L.sort(key=None, reverse=False) -> None -- stable sort *IN PLACE*\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.list:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class Header(builtins.object)\n",
      "     |  FITS header class.  This class exposes both a dict-like interface and a\n",
      "     |  list-like interface to FITS headers.\n",
      "     |  \n",
      "     |  The header may be indexed by keyword and, like a dict, the associated value\n",
      "     |  will be returned.  When the header contains cards with duplicate keywords,\n",
      "     |  only the value of the first card with the given keyword will be returned.\n",
      "     |  It is also possible to use a 2-tuple as the index in the form (keyword,\n",
      "     |  n)--this returns the n-th value with that keyword, in the case where there\n",
      "     |  are duplicate keywords.\n",
      "     |  \n",
      "     |  For example::\n",
      "     |  \n",
      "     |      >>> header['NAXIS']\n",
      "     |      0\n",
      "     |      >>> header[('FOO', 1)]  # Return the value of the second FOO keyword\n",
      "     |      'foo'\n",
      "     |  \n",
      "     |  The header may also be indexed by card number::\n",
      "     |  \n",
      "     |      >>> header[0]  # Return the value of the first card in the header\n",
      "     |      'T'\n",
      "     |  \n",
      "     |  Commentary keywords such as HISTORY and COMMENT are special cases: When\n",
      "     |  indexing the Header object with either 'HISTORY' or 'COMMENT' a list of all\n",
      "     |  the HISTORY/COMMENT values is returned::\n",
      "     |  \n",
      "     |      >>> header['HISTORY']\n",
      "     |      This is the first history entry in this header.\n",
      "     |      This is the second history entry in this header.\n",
      "     |      ...\n",
      "     |  \n",
      "     |  See the Astropy documentation for more details on working with headers.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |  \n",
      "     |  __contains__(self, keyword)\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Two Headers are equal only if they have the exact same string\n",
      "     |      representation.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __iadd__(self, other)\n",
      "     |  \n",
      "     |  __init__(self, cards=[], copy=False)\n",
      "     |      Construct a `Header` from an iterable and/or text file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cards : A list of `Card` objects, optional\n",
      "     |          The cards to initialize the header with. Also allowed are other\n",
      "     |          `Header` (or `dict`-like) objects.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.2\n",
      "     |              Allowed ``cards`` to be a `dict`-like object.\n",
      "     |      \n",
      "     |      copy : bool, optional\n",
      "     |      \n",
      "     |          If ``True`` copies the ``cards`` if they were another `Header`\n",
      "     |          instance.\n",
      "     |          Default is ``False``.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  add_blank(self, value='', before=None, after=None)\n",
      "     |      Add a blank card.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : str, optional\n",
      "     |          Text to be added.\n",
      "     |      \n",
      "     |      before : str or int, optional\n",
      "     |          Same as in `Header.update`\n",
      "     |      \n",
      "     |      after : str or int, optional\n",
      "     |          Same as in `Header.update`\n",
      "     |  \n",
      "     |  add_comment(self, value, before=None, after=None)\n",
      "     |      Add a ``COMMENT`` card.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : str\n",
      "     |          Text to be added.\n",
      "     |      \n",
      "     |      before : str or int, optional\n",
      "     |          Same as in `Header.update`\n",
      "     |      \n",
      "     |      after : str or int, optional\n",
      "     |          Same as in `Header.update`\n",
      "     |  \n",
      "     |  add_history(self, value, before=None, after=None)\n",
      "     |      Add a ``HISTORY`` card.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : str\n",
      "     |          History text to be added.\n",
      "     |      \n",
      "     |      before : str or int, optional\n",
      "     |          Same as in `Header.update`\n",
      "     |      \n",
      "     |      after : str or int, optional\n",
      "     |          Same as in `Header.update`\n",
      "     |  \n",
      "     |  append(self, card=None, useblanks=True, bottom=False, end=False)\n",
      "     |      Appends a new keyword+value card to the end of the Header, similar\n",
      "     |      to `list.append`.\n",
      "     |      \n",
      "     |      By default if the last cards in the Header have commentary keywords,\n",
      "     |      this will append the new keyword before the commentary (unless the new\n",
      "     |      keyword is also commentary).\n",
      "     |      \n",
      "     |      Also differs from `list.append` in that it can be called with no\n",
      "     |      arguments: In this case a blank card is appended to the end of the\n",
      "     |      Header.  In the case all the keyword arguments are ignored.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      card : str, tuple\n",
      "     |          A keyword or a (keyword, value, [comment]) tuple representing a\n",
      "     |          single header card; the comment is optional in which case a\n",
      "     |          2-tuple may be used\n",
      "     |      \n",
      "     |      useblanks : bool, optional\n",
      "     |          If there are blank cards at the end of the Header, replace the\n",
      "     |          first blank card so that the total number of cards in the Header\n",
      "     |          does not increase.  Otherwise preserve the number of blank cards.\n",
      "     |      \n",
      "     |      bottom : bool, optional\n",
      "     |          If True, instead of appending after the last non-commentary card,\n",
      "     |          append after the last non-blank card.\n",
      "     |      \n",
      "     |      end : bool, optional\n",
      "     |          If True, ignore the useblanks and bottom options, and append at the\n",
      "     |          very end of the Header.\n",
      "     |  \n",
      "     |  clear(self)\n",
      "     |      Remove all cards from the header.\n",
      "     |  \n",
      "     |  copy(self, strip=False)\n",
      "     |      Make a copy of the :class:`Header`.\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |          `copy.copy` and `copy.deepcopy` on a `Header` will call this\n",
      "     |          method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      strip : bool, optional\n",
      "     |         If `True`, strip any headers that are specific to one of the\n",
      "     |         standard HDU types, so that this header can be used in a different\n",
      "     |         HDU.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      header\n",
      "     |          A new :class:`Header` instance.\n",
      "     |  \n",
      "     |  count(self, keyword)\n",
      "     |      Returns the count of the given keyword in the header, similar to\n",
      "     |      `list.count` if the Header object is treated as a list of keywords.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to count instances of in the header\n",
      "     |  \n",
      "     |  extend(self, cards, strip=True, unique=False, update=False, update_first=False, useblanks=True, bottom=False, end=False)\n",
      "     |      Appends multiple keyword+value cards to the end of the header, similar\n",
      "     |      to `list.extend`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cards : iterable\n",
      "     |          An iterable of (keyword, value, [comment]) tuples; see\n",
      "     |          `Header.append`.\n",
      "     |      \n",
      "     |      strip : bool, optional\n",
      "     |          Remove any keywords that have meaning only to specific types of\n",
      "     |          HDUs, so that only more general keywords are added from extension\n",
      "     |          Header or Card list (default: `True`).\n",
      "     |      \n",
      "     |      unique : bool, optional\n",
      "     |          If `True`, ensures that no duplicate keywords are appended;\n",
      "     |          keywords already in this header are simply discarded.  The\n",
      "     |          exception is commentary keywords (COMMENT, HISTORY, etc.): they are\n",
      "     |          only treated as duplicates if their values match.\n",
      "     |      \n",
      "     |      update : bool, optional\n",
      "     |          If `True`, update the current header with the values and comments\n",
      "     |          from duplicate keywords in the input header.  This supercedes the\n",
      "     |          ``unique`` argument.  Commentary keywords are treated the same as\n",
      "     |          if ``unique=True``.\n",
      "     |      \n",
      "     |      update_first : bool, optional\n",
      "     |          If the first keyword in the header is 'SIMPLE', and the first\n",
      "     |          keyword in the input header is 'XTENSION', the 'SIMPLE' keyword is\n",
      "     |          replaced by the 'XTENSION' keyword.  Likewise if the first keyword\n",
      "     |          in the header is 'XTENSION' and the first keyword in the input\n",
      "     |          header is 'SIMPLE', the 'XTENSION' keyword is replaced by the\n",
      "     |          'SIMPLE' keyword.  This behavior is otherwise dumb as to whether or\n",
      "     |          not the resulting header is a valid primary or extension header.\n",
      "     |          This is mostly provided to support backwards compatibility with the\n",
      "     |          old ``Header.fromTxtFile`` method, and only applies if\n",
      "     |          ``update=True``.\n",
      "     |      \n",
      "     |      useblanks, bottom, end : bool, optional\n",
      "     |          These arguments are passed to :meth:`Header.append` while appending\n",
      "     |          new cards to the header.\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      Similar to :meth:`dict.get`--returns the value associated with keyword\n",
      "     |      in the header, or a default value if the keyword is not found.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : str\n",
      "     |          A keyword that may or may not be in the header.\n",
      "     |      \n",
      "     |      default : optional\n",
      "     |          A default value to return if the keyword is not found in the\n",
      "     |          header.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value\n",
      "     |          The value associated with the given keyword, or the default value\n",
      "     |          if the keyword is not in the header.\n",
      "     |  \n",
      "     |  index(self, keyword, start=None, stop=None)\n",
      "     |      Returns the index if the first instance of the given keyword in the\n",
      "     |      header, similar to `list.index` if the Header object is treated as a\n",
      "     |      list of keywords.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to look up in the list of all keywords in the header\n",
      "     |      \n",
      "     |      start : int, optional\n",
      "     |          The lower bound for the index\n",
      "     |      \n",
      "     |      stop : int, optional\n",
      "     |          The upper bound for the index\n",
      "     |  \n",
      "     |  insert(self, key, card, useblanks=True, after=False)\n",
      "     |      Inserts a new keyword+value card into the Header at a given location,\n",
      "     |      similar to `list.insert`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : int, str, or tuple\n",
      "     |          The index into the list of header keywords before which the\n",
      "     |          new keyword should be inserted, or the name of a keyword before\n",
      "     |          which the new keyword should be inserted.  Can also accept a\n",
      "     |          (keyword, index) tuple for inserting around duplicate keywords.\n",
      "     |      \n",
      "     |      card : str, tuple\n",
      "     |          A keyword or a (keyword, value, [comment]) tuple; see\n",
      "     |          `Header.append`\n",
      "     |      \n",
      "     |      useblanks : bool, optional\n",
      "     |          If there are blank cards at the end of the Header, replace the\n",
      "     |          first blank card so that the total number of cards in the Header\n",
      "     |          does not increase.  Otherwise preserve the number of blank cards.\n",
      "     |      \n",
      "     |      after : bool, optional\n",
      "     |          If set to `True`, insert *after* the specified index or keyword,\n",
      "     |          rather than before it.  Defaults to `False`.\n",
      "     |  \n",
      "     |  items = iteritems(self)\n",
      "     |      Like :meth:`dict.iteritems`.\n",
      "     |  \n",
      "     |  keys = iterkeys(self)\n",
      "     |      Like :meth:`dict.iterkeys`--iterating directly over the `Header`\n",
      "     |      instance has the same behavior.\n",
      "     |  \n",
      "     |  pop(self, *args)\n",
      "     |      Works like :meth:`list.pop` if no arguments or an index argument are\n",
      "     |      supplied; otherwise works like :meth:`dict.pop`.\n",
      "     |  \n",
      "     |  popitem(self)\n",
      "     |      Similar to :meth:`dict.popitem`.\n",
      "     |  \n",
      "     |  remove(self, keyword, ignore_missing=False, remove_all=False)\n",
      "     |      Removes the first instance of the given keyword from the header similar\n",
      "     |      to `list.remove` if the Header object is treated as a list of keywords.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword of which to remove the first instance in the header.\n",
      "     |      \n",
      "     |      ignore_missing : bool, optional\n",
      "     |          When True, ignores missing keywords.  Otherwise, if the keyword\n",
      "     |          is not present in the header a KeyError is raised.\n",
      "     |      \n",
      "     |      remove_all : bool, optional\n",
      "     |          When True, all instances of keyword will be removed.\n",
      "     |          Otherwise only the first instance of the given keyword is removed.\n",
      "     |  \n",
      "     |  rename_keyword(self, oldkeyword, newkeyword, force=False)\n",
      "     |      Rename a card's keyword in the header.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      oldkeyword : str or int\n",
      "     |          Old keyword or card index\n",
      "     |      \n",
      "     |      newkeyword : str\n",
      "     |          New keyword\n",
      "     |      \n",
      "     |      force : bool, optional\n",
      "     |          When `True`, if the new keyword already exists in the header, force\n",
      "     |          the creation of a duplicate keyword. Otherwise a\n",
      "     |          `ValueError` is raised.\n",
      "     |  \n",
      "     |  set(self, keyword, value=None, comment=None, before=None, after=None)\n",
      "     |      Set the value and/or comment and/or position of a specified keyword.\n",
      "     |      \n",
      "     |      If the keyword does not already exist in the header, a new keyword is\n",
      "     |      created in the specified position, or appended to the end of the header\n",
      "     |      if no position is specified.\n",
      "     |      \n",
      "     |      This method is similar to :meth:`Header.update` prior to PyFITS 3.1\n",
      "     |      / Astropy v0.1.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          It should be noted that ``header.set(keyword, value)`` and\n",
      "     |          ``header.set(keyword, value, comment)`` are equivalent to\n",
      "     |          ``header[keyword] = value`` and\n",
      "     |          ``header[keyword] = (value, comment)`` respectively.\n",
      "     |      \n",
      "     |          New keywords can also be inserted relative to existing keywords\n",
      "     |          using, for example::\n",
      "     |      \n",
      "     |              >>> header.insert('NAXIS1', ('NAXIS', 2, 'Number of axes'))\n",
      "     |      \n",
      "     |          to insert before an existing keyword, or::\n",
      "     |      \n",
      "     |              >>> header.insert('NAXIS', ('NAXIS1', 4096), after=True)\n",
      "     |      \n",
      "     |          to insert after an existing keyword.\n",
      "     |      \n",
      "     |          The only advantage of using :meth:`Header.set` is that it\n",
      "     |          easily replaces the old usage of :meth:`Header.update` both\n",
      "     |          conceptually and in terms of function signature.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          A header keyword\n",
      "     |      \n",
      "     |      value : str, optional\n",
      "     |          The value to set for the given keyword; if None the existing value\n",
      "     |          is kept, but '' may be used to set a blank value\n",
      "     |      \n",
      "     |      comment : str, optional\n",
      "     |          The comment to set for the given keyword; if None the existing\n",
      "     |          comment is kept, but ``''`` may be used to set a blank comment\n",
      "     |      \n",
      "     |      before : str, int, optional\n",
      "     |          Name of the keyword, or index of the `Card` before which this card\n",
      "     |          should be located in the header.  The argument ``before`` takes\n",
      "     |          precedence over ``after`` if both specified.\n",
      "     |      \n",
      "     |      after : str, int, optional\n",
      "     |          Name of the keyword, or index of the `Card` after which this card\n",
      "     |          should be located in the header.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None)\n",
      "     |      Similar to :meth:`dict.setdefault`.\n",
      "     |  \n",
      "     |  tofile(self, fileobj, sep='', endcard=True, padding=True, overwrite=False)\n",
      "     |      Writes the header to file or file-like object.\n",
      "     |      \n",
      "     |      By default this writes the header exactly as it would be written to a\n",
      "     |      FITS file, with the END card included and padding to the next multiple\n",
      "     |      of 2880 bytes.  However, aspects of this may be controlled.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : str, file, optional\n",
      "     |          Either the pathname of a file, or an open file handle or file-like\n",
      "     |          object\n",
      "     |      \n",
      "     |      sep : str, optional\n",
      "     |          The character or string with which to separate cards.  By default\n",
      "     |          there is no separator, but one could use ``'\\\\n'``, for example, to\n",
      "     |          separate each card with a new line\n",
      "     |      \n",
      "     |      endcard : bool, optional\n",
      "     |          If `True` (default) adds the END card to the end of the header\n",
      "     |          string\n",
      "     |      \n",
      "     |      padding : bool, optional\n",
      "     |          If `True` (default) pads the string with spaces out to the next\n",
      "     |          multiple of 2880 characters\n",
      "     |      \n",
      "     |      overwrite : bool, optional\n",
      "     |          If ``True``, overwrite the output file if it exists. Raises an\n",
      "     |          ``OSError`` (``IOError`` for Python 2) if ``False`` and the\n",
      "     |          output file exists. Default is ``False``.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.3\n",
      "     |             ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |  \n",
      "     |  tostring(self, sep='', endcard=True, padding=True)\n",
      "     |      Returns a string representation of the header.\n",
      "     |      \n",
      "     |      By default this uses no separator between cards, adds the END card, and\n",
      "     |      pads the string with spaces to the next multiple of 2880 bytes.  That\n",
      "     |      is, it returns the header exactly as it would appear in a FITS file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sep : str, optional\n",
      "     |          The character or string with which to separate cards.  By default\n",
      "     |          there is no separator, but one could use ``'\\\\n'``, for example, to\n",
      "     |          separate each card with a new line\n",
      "     |      \n",
      "     |      endcard : bool, optional\n",
      "     |          If True (default) adds the END card to the end of the header\n",
      "     |          string\n",
      "     |      \n",
      "     |      padding : bool, optional\n",
      "     |          If True (default) pads the string with spaces out to the next\n",
      "     |          multiple of 2880 characters\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      s : str\n",
      "     |          A string representing a FITS header.\n",
      "     |  \n",
      "     |  totextfile(self, fileobj, endcard=False, overwrite=False)\n",
      "     |      Write the header as text to a file or a file-like object.\n",
      "     |      \n",
      "     |      Equivalent to::\n",
      "     |      \n",
      "     |          >>> Header.tofile(fileobj, sep='\\n', endcard=False,\n",
      "     |          ...               padding=False, overwrite=overwrite)\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |         ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      tofile\n",
      "     |  \n",
      "     |  update(self, *args, **kwargs)\n",
      "     |      Update the Header with new keyword values, updating the values of\n",
      "     |      existing keywords and appending new keywords otherwise; similar to\n",
      "     |      `dict.update`.\n",
      "     |      \n",
      "     |      `update` accepts either a dict-like object or an iterable.  In the\n",
      "     |      former case the keys must be header keywords and the values may be\n",
      "     |      either scalar values or (value, comment) tuples.  In the case of an\n",
      "     |      iterable the items must be (keyword, value) tuples or (keyword, value,\n",
      "     |      comment) tuples.\n",
      "     |      \n",
      "     |      Arbitrary arguments are also accepted, in which case the update() is\n",
      "     |      called again with the kwargs dict as its only argument.  That is,\n",
      "     |      \n",
      "     |      ::\n",
      "     |      \n",
      "     |          >>> header.update(NAXIS1=100, NAXIS2=100)\n",
      "     |      \n",
      "     |      is equivalent to::\n",
      "     |      \n",
      "     |          header.update({'NAXIS1': 100, 'NAXIS2': 100})\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          As this method works similarly to `dict.update` it is very\n",
      "     |          different from the ``Header.update()`` method in PyFITS versions\n",
      "     |          prior to 3.1.0 (or Astropy v0.1). Use of the old API was\n",
      "     |          **deprecated** for a long time and is now removed. Most uses of the\n",
      "     |          old API can be replaced as follows:\n",
      "     |      \n",
      "     |          * Replace ::\n",
      "     |      \n",
      "     |                header.update(keyword, value)\n",
      "     |      \n",
      "     |            with ::\n",
      "     |      \n",
      "     |                header[keyword] = value\n",
      "     |      \n",
      "     |          * Replace ::\n",
      "     |      \n",
      "     |                header.update(keyword, value, comment=comment)\n",
      "     |      \n",
      "     |            with ::\n",
      "     |      \n",
      "     |                header[keyword] = (value, comment)\n",
      "     |      \n",
      "     |          * Replace ::\n",
      "     |      \n",
      "     |                header.update(keyword, value, before=before_keyword)\n",
      "     |      \n",
      "     |            with ::\n",
      "     |      \n",
      "     |                header.insert(before_keyword, (keyword, value))\n",
      "     |      \n",
      "     |          * Replace ::\n",
      "     |      \n",
      "     |                header.update(keyword, value, after=after_keyword)\n",
      "     |      \n",
      "     |            with ::\n",
      "     |      \n",
      "     |                header.insert(after_keyword, (keyword, value),\n",
      "     |                              after=True)\n",
      "     |      \n",
      "     |          See also :meth:`Header.set` which is a new method that provides an\n",
      "     |          interface similar to the old ``Header.update()`` and may help make\n",
      "     |          transition a little easier.\n",
      "     |  \n",
      "     |  values = itervalues(self)\n",
      "     |      Like :meth:`dict.itervalues`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  fromfile(fileobj, sep='', endcard=True, padding=True) from builtins.type\n",
      "     |      Similar to :meth:`Header.fromstring`, but reads the header string from\n",
      "     |      a given file-like object or filename.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : str, file-like\n",
      "     |          A filename or an open file-like object from which a FITS header is\n",
      "     |          to be read.  For open file handles the file pointer must be at the\n",
      "     |          beginning of the header.\n",
      "     |      \n",
      "     |      sep : str, optional\n",
      "     |          The string separating cards from each other, such as a newline.  By\n",
      "     |          default there is no card separator (as is the case in a raw FITS\n",
      "     |          file).\n",
      "     |      \n",
      "     |      endcard : bool, optional\n",
      "     |          If True (the default) the header must end with an END card in order\n",
      "     |          to be considered valid.  If an END card is not found an\n",
      "     |          `IOError` is raised.\n",
      "     |      \n",
      "     |      padding : bool, optional\n",
      "     |          If True (the default) the header will be required to be padded out\n",
      "     |          to a multiple of 2880, the FITS header block size.  Otherwise any\n",
      "     |          padding, or lack thereof, is ignored.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      header\n",
      "     |          A new `Header` instance.\n",
      "     |  \n",
      "     |  fromkeys(iterable, value=None) from builtins.type\n",
      "     |      Similar to :meth:`dict.fromkeys`--creates a new `Header` from an\n",
      "     |      iterable of keywords and an optional default value.\n",
      "     |      \n",
      "     |      This method is not likely to be particularly useful for creating real\n",
      "     |      world FITS headers, but it is useful for testing.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      iterable\n",
      "     |          Any iterable that returns strings representing FITS keywords.\n",
      "     |      \n",
      "     |      value : optional\n",
      "     |          A default value to assign to each keyword; must be a valid type for\n",
      "     |          FITS keywords.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      header\n",
      "     |          A new `Header` instance.\n",
      "     |  \n",
      "     |  fromstring(data, sep='') from builtins.type\n",
      "     |      Creates an HDU header from a byte string containing the entire header\n",
      "     |      data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str\n",
      "     |         String containing the entire header.\n",
      "     |      \n",
      "     |      sep : str, optional\n",
      "     |          The string separating cards from each other, such as a newline.  By\n",
      "     |          default there is no card separator (as is the case in a raw FITS\n",
      "     |          file).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      header\n",
      "     |          A new `Header` instance.\n",
      "     |  \n",
      "     |  fromtextfile(fileobj, endcard=False) from builtins.type\n",
      "     |      Read a header from a simple text file or file-like object.\n",
      "     |      \n",
      "     |      Equivalent to::\n",
      "     |      \n",
      "     |          >>> Header.fromfile(fileobj, sep='\\n', endcard=False,\n",
      "     |          ...                 padding=False)\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      fromfile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  cards\n",
      "     |      The underlying physical cards that make up this Header; it can be\n",
      "     |      looked at, but it should not be modified directly.\n",
      "     |  \n",
      "     |  comments\n",
      "     |      View the comments associated with each keyword, if any.\n",
      "     |      \n",
      "     |      For example, to see the comment on the NAXIS keyword:\n",
      "     |      \n",
      "     |          >>> header.comments['NAXIS']\n",
      "     |          number of data axes\n",
      "     |      \n",
      "     |      Comments can also be updated through this interface:\n",
      "     |      \n",
      "     |          >>> header.comments['NAXIS'] = 'Number of data axes'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class ImageHDU(_ImageBaseHDU, astropy.io.fits.hdu.base.ExtensionHDU)\n",
      "     |  FITS image extension HDU class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ImageHDU\n",
      "     |      _ImageBaseHDU\n",
      "     |      astropy.io.fits.hdu.base.ExtensionHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None, name=None, do_not_scale_image_data=False, uint=True, scale_back=None)\n",
      "     |      Construct an image HDU.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array\n",
      "     |          The data in the HDU.\n",
      "     |      \n",
      "     |      header : Header instance\n",
      "     |          The header to be used (as a template).  If ``header`` is\n",
      "     |          `None`, a minimal header will be provided.\n",
      "     |      \n",
      "     |      name : str, optional\n",
      "     |          The name of the HDU, will be the value of the keyword\n",
      "     |          ``EXTNAME``.\n",
      "     |      \n",
      "     |      do_not_scale_image_data : bool, optional\n",
      "     |          If `True`, image data is not scaled using BSCALE/BZERO values\n",
      "     |          when read. (default: False)\n",
      "     |      \n",
      "     |      uint : bool, optional\n",
      "     |          Interpret signed integer data where ``BZERO`` is the\n",
      "     |          central value and ``BSCALE == 1`` as unsigned integer\n",
      "     |          data.  For example, ``int16`` data with ``BZERO = 32768``\n",
      "     |          and ``BSCALE = 1`` would be treated as ``uint16`` data.\n",
      "     |          (default: True)\n",
      "     |      \n",
      "     |      scale_back : bool, optional\n",
      "     |          If `True`, when saving changes to a file that contained scaled\n",
      "     |          image data, restore the data to the original type and reapply the\n",
      "     |          original BSCALE/BZERO values.  This could lead to loss of accuracy\n",
      "     |          if scaling back to integer values after performing floating point\n",
      "     |          operations on the data.  Pseudo-unsigned integers are automatically\n",
      "     |          rescaled unless scale_back is explicitly set to `False`.\n",
      "     |          (default: None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      _ImageBaseHDU is sort of an abstract class for HDUs containing image\n",
      "     |      data (as opposed to table data) and should never be used directly.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  scale(self, type=None, option='old', bscale=None, bzero=None)\n",
      "     |      Scale image data by using ``BSCALE``/``BZERO``.\n",
      "     |      \n",
      "     |      Call to this method will scale `data` and update the keywords of\n",
      "     |      ``BSCALE`` and ``BZERO`` in the HDU's header.  This method should only\n",
      "     |      be used right before writing to the output file, as the data will be\n",
      "     |      scaled and is therefore not very usable after the call.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      type : str, optional\n",
      "     |          destination data type, use a string representing a numpy\n",
      "     |          dtype name, (e.g. ``'uint8'``, ``'int16'``, ``'float32'``\n",
      "     |          etc.).  If is `None`, use the current data type.\n",
      "     |      \n",
      "     |      option : str, optional\n",
      "     |          How to scale the data: ``\"old\"`` uses the original ``BSCALE`` and\n",
      "     |          ``BZERO`` values from when the data was read/created (defaulting to\n",
      "     |          1 and 0 if they don't exist). For integer data only, ``\"minmax\"``\n",
      "     |          uses the minimum and maximum of the data to scale. User-specified\n",
      "     |          ``bscale``/``bzero`` values always take precedence.\n",
      "     |      \n",
      "     |      bscale, bzero : int, optional\n",
      "     |          User-specified ``BSCALE`` and ``BZERO`` values\n",
      "     |  \n",
      "     |  update_header(self)\n",
      "     |      Update the header keywords to agree with the data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  data\n",
      "     |      Image/array data as a `~numpy.ndarray`.\n",
      "     |      \n",
      "     |      Please remember that the order of axes on an Numpy array are opposite\n",
      "     |      of the order specified in the FITS file.  For example for a 2D image\n",
      "     |      the \"rows\" or y-axis are the first dimension, and the \"columns\" or\n",
      "     |      x-axis are the second dimension.\n",
      "     |      \n",
      "     |      If the data is scaled using the BZERO and BSCALE parameters, this\n",
      "     |      attribute returns the data scaled to its physical values unless the\n",
      "     |      file was opened with ``do_not_scale_image_data=True``.\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  section\n",
      "     |      Access a section of the image array without loading the entire array\n",
      "     |      into memory.  The :class:`Section` object returned by this attribute is\n",
      "     |      not meant to be used directly by itself.  Rather, slices of the section\n",
      "     |      return the appropriate slice of the data, and loads *only* that section\n",
      "     |      into memory.\n",
      "     |      \n",
      "     |      Sections are mostly obsoleted by memmap support, but should still be\n",
      "     |      used to deal with very large scaled images.  See the\n",
      "     |      :ref:`data-sections` section of the PyFITS documentation for more\n",
      "     |      details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Shape of the image array--should be equivalent to ``self.data.shape``.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  standard_keyword_comments = {'BITPIX': 'array data type', 'GCOUNT': 'n...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base.ExtensionHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Works similarly to the normal writeto(), but prepends a default\n",
      "     |      `PrimaryHDU` are required by extension HDUs (which cannot stand on\n",
      "     |      their own).\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |         ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, blocking='standard', checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, blocking='standard', datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file object or file-like object\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __new__(cls, data=None, header=None, *args, **kwargs)\n",
      "     |      Iterates through the subclasses of _BaseHDU and uses that class's\n",
      "     |      match_header() method to determine which subclass to instantiate.\n",
      "     |      \n",
      "     |      It's important to be aware that the class hierarchy is traversed in a\n",
      "     |      depth-last order.  Each match_header() should identify an HDU type as\n",
      "     |      uniquely as possible.  Abstract types may choose to simply return False\n",
      "     |      or raise NotImplementedError to be skipped.\n",
      "     |      \n",
      "     |      If any unexpected exceptions are raised while evaluating\n",
      "     |      match_header(), the type is taken to be _CorruptedHDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class PrimaryHDU(_ImageBaseHDU)\n",
      "     |  FITS primary HDU class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PrimaryHDU\n",
      "     |      _ImageBaseHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None, do_not_scale_image_data=False, ignore_blank=False, uint=True, scale_back=None)\n",
      "     |      Construct a primary HDU.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array or DELAYED, optional\n",
      "     |          The data in the HDU.\n",
      "     |      \n",
      "     |      header : Header instance, optional\n",
      "     |          The header to be used (as a template).  If ``header`` is `None`, a\n",
      "     |          minimal header will be provided.\n",
      "     |      \n",
      "     |      do_not_scale_image_data : bool, optional\n",
      "     |          If `True`, image data is not scaled using BSCALE/BZERO values\n",
      "     |          when read. (default: False)\n",
      "     |      \n",
      "     |      ignore_blank : bool, optional\n",
      "     |          If `True`, the BLANK header keyword will be ignored if present.\n",
      "     |          Otherwise, pixels equal to this value will be replaced with\n",
      "     |          NaNs. (default: False)\n",
      "     |      \n",
      "     |      uint : bool, optional\n",
      "     |          Interpret signed integer data where ``BZERO`` is the\n",
      "     |          central value and ``BSCALE == 1`` as unsigned integer\n",
      "     |          data.  For example, ``int16`` data with ``BZERO = 32768``\n",
      "     |          and ``BSCALE = 1`` would be treated as ``uint16`` data.\n",
      "     |          (default: True)\n",
      "     |      \n",
      "     |      scale_back : bool, optional\n",
      "     |          If `True`, when saving changes to a file that contained scaled\n",
      "     |          image data, restore the data to the original type and reapply the\n",
      "     |          original BSCALE/BZERO values.  This could lead to loss of accuracy\n",
      "     |          if scaling back to integer values after performing floating point\n",
      "     |          operations on the data.  Pseudo-unsigned integers are automatically\n",
      "     |          rescaled unless scale_back is explicitly set to `False`.\n",
      "     |          (default: None)\n",
      "     |  \n",
      "     |  update_header(self)\n",
      "     |      Update the header keywords to agree with the data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      _ImageBaseHDU is sort of an abstract class for HDUs containing image\n",
      "     |      data (as opposed to table data) and should never be used directly.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  scale(self, type=None, option='old', bscale=None, bzero=None)\n",
      "     |      Scale image data by using ``BSCALE``/``BZERO``.\n",
      "     |      \n",
      "     |      Call to this method will scale `data` and update the keywords of\n",
      "     |      ``BSCALE`` and ``BZERO`` in the HDU's header.  This method should only\n",
      "     |      be used right before writing to the output file, as the data will be\n",
      "     |      scaled and is therefore not very usable after the call.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      type : str, optional\n",
      "     |          destination data type, use a string representing a numpy\n",
      "     |          dtype name, (e.g. ``'uint8'``, ``'int16'``, ``'float32'``\n",
      "     |          etc.).  If is `None`, use the current data type.\n",
      "     |      \n",
      "     |      option : str, optional\n",
      "     |          How to scale the data: ``\"old\"`` uses the original ``BSCALE`` and\n",
      "     |          ``BZERO`` values from when the data was read/created (defaulting to\n",
      "     |          1 and 0 if they don't exist). For integer data only, ``\"minmax\"``\n",
      "     |          uses the minimum and maximum of the data to scale. User-specified\n",
      "     |          ``bscale``/``bzero`` values always take precedence.\n",
      "     |      \n",
      "     |      bscale, bzero : int, optional\n",
      "     |          User-specified ``BSCALE`` and ``BZERO`` values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  data\n",
      "     |      Image/array data as a `~numpy.ndarray`.\n",
      "     |      \n",
      "     |      Please remember that the order of axes on an Numpy array are opposite\n",
      "     |      of the order specified in the FITS file.  For example for a 2D image\n",
      "     |      the \"rows\" or y-axis are the first dimension, and the \"columns\" or\n",
      "     |      x-axis are the second dimension.\n",
      "     |      \n",
      "     |      If the data is scaled using the BZERO and BSCALE parameters, this\n",
      "     |      attribute returns the data scaled to its physical values unless the\n",
      "     |      file was opened with ``do_not_scale_image_data=True``.\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  section\n",
      "     |      Access a section of the image array without loading the entire array\n",
      "     |      into memory.  The :class:`Section` object returned by this attribute is\n",
      "     |      not meant to be used directly by itself.  Rather, slices of the section\n",
      "     |      return the appropriate slice of the data, and loads *only* that section\n",
      "     |      into memory.\n",
      "     |      \n",
      "     |      Sections are mostly obsoleted by memmap support, but should still be\n",
      "     |      used to deal with very large scaled images.  See the\n",
      "     |      :ref:`data-sections` section of the PyFITS documentation for more\n",
      "     |      details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Shape of the image array--should be equivalent to ``self.data.shape``.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _ImageBaseHDU:\n",
      "     |  \n",
      "     |  standard_keyword_comments = {'BITPIX': 'array data type', 'GCOUNT': 'n...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, blocking='standard', checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, blocking='standard', datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Write the HDU to a new file. This is a convenience method to\n",
      "     |      provide a user easier output interface if only one HDU needs\n",
      "     |      to be written to a file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : file path, file object or file-like object\n",
      "     |          Output FITS file.  If the file object is already opened, it must\n",
      "     |          be opened in a writeable mode.\n",
      "     |      \n",
      "     |      output_verify : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      overwrite : bool, optional\n",
      "     |          If ``True``, overwrite the output file if it exists. Raises an\n",
      "     |          ``OSError`` (``IOError`` for Python 2) if ``False`` and the\n",
      "     |          output file exists. Default is ``False``.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.3\n",
      "     |             ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards\n",
      "     |          to the header of the HDU when written to the file.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file object or file-like object\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __new__(cls, data=None, header=None, *args, **kwargs)\n",
      "     |      Iterates through the subclasses of _BaseHDU and uses that class's\n",
      "     |      match_header() method to determine which subclass to instantiate.\n",
      "     |      \n",
      "     |      It's important to be aware that the class hierarchy is traversed in a\n",
      "     |      depth-last order.  Each match_header() should identify an HDU type as\n",
      "     |      uniquely as possible.  Abstract types may choose to simply return False\n",
      "     |      or raise NotImplementedError to be skipped.\n",
      "     |      \n",
      "     |      If any unexpected exceptions are raised while evaluating\n",
      "     |      match_header(), the type is taken to be _CorruptedHDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class Section(builtins.object)\n",
      "     |  Image section.\n",
      "     |  \n",
      "     |  Slices of this object load the corresponding section of an image array from\n",
      "     |  the underlying FITS file on disk, and applies any BSCALE/BZERO factors.\n",
      "     |  \n",
      "     |  Section slices cannot be assigned to, and modifications to a section are\n",
      "     |  not saved back to the underlying file.\n",
      "     |  \n",
      "     |  See the :ref:`data-sections` section of the PyFITS documentation for more\n",
      "     |  details.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __init__(self, hdu)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class StreamingHDU(builtins.object)\n",
      "     |  A class that provides the capability to stream data to a FITS file\n",
      "     |  instead of requiring data to all be written at once.\n",
      "     |  \n",
      "     |  The following pseudocode illustrates its use::\n",
      "     |  \n",
      "     |      header = astropy.io.fits.Header()\n",
      "     |  \n",
      "     |      for all the cards you need in the header:\n",
      "     |          header[key] = (value, comment)\n",
      "     |  \n",
      "     |      shdu = astropy.io.fits.StreamingHDU('filename.fits', header)\n",
      "     |  \n",
      "     |      for each piece of data:\n",
      "     |          shdu.write(data)\n",
      "     |  \n",
      "     |      shdu.close()\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |      # Support the 'with' statement\n",
      "     |  \n",
      "     |  __exit__(self, type, value, traceback)\n",
      "     |  \n",
      "     |  __init__(self, name, header)\n",
      "     |      Construct a `StreamingHDU` object given a file name and a header.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : file path, file object, or file like object\n",
      "     |          The file to which the header and data will be streamed.  If opened,\n",
      "     |          the file object must be opened in a writeable binary mode such as\n",
      "     |          'wb' or 'ab+'.\n",
      "     |      \n",
      "     |      header : `Header` instance\n",
      "     |          The header object associated with the data to be written\n",
      "     |          to the file.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The file will be opened and the header appended to the end of\n",
      "     |      the file.  If the file does not already exist, it will be\n",
      "     |      created, and if the header represents a Primary header, it\n",
      "     |      will be written to the beginning of the file.  If the file\n",
      "     |      does not exist and the provided header is not a Primary\n",
      "     |      header, a default Primary HDU will be inserted at the\n",
      "     |      beginning of the file and the provided header will be added as\n",
      "     |      the first extension.  If the file does already exist, but the\n",
      "     |      provided header represents a Primary header, the header will\n",
      "     |      be modified to an image extension header and appended to the\n",
      "     |      end of the file.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Close the physical FITS file.\n",
      "     |  \n",
      "     |  write(self, data)\n",
      "     |      Write the given data to the stream.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : ndarray\n",
      "     |          Data to stream to the file.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      writecomplete : int\n",
      "     |          Flag that when `True` indicates that all of the required\n",
      "     |          data has been written to the stream.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only the amount of data specified in the header provided to the class\n",
      "     |      constructor may be written to the stream.  If the provided data would\n",
      "     |      cause the stream to overflow, an `IOError` exception is\n",
      "     |      raised and the data is not written. Once sufficient data has been\n",
      "     |      written to the stream to satisfy the amount specified in the header,\n",
      "     |      the stream is padded to fill a complete FITS block and no more data\n",
      "     |      will be accepted. An attempt to write more data after the stream has\n",
      "     |      been filled will raise an `IOError` exception. If the\n",
      "     |      dtype of the input data does not match what is expected by the header,\n",
      "     |      a `TypeError` exception is raised.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  size\n",
      "     |      Return the size (in bytes) of the data portion of the HDU.\n",
      "    \n",
      "    class TableHDU(_TableBaseHDU)\n",
      "     |  FITS ASCII table extension HDU class.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  data : array or `FITS_rec`\n",
      "     |      Data to be used.\n",
      "     |  header : `Header`\n",
      "     |      Header to be used.\n",
      "     |  name : str\n",
      "     |      Name to be populated in ``EXTNAME`` keyword.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TableHDU\n",
      "     |      _TableBaseHDU\n",
      "     |      astropy.io.fits.hdu.base.ExtensionHDU\n",
      "     |      _TableLikeHDU\n",
      "     |      astropy.io.fits.hdu.base._ValidHDU\n",
      "     |      astropy.io.fits.hdu.base._BaseHDU\n",
      "     |      astropy.io.fits.verify._Verify\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data=None, header=None, name=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  match_header(header) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      This is an abstract type that implements the shared functionality of\n",
      "     |      the ASCII and Binary Table HDU types, which should be used instead of\n",
      "     |      this.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _TableBaseHDU:\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Make a copy of the table HDU, both header and data are copied.\n",
      "     |  \n",
      "     |  update(self)\n",
      "     |      Update header keywords to reflect recent changes of columns.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _TableBaseHDU:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      The :class:`ColDefs` objects describing the columns in this table.\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base.ExtensionHDU:\n",
      "     |  \n",
      "     |  writeto(self, name, output_verify='exception', overwrite=False, checksum=False)\n",
      "     |      Works similarly to the normal writeto(), but prepends a default\n",
      "     |      `PrimaryHDU` are required by extension HDUs (which cannot stand on\n",
      "     |      their own).\n",
      "     |      \n",
      "     |      .. versionchanged:: 1.3\n",
      "     |         ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from _TableLikeHDU:\n",
      "     |  \n",
      "     |  from_columns(columns, header=None, nrows=0, fill=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Given either a `ColDefs` object, a sequence of `Column` objects,\n",
      "     |      or another table HDU or table data (a `FITS_rec` or multi-field\n",
      "     |      `numpy.ndarray` or `numpy.recarray` object, return a new table HDU of\n",
      "     |      the class this method was called on using the column definition from\n",
      "     |      the input.\n",
      "     |      \n",
      "     |      See also `FITS_rec.from_columns`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      columns : sequence of `Column`, `ColDefs`, or other\n",
      "     |          The columns from which to create the table data, or an object with\n",
      "     |          a column-like structure from which a `ColDefs` can be instantiated.\n",
      "     |          This includes an existing `BinTableHDU` or `TableHDU`, or a\n",
      "     |          `numpy.recarray` to give some examples.\n",
      "     |      \n",
      "     |          If these columns have data arrays attached that data may be used in\n",
      "     |          initializing the new table.  Otherwise the input columns will be\n",
      "     |          used as a template for a new table with the requested number of\n",
      "     |          rows.\n",
      "     |      \n",
      "     |      header : `Header`\n",
      "     |          An optional `Header` object to instantiate the new HDU yet.  Header\n",
      "     |          keywords specifically related to defining the table structure (such\n",
      "     |          as the \"TXXXn\" keywords like TTYPEn) will be overridden by the\n",
      "     |          supplied column definitions, but all other informational and data\n",
      "     |          model-specific keywords are kept.\n",
      "     |      \n",
      "     |      nrows : int\n",
      "     |          Number of rows in the new table.  If the input columns have data\n",
      "     |          associated with them, the size of the largest input column is used.\n",
      "     |          Otherwise the default is 0.\n",
      "     |      \n",
      "     |      fill : bool\n",
      "     |          If `True`, will fill all cells with zeros or blanks.  If `False`,\n",
      "     |          copy the data from input, undefined cells will still be filled with\n",
      "     |          zeros/blanks.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      \n",
      "     |      Any additional keyword arguments accepted by the HDU class's\n",
      "     |      ``__init__`` may also be passed in as keyword arguments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  add_checksum(self, when=None, override_datasum=False, blocking='standard', checksum_keyword='CHECKSUM', datasum_keyword='DATASUM')\n",
      "     |      Add the ``CHECKSUM`` and ``DATASUM`` cards to this HDU with\n",
      "     |      the values set to the checksum calculated for the HDU and the\n",
      "     |      data respectively.  The addition of the ``DATASUM`` card may\n",
      "     |      be overridden.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |         comment string for the cards; by default the comments\n",
      "     |         will represent the time when the checksum was calculated\n",
      "     |      \n",
      "     |      override_datasum : bool, optional\n",
      "     |         add the ``CHECKSUM`` card only\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      checksum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the checksum value in; this\n",
      "     |          is typically 'CHECKSUM' per convention, but there exist use cases\n",
      "     |          in which a different keyword should be used\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          See ``checksum_keyword``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, first call `add_datasum` with a ``when``\n",
      "     |      argument, then call `add_checksum` with a ``when`` argument and\n",
      "     |      ``override_datasum`` set to `True`.  This will provide consistent\n",
      "     |      comments for both cards and enable the generation of a ``CHECKSUM``\n",
      "     |      card with a consistent value.\n",
      "     |  \n",
      "     |  add_datasum(self, when=None, blocking='standard', datasum_keyword='DATASUM')\n",
      "     |      Add the ``DATASUM`` card to this HDU with the value set to the\n",
      "     |      checksum calculated for the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      when : str, optional\n",
      "     |          Comment string for the card that by default represents the\n",
      "     |          time when the checksum was calculated\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      datasum_keyword : str, optional\n",
      "     |          The name of the header keyword to store the datasum value in;\n",
      "     |          this is typically 'DATASUM' per convention, but there exist\n",
      "     |          use cases in which a different keyword should be used\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      checksum : int\n",
      "     |          The calculated datasum\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For testing purposes, provide a ``when`` argument to enable the comment\n",
      "     |      value in the card to remain consistent.  This will enable the\n",
      "     |      generation of a ``CHECKSUM`` card with a consistent value.\n",
      "     |  \n",
      "     |  filebytes(self)\n",
      "     |      Calculates and returns the number of bytes that this HDU will write to\n",
      "     |      a file.\n",
      "     |  \n",
      "     |  fileinfo(self)\n",
      "     |      Returns a dictionary detailing information about the locations\n",
      "     |      of this HDU within any associated file.  The values are only\n",
      "     |      valid after a read or write of the associated file with no\n",
      "     |      intervening changes to the `HDUList`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict or None\n",
      "     |      \n",
      "     |         The dictionary details information about the locations of\n",
      "     |         this HDU within an associated file.  Returns `None` when\n",
      "     |         the HDU is not associated with a file.\n",
      "     |      \n",
      "     |         Dictionary contents:\n",
      "     |      \n",
      "     |         ========== ================================================\n",
      "     |         Key        Value\n",
      "     |         ========== ================================================\n",
      "     |         file       File object associated with the HDU\n",
      "     |         filemode   Mode in which the file was opened (readonly, copyonwrite,\n",
      "     |                    update, append, ostream)\n",
      "     |         hdrLoc     Starting byte location of header in file\n",
      "     |         datLoc     Starting byte location of data block in file\n",
      "     |         datSpan    Data size including padding\n",
      "     |         ========== ================================================\n",
      "     |  \n",
      "     |  req_cards(self, keyword, pos, test, fix_value, option, errlist)\n",
      "     |      Check the existence, location, and value of a required `Card`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      keyword : str\n",
      "     |          The keyword to validate\n",
      "     |      \n",
      "     |      pos : int, callable\n",
      "     |          If an ``int``, this specifies the exact location this card should\n",
      "     |          have in the header.  Remember that Python is zero-indexed, so this\n",
      "     |          means ``pos=0`` requires the card to be the first card in the\n",
      "     |          header.  If given a callable, it should take one argument--the\n",
      "     |          actual position of the keyword--and return `True` or `False`.  This\n",
      "     |          can be used for custom evaluation.  For example if\n",
      "     |          ``pos=lambda idx: idx > 10`` this will check that the keyword's\n",
      "     |          index is greater than 10.\n",
      "     |      \n",
      "     |      test : callable\n",
      "     |          This should be a callable (generally a function) that is passed the\n",
      "     |          value of the given keyword and returns `True` or `False`.  This can\n",
      "     |          be used to validate the value associated with the given keyword.\n",
      "     |      \n",
      "     |      fix_value : str, int, float, complex, bool, None\n",
      "     |          A valid value for a FITS keyword to to use if the given ``test``\n",
      "     |          fails to replace an invalid value.  In other words, this provides\n",
      "     |          a default value to use as a replacement if the keyword's current\n",
      "     |          value is invalid.  If `None`, there is no replacement value and the\n",
      "     |          keyword is unfixable.\n",
      "     |      \n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "     |      \n",
      "     |      errlist : list\n",
      "     |          A list of validation errors already found in the FITS file; this is\n",
      "     |          used primarily for the validation system to collect errors across\n",
      "     |          multiple HDUs and multiple calls to `req_cards`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If ``pos=None``, the card can be anywhere in the header.  If the card\n",
      "     |      does not exist, the new card will have the ``fix_value`` as its value\n",
      "     |      when created.  Also check the card's value by using the ``test``\n",
      "     |      argument.\n",
      "     |  \n",
      "     |  verify_checksum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``CHECKSUM`` keyword matches the\n",
      "     |      value calculated for the current HDU CHECKSUM.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``CHECKSUM`` keyword present\n",
      "     |  \n",
      "     |  verify_datasum(self, blocking='standard')\n",
      "     |      Verify that the value in the ``DATASUM`` keyword matches the value\n",
      "     |      calculated for the ``DATASUM`` of the current HDU data.\n",
      "     |      \n",
      "     |      blocking : str, optional\n",
      "     |          \"standard\" or \"nonstandard\", compute sum 2880 bytes at a time, or\n",
      "     |          not\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      valid : int\n",
      "     |         - 0 - failure\n",
      "     |         - 1 - success\n",
      "     |         - 2 - no ``DATASUM`` keyword present\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._ValidHDU:\n",
      "     |  \n",
      "     |  size\n",
      "     |      Size (in bytes) of the data portion of the HDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  fromstring(data, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Creates a new HDU object of the appropriate type from a string\n",
      "     |      containing the HDU's entire header and, optionally, its data.\n",
      "     |      \n",
      "     |      Note: When creating a new HDU from a string without a backing file\n",
      "     |      object, the data of that HDU may be read-only.  It depends on whether\n",
      "     |      the underlying string was an immutable Python str/bytes object, or some\n",
      "     |      kind of read-write memory buffer such as a `memoryview`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : str, bytearray, memoryview, ndarray\n",
      "     |         A byte string containing the HDU's header and data.\n",
      "     |      \n",
      "     |      checksum : bool, optional\n",
      "     |         Check the HDU's checksum and/or datasum.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool, optional\n",
      "     |         Ignore a missing end card in the header data.  Note that without the\n",
      "     |         end card the end of the header may be ambiguous and resulted in a\n",
      "     |         corrupt HDU.  In this case the assumption is that the first 2880\n",
      "     |         block that does not begin with valid FITS header data is the\n",
      "     |         beginning of the data.\n",
      "     |      \n",
      "     |      kwargs : optional\n",
      "     |         May consist of additional keyword arguments specific to an HDU\n",
      "     |         type--these correspond to keywords recognized by the constructors of\n",
      "     |         different HDU classes such as `PrimaryHDU`, `ImageHDU`, or\n",
      "     |         `BinTableHDU`.  Any unrecognized keyword arguments are simply\n",
      "     |         ignored.\n",
      "     |  \n",
      "     |  readfrom(fileobj, checksum=False, ignore_missing_end=False, **kwargs) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |      Read the HDU from a file.  Normally an HDU should be opened with\n",
      "     |      :func:`open` which reads the entire HDU list in a FITS file.  But this\n",
      "     |      method is still provided for symmetry with :func:`writeto`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fileobj : file object or file-like object\n",
      "     |          Input FITS file.  The file's seek pointer is assumed to be at the\n",
      "     |          beginning of the HDU.\n",
      "     |      \n",
      "     |      checksum : bool\n",
      "     |          If `True`, verifies that both ``DATASUM`` and ``CHECKSUM`` card\n",
      "     |          values (when present in the HDU header) match the header and data\n",
      "     |          of all HDU's in the file.\n",
      "     |      \n",
      "     |      ignore_missing_end : bool\n",
      "     |          Do not issue an exception when opening a file that is missing an\n",
      "     |          ``END`` card in the last header.\n",
      "     |  \n",
      "     |  register_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  unregister_hdu(hducls) from astropy.io.fits.hdu.base._BaseHDUMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __new__(cls, data=None, header=None, *args, **kwargs)\n",
      "     |      Iterates through the subclasses of _BaseHDU and uses that class's\n",
      "     |      match_header() method to determine which subclass to instantiate.\n",
      "     |      \n",
      "     |      It's important to be aware that the class hierarchy is traversed in a\n",
      "     |      depth-last order.  Each match_header() should identify an HDU type as\n",
      "     |      uniquely as possible.  Abstract types may choose to simply return False\n",
      "     |      or raise NotImplementedError to be skipped.\n",
      "     |      \n",
      "     |      If any unexpected exceptions are raised while evaluating\n",
      "     |      match_header(), the type is taken to be _CorruptedHDU.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from astropy.io.fits.hdu.base._BaseHDU:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  header\n",
      "     |  \n",
      "     |  is_image\n",
      "     |  \n",
      "     |  level\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ver\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from astropy.io.fits.verify._Verify:\n",
      "     |  \n",
      "     |  run_option(self, option='warn', err_text='', fix_text='Fixed.', fix=None, fixable=True)\n",
      "     |      Execute the verification with selected option.\n",
      "     |  \n",
      "     |  verify(self, option='warn')\n",
      "     |      Verify all values in the instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      option : str\n",
      "     |          Output verification option.  Must be one of ``\"fix\"``,\n",
      "     |          ``\"silentfix\"``, ``\"ignore\"``, ``\"warn\"``, or\n",
      "     |          ``\"exception\"``.  May also be any combination of ``\"fix\"`` or\n",
      "     |          ``\"silentfix\"`` with ``\"+ignore\"``, ``+warn``, or ``+exception\"\n",
      "     |          (e.g. ``\"fix+warn\"``).  See :ref:`verify` for more info.\n",
      "    \n",
      "    class Undefined(builtins.object)\n",
      "     |  Undefined value.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class VerifyError(builtins.Exception)\n",
      "     |  Verify exception class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VerifyError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "\n",
      "FUNCTIONS\n",
      "    append(filename, data, header=None, checksum=False, verify=True, **kwargs)\n",
      "        Append the header/data to FITS file if filename exists, create if not.\n",
      "        \n",
      "        If only ``data`` is supplied, a minimal header is created.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : file path, file object, or file like object\n",
      "            File to write to.  If opened, must be opened for update (rb+) unless it\n",
      "            is a new file, then it must be opened for append (ab+).  A file or\n",
      "            `~gzip.GzipFile` object opened for update will be closed after return.\n",
      "        \n",
      "        data : array, table, or group data object\n",
      "            the new data used for appending\n",
      "        \n",
      "        header : `Header` object, optional\n",
      "            The header associated with ``data``.  If `None`, an appropriate header\n",
      "            will be created for the data object supplied.\n",
      "        \n",
      "        checksum : bool, optional\n",
      "            When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards to the header\n",
      "            of the HDU when written to the file.\n",
      "        \n",
      "        verify : bool, optional\n",
      "            When `True`, the existing FITS file will be read in to verify it for\n",
      "            correctness before appending.  When `False`, content is simply appended\n",
      "            to the end of the file.  Setting ``verify`` to `False` can be much\n",
      "            faster.\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "    \n",
      "    delval(filename, keyword, *args, **kwargs)\n",
      "        Delete all instances of keyword from a header in a FITS file.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        \n",
      "        filename : file path, file object, or file like object\n",
      "            Name of the FITS file, or file object If opened, mode must be update\n",
      "            (rb+).  An opened file object or `~gzip.GzipFile` object will be closed\n",
      "            upon return.\n",
      "        \n",
      "        keyword : str, int\n",
      "            Keyword name or index\n",
      "        \n",
      "        ext, extname, extver\n",
      "            The rest of the arguments are for extension specification.\n",
      "            See `getdata` for explanations/examples.\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "            *Note:* This function automatically specifies ``do_not_scale_image_data\n",
      "            = True`` when opening the file so that values can be retrieved from the\n",
      "            unmodified header.\n",
      "    \n",
      "    getdata(filename, *args, **kwargs)\n",
      "        Get the data from an extension of a FITS file (and optionally the\n",
      "        header).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : file path, file object, or file like object\n",
      "            File to get data from.  If opened, mode must be one of the\n",
      "            following rb, rb+, or ab+.\n",
      "        \n",
      "        ext\n",
      "            The rest of the arguments are for extension specification.\n",
      "            They are flexible and are best illustrated by examples.\n",
      "        \n",
      "            No extra arguments implies the primary header::\n",
      "        \n",
      "                getdata('in.fits')\n",
      "        \n",
      "            By extension number::\n",
      "        \n",
      "                getdata('in.fits', 0)      # the primary header\n",
      "                getdata('in.fits', 2)      # the second extension\n",
      "                getdata('in.fits', ext=2)  # the second extension\n",
      "        \n",
      "            By name, i.e., ``EXTNAME`` value (if unique)::\n",
      "        \n",
      "                getdata('in.fits', 'sci')\n",
      "                getdata('in.fits', extname='sci')  # equivalent\n",
      "        \n",
      "            Note ``EXTNAME`` values are not case sensitive\n",
      "        \n",
      "            By combination of ``EXTNAME`` and EXTVER`` as separate\n",
      "            arguments or as a tuple::\n",
      "        \n",
      "                getdata('in.fits', 'sci', 2)  # EXTNAME='SCI' & EXTVER=2\n",
      "                getdata('in.fits', extname='sci', extver=2)  # equivalent\n",
      "                getdata('in.fits', ('sci', 2))  # equivalent\n",
      "        \n",
      "            Ambiguous or conflicting specifications will raise an exception::\n",
      "        \n",
      "                getdata('in.fits', ext=('sci',1), extname='err', extver=2)\n",
      "        \n",
      "        header : bool, optional\n",
      "            If `True`, return the data and the header of the specified HDU as a\n",
      "            tuple.\n",
      "        \n",
      "        lower, upper : bool, optional\n",
      "            If ``lower`` or ``upper`` are `True`, the field names in the\n",
      "            returned data object will be converted to lower or upper case,\n",
      "            respectively.\n",
      "        \n",
      "        view : ndarray, optional\n",
      "            When given, the data will be returned wrapped in the given ndarray\n",
      "            subclass by calling::\n",
      "        \n",
      "               data.view(view)\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        array : array, record array or groups data object\n",
      "            Type depends on the type of the extension being referenced.\n",
      "        \n",
      "            If the optional keyword ``header`` is set to `True`, this\n",
      "            function will return a (``data``, ``header``) tuple.\n",
      "    \n",
      "    getheader(filename, *args, **kwargs)\n",
      "        Get the header from an extension of a FITS file.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : file path, file object, or file like object\n",
      "            File to get header from.  If an opened file object, its mode\n",
      "            must be one of the following rb, rb+, or ab+).\n",
      "        \n",
      "        ext, extname, extver\n",
      "            The rest of the arguments are for extension specification.  See the\n",
      "            `getdata` documentation for explanations/examples.\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        header : `Header` object\n",
      "    \n",
      "    getval(filename, keyword, *args, **kwargs)\n",
      "        Get a keyword's value from a header in a FITS file.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : file path, file object, or file like object\n",
      "            Name of the FITS file, or file object (if opened, mode must be\n",
      "            one of the following rb, rb+, or ab+).\n",
      "        \n",
      "        keyword : str\n",
      "            Keyword name\n",
      "        \n",
      "        ext, extname, extver\n",
      "            The rest of the arguments are for extension specification.\n",
      "            See `getdata` for explanations/examples.\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "            *Note:* This function automatically specifies ``do_not_scale_image_data\n",
      "            = True`` when opening the file so that values can be retrieved from the\n",
      "            unmodified header.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        keyword value : str, int, or float\n",
      "    \n",
      "    info(filename, output=None, **kwargs)\n",
      "        Print the summary information on a FITS file.\n",
      "        \n",
      "        This includes the name, type, length of header, data shape and type\n",
      "        for each extension.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : file path, file object, or file like object\n",
      "            FITS file to obtain info from.  If opened, mode must be one of\n",
      "            the following: rb, rb+, or ab+ (i.e. the file must be readable).\n",
      "        \n",
      "        output : file, bool, optional\n",
      "            A file-like object to write the output to.  If ``False``, does not\n",
      "            output to a file and instead returns a list of tuples representing the\n",
      "            HDU info.  Writes to ``sys.stdout`` by default.\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "            *Note:* This function sets ``ignore_missing_end=True`` by default.\n",
      "    \n",
      "    open = fitsopen(name, mode='readonly', memmap=None, save_backup=False, cache=True, lazy_load_hdus=None, **kwargs)\n",
      "        Factory function to open a FITS file and return an `HDUList` object.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        name : file path, file object, file-like object or pathlib.Path object\n",
      "            File to be opened.\n",
      "        \n",
      "        mode : str, optional\n",
      "            Open mode, 'readonly' (default), 'update', 'append', 'denywrite', or\n",
      "            'ostream'.\n",
      "        \n",
      "            If ``name`` is a file object that is already opened, ``mode`` must\n",
      "            match the mode the file was opened with, readonly (rb), update (rb+),\n",
      "            append (ab+), ostream (w), denywrite (rb)).\n",
      "        \n",
      "        memmap : bool, optional\n",
      "            Is memory mapping to be used?\n",
      "        \n",
      "        save_backup : bool, optional\n",
      "            If the file was opened in update or append mode, this ensures that a\n",
      "            backup of the original file is saved before any changes are flushed.\n",
      "            The backup has the same name as the original file with \".bak\" appended.\n",
      "            If \"file.bak\" already exists then \"file.bak.1\" is used, and so on.\n",
      "        \n",
      "        cache : bool, optional\n",
      "            If the file name is a URL, `~astropy.utils.data.download_file` is used\n",
      "            to open the file.  This specifies whether or not to save the file\n",
      "            locally in Astropy's download cache (default: `True`).\n",
      "        \n",
      "        lazy_load_hdus : bool, option\n",
      "            By default `~astropy.io.fits.open` will not read all the HDUs and\n",
      "            headers in a FITS file immediately upon opening.  This is an\n",
      "            optimization especially useful for large files, as FITS has no way\n",
      "            of determining the number and offsets of all the HDUs in a file\n",
      "            without scanning through the file and reading all the headers.\n",
      "        \n",
      "            To disable lazy loading and read all HDUs immediately (the old\n",
      "            behavior) use ``lazy_load_hdus=False``.  This can lead to fewer\n",
      "            surprises--for example with lazy loading enabled, ``len(hdul)``\n",
      "            can be slow, as it means the entire FITS file needs to be read in\n",
      "            order to determine the number of HDUs.  ``lazy_load_hdus=False``\n",
      "            ensures that all HDUs have already been loaded after the file has\n",
      "            been opened.\n",
      "        \n",
      "            .. versionadded:: 1.3\n",
      "        \n",
      "        kwargs : dict, optional\n",
      "            additional optional keyword arguments, possible values are:\n",
      "        \n",
      "            - **uint** : bool\n",
      "        \n",
      "                Interpret signed integer data where ``BZERO`` is the\n",
      "                central value and ``BSCALE == 1`` as unsigned integer\n",
      "                data.  For example, ``int16`` data with ``BZERO = 32768``\n",
      "                and ``BSCALE = 1`` would be treated as ``uint16`` data.\n",
      "                This is enabled by default so that the pseudo-unsigned\n",
      "                integer convention is assumed.\n",
      "        \n",
      "                Note, for backward compatibility, the kwarg **uint16** may\n",
      "                be used instead.  The kwarg was renamed when support was\n",
      "                added for integers of any size.\n",
      "        \n",
      "            - **ignore_missing_end** : bool\n",
      "        \n",
      "                Do not issue an exception when opening a file that is\n",
      "                missing an ``END`` card in the last header.\n",
      "        \n",
      "            - **checksum** : bool, str\n",
      "        \n",
      "                If `True`, verifies that both ``DATASUM`` and\n",
      "                ``CHECKSUM`` card values (when present in the HDU header)\n",
      "                match the header and data of all HDU's in the file.  Updates to a\n",
      "                file that already has a checksum will preserve and update the\n",
      "                existing checksums unless this argument is given a value of\n",
      "                'remove', in which case the CHECKSUM and DATASUM values are not\n",
      "                checked, and are removed when saving changes to the file.\n",
      "        \n",
      "            - **disable_image_compression** : bool\n",
      "        \n",
      "                If `True`, treats compressed image HDU's like normal\n",
      "                binary table HDU's.\n",
      "        \n",
      "            - **do_not_scale_image_data** : bool\n",
      "        \n",
      "                If `True`, image data is not scaled using BSCALE/BZERO values\n",
      "                when read.\n",
      "        \n",
      "            - **ignore_blank** : bool\n",
      "        \n",
      "                If `True`, the BLANK keyword is ignored if present.\n",
      "        \n",
      "            - **scale_back** : bool\n",
      "        \n",
      "                If `True`, when saving changes to a file that contained scaled\n",
      "                image data, restore the data to the original type and reapply the\n",
      "                original BSCALE/BZERO values.  This could lead to loss of accuracy\n",
      "                if scaling back to integer values after performing floating point\n",
      "                operations on the data.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "            hdulist : an `HDUList` object\n",
      "                `HDUList` containing all of the header data units in the\n",
      "                file.\n",
      "    \n",
      "    printdiff(inputa, inputb, *args, **kwargs)\n",
      "        Compare two parts of a FITS file, including entire FITS files,\n",
      "        FITS `HDUList` objects and FITS ``HDU`` objects.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        inputa : str, `HDUList` object, or ``HDU`` object\n",
      "            The filename of a FITS file, `HDUList`, or ``HDU``\n",
      "            object to compare to ``inputb``.\n",
      "        \n",
      "        inputb : str, `HDUList` object, or ``HDU`` object\n",
      "            The filename of a FITS file, `HDUList`, or ``HDU``\n",
      "            object to compare to ``inputa``.\n",
      "        \n",
      "        ext, extname, extver\n",
      "            Additional positional arguments are for extension specification if your\n",
      "            inputs are string filenames (will not work if\n",
      "            ``inputa`` and ``inputb`` are ``HDU`` objects or `HDUList` objects).\n",
      "            They are flexible and are best illustrated by examples.  In addition\n",
      "            to using these arguments positionally you can directly call the\n",
      "            keyword parameters ``ext``, ``extname``.\n",
      "        \n",
      "            By extension number::\n",
      "        \n",
      "                printdiff('inA.fits', 'inB.fits', 0)      # the primary HDU\n",
      "                printdiff('inA.fits', 'inB.fits', 2)      # the second extension\n",
      "                printdiff('inA.fits', 'inB.fits', ext=2)  # the second extension\n",
      "        \n",
      "            By name, i.e., ``EXTNAME`` value (if unique). ``EXTNAME`` values are\n",
      "            not case sensitive:\n",
      "        \n",
      "                printdiff('inA.fits', 'inB.fits', 'sci')\n",
      "                printdiff('inA.fits', 'inB.fits', extname='sci')  # equivalent\n",
      "        \n",
      "            By combination of ``EXTNAME`` and ``EXTVER`` as separate\n",
      "            arguments or as a tuple::\n",
      "        \n",
      "                printdiff('inA.fits', 'inB.fits', 'sci', 2)    # EXTNAME='SCI'\n",
      "                                                               # & EXTVER=2\n",
      "                printdiff('inA.fits', 'inB.fits', extname='sci', extver=2)\n",
      "                                                               # equivalent\n",
      "                printdiff('inA.fits', 'inB.fits', ('sci', 2))  # equivalent\n",
      "        \n",
      "            Ambiguous or conflicting specifications will raise an exception::\n",
      "        \n",
      "                printdiff('inA.fits', 'inB.fits',\n",
      "                          ext=('sci', 1), extname='err', extver=2)\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `~astropy.io.fits.FITSDiff`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The primary use for the `printdiff` function is to allow quick print out\n",
      "        of a FITS difference report and will write to ``sys.stdout``.\n",
      "        To save the diff report to a file please use `~astropy.io.fits.FITSDiff`\n",
      "        directly.\n",
      "    \n",
      "    register_hdu(hducls) method of astropy.io.fits.hdu.base._BaseHDUMeta instance\n",
      "    \n",
      "    setval(filename, keyword, *args, **kwargs)\n",
      "        Set a keyword's value from a header in a FITS file.\n",
      "        \n",
      "        If the keyword already exists, it's value/comment will be updated.\n",
      "        If it does not exist, a new card will be created and it will be\n",
      "        placed before or after the specified location.  If no ``before`` or\n",
      "        ``after`` is specified, it will be appended at the end.\n",
      "        \n",
      "        When updating more than one keyword in a file, this convenience\n",
      "        function is a much less efficient approach compared with opening\n",
      "        the file for update, modifying the header, and closing the file.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : file path, file object, or file like object\n",
      "            Name of the FITS file, or file object If opened, mode must be update\n",
      "            (rb+).  An opened file object or `~gzip.GzipFile` object will be closed\n",
      "            upon return.\n",
      "        \n",
      "        keyword : str\n",
      "            Keyword name\n",
      "        \n",
      "        value : str, int, float, optional\n",
      "            Keyword value (default: `None`, meaning don't modify)\n",
      "        \n",
      "        comment : str, optional\n",
      "            Keyword comment, (default: `None`, meaning don't modify)\n",
      "        \n",
      "        before : str, int, optional\n",
      "            Name of the keyword, or index of the card before which the new card\n",
      "            will be placed.  The argument ``before`` takes precedence over\n",
      "            ``after`` if both are specified (default: `None`).\n",
      "        \n",
      "        after : str, int, optional\n",
      "            Name of the keyword, or index of the card after which the new card will\n",
      "            be placed. (default: `None`).\n",
      "        \n",
      "        savecomment : bool, optional\n",
      "            When `True`, preserve the current comment for an existing keyword.  The\n",
      "            argument ``savecomment`` takes precedence over ``comment`` if both\n",
      "            specified.  If ``comment`` is not specified then the current comment\n",
      "            will automatically be preserved  (default: `False`).\n",
      "        \n",
      "        ext, extname, extver\n",
      "            The rest of the arguments are for extension specification.\n",
      "            See `getdata` for explanations/examples.\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "            *Note:* This function automatically specifies ``do_not_scale_image_data\n",
      "            = True`` when opening the file so that values can be retrieved from the\n",
      "            unmodified header.\n",
      "    \n",
      "    table_to_hdu(table)\n",
      "        Convert an `~astropy.table.Table` object to a FITS\n",
      "        `~astropy.io.fits.BinTableHDU`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        table : astropy.table.Table\n",
      "            The table to convert.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        table_hdu : `~astropy.io.fits.BinTableHDU`\n",
      "            The FITS binary table HDU.\n",
      "    \n",
      "    tabledump(filename, datafile=None, cdfile=None, hfile=None, ext=1, overwrite=False)\n",
      "        Dump a table HDU to a file in ASCII format.  The table may be\n",
      "        dumped in three separate files, one containing column definitions,\n",
      "        one containing header parameters, and one for table data.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : file path, file object or file-like object\n",
      "            Input fits file.\n",
      "        \n",
      "        datafile : file path, file object or file-like object, optional\n",
      "            Output data file.  The default is the root name of the input\n",
      "            fits file appended with an underscore, followed by the\n",
      "            extension number (ext), followed by the extension ``.txt``.\n",
      "        \n",
      "        cdfile : file path, file object or file-like object, optional\n",
      "            Output column definitions file.  The default is `None`,\n",
      "            no column definitions output is produced.\n",
      "        \n",
      "        hfile : file path, file object or file-like object, optional\n",
      "            Output header parameters file.  The default is `None`,\n",
      "            no header parameters output is produced.\n",
      "        \n",
      "        ext : int\n",
      "            The number of the extension containing the table HDU to be\n",
      "            dumped.\n",
      "        \n",
      "        overwrite : bool, optional\n",
      "            If ``True``, overwrite the output file if it exists. Raises an\n",
      "            ``OSError`` (``IOError`` for Python 2) if ``False`` and the\n",
      "            output file exists. Default is ``False``.\n",
      "        \n",
      "            .. versionchanged:: 1.3\n",
      "               ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The primary use for the `tabledump` function is to allow editing in a\n",
      "        standard text editor of the table data and parameters.  The\n",
      "        `tableload` function can be used to reassemble the table from the\n",
      "        three ASCII files.\n",
      "        \n",
      "        \n",
      "        - **datafile:** Each line of the data file represents one row of table\n",
      "          data.  The data is output one column at a time in column order.  If\n",
      "          a column contains an array, each element of the column array in the\n",
      "          current row is output before moving on to the next column.  Each row\n",
      "          ends with a new line.\n",
      "        \n",
      "          Integer data is output right-justified in a 21-character field\n",
      "          followed by a blank.  Floating point data is output right justified\n",
      "          using 'g' format in a 21-character field with 15 digits of\n",
      "          precision, followed by a blank.  String data that does not contain\n",
      "          whitespace is output left-justified in a field whose width matches\n",
      "          the width specified in the ``TFORM`` header parameter for the\n",
      "          column, followed by a blank.  When the string data contains\n",
      "          whitespace characters, the string is enclosed in quotation marks\n",
      "          (``\"\"``).  For the last data element in a row, the trailing blank in\n",
      "          the field is replaced by a new line character.\n",
      "        \n",
      "          For column data containing variable length arrays ('P' format), the\n",
      "          array data is preceded by the string ``'VLA_Length= '`` and the\n",
      "          integer length of the array for that row, left-justified in a\n",
      "          21-character field, followed by a blank.\n",
      "        \n",
      "          .. note::\n",
      "        \n",
      "              This format does *not* support variable length arrays using the\n",
      "              ('Q' format) due to difficult to overcome ambiguities. What this\n",
      "              means is that this file format cannot support VLA columns in\n",
      "              tables stored in files that are over 2 GB in size.\n",
      "        \n",
      "          For column data representing a bit field ('X' format), each bit\n",
      "          value in the field is output right-justified in a 21-character field\n",
      "          as 1 (for true) or 0 (for false).\n",
      "        \n",
      "        - **cdfile:** Each line of the column definitions file provides the\n",
      "          definitions for one column in the table.  The line is broken up into\n",
      "          8, sixteen-character fields.  The first field provides the column\n",
      "          name (``TTYPEn``).  The second field provides the column format\n",
      "          (``TFORMn``).  The third field provides the display format\n",
      "          (``TDISPn``).  The fourth field provides the physical units\n",
      "          (``TUNITn``).  The fifth field provides the dimensions for a\n",
      "          multidimensional array (``TDIMn``).  The sixth field provides the\n",
      "          value that signifies an undefined value (``TNULLn``).  The seventh\n",
      "          field provides the scale factor (``TSCALn``).  The eighth field\n",
      "          provides the offset value (``TZEROn``).  A field value of ``\"\"`` is\n",
      "          used to represent the case where no value is provided.\n",
      "        \n",
      "        - **hfile:** Each line of the header parameters file provides the\n",
      "          definition of a single HDU header card as represented by the card\n",
      "          image.\n",
      "    \n",
      "    tableload(datafile, cdfile, hfile=None)\n",
      "        Create a table from the input ASCII files.  The input is from up\n",
      "        to three separate files, one containing column definitions, one\n",
      "        containing header parameters, and one containing column data.  The\n",
      "        header parameters file is not required.  When the header\n",
      "        parameters file is absent a minimal header is constructed.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        datafile : file path, file object or file-like object\n",
      "            Input data file containing the table data in ASCII format.\n",
      "        \n",
      "        cdfile : file path, file object or file-like object\n",
      "            Input column definition file containing the names, formats,\n",
      "            display formats, physical units, multidimensional array\n",
      "            dimensions, undefined values, scale factors, and offsets\n",
      "            associated with the columns in the table.\n",
      "        \n",
      "        hfile : file path, file object or file-like object, optional\n",
      "            Input parameter definition file containing the header\n",
      "            parameter definitions to be associated with the table.\n",
      "            If `None`, a minimal header is constructed.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The primary use for the `tableload` function is to allow the input of\n",
      "        ASCII data that was edited in a standard text editor of the table\n",
      "        data and parameters.  The tabledump function can be used to create the\n",
      "        initial ASCII files.\n",
      "        \n",
      "        \n",
      "        - **datafile:** Each line of the data file represents one row of table\n",
      "          data.  The data is output one column at a time in column order.  If\n",
      "          a column contains an array, each element of the column array in the\n",
      "          current row is output before moving on to the next column.  Each row\n",
      "          ends with a new line.\n",
      "        \n",
      "          Integer data is output right-justified in a 21-character field\n",
      "          followed by a blank.  Floating point data is output right justified\n",
      "          using 'g' format in a 21-character field with 15 digits of\n",
      "          precision, followed by a blank.  String data that does not contain\n",
      "          whitespace is output left-justified in a field whose width matches\n",
      "          the width specified in the ``TFORM`` header parameter for the\n",
      "          column, followed by a blank.  When the string data contains\n",
      "          whitespace characters, the string is enclosed in quotation marks\n",
      "          (``\"\"``).  For the last data element in a row, the trailing blank in\n",
      "          the field is replaced by a new line character.\n",
      "        \n",
      "          For column data containing variable length arrays ('P' format), the\n",
      "          array data is preceded by the string ``'VLA_Length= '`` and the\n",
      "          integer length of the array for that row, left-justified in a\n",
      "          21-character field, followed by a blank.\n",
      "        \n",
      "          .. note::\n",
      "        \n",
      "              This format does *not* support variable length arrays using the\n",
      "              ('Q' format) due to difficult to overcome ambiguities. What this\n",
      "              means is that this file format cannot support VLA columns in\n",
      "              tables stored in files that are over 2 GB in size.\n",
      "        \n",
      "          For column data representing a bit field ('X' format), each bit\n",
      "          value in the field is output right-justified in a 21-character field\n",
      "          as 1 (for true) or 0 (for false).\n",
      "        \n",
      "        - **cdfile:** Each line of the column definitions file provides the\n",
      "          definitions for one column in the table.  The line is broken up into\n",
      "          8, sixteen-character fields.  The first field provides the column\n",
      "          name (``TTYPEn``).  The second field provides the column format\n",
      "          (``TFORMn``).  The third field provides the display format\n",
      "          (``TDISPn``).  The fourth field provides the physical units\n",
      "          (``TUNITn``).  The fifth field provides the dimensions for a\n",
      "          multidimensional array (``TDIMn``).  The sixth field provides the\n",
      "          value that signifies an undefined value (``TNULLn``).  The seventh\n",
      "          field provides the scale factor (``TSCALn``).  The eighth field\n",
      "          provides the offset value (``TZEROn``).  A field value of ``\"\"`` is\n",
      "          used to represent the case where no value is provided.\n",
      "        \n",
      "        - **hfile:** Each line of the header parameters file provides the\n",
      "          definition of a single HDU header card as represented by the card\n",
      "          image.\n",
      "    \n",
      "    unregister_hdu(hducls) method of astropy.io.fits.hdu.base._BaseHDUMeta instance\n",
      "    \n",
      "    update(filename, data, *args, **kwargs)\n",
      "        Update the specified extension with the input data/header.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : file path, file object, or file like object\n",
      "            File to update.  If opened, mode must be update (rb+).  An opened file\n",
      "            object or `~gzip.GzipFile` object will be closed upon return.\n",
      "        \n",
      "        data : array, table, or group data object\n",
      "            the new data used for updating\n",
      "        \n",
      "        header : `Header` object, optional\n",
      "            The header associated with ``data``.  If `None`, an appropriate header\n",
      "            will be created for the data object supplied.\n",
      "        \n",
      "        ext, extname, extver\n",
      "            The rest of the arguments are flexible: the 3rd argument can be the\n",
      "            header associated with the data.  If the 3rd argument is not a\n",
      "            `Header`, it (and other positional arguments) are assumed to be the\n",
      "            extension specification(s).  Header and extension specs can also be\n",
      "            keyword arguments.  For example::\n",
      "        \n",
      "                update(file, dat, hdr, 'sci')  # update the 'sci' extension\n",
      "                update(file, dat, 3)  # update the 3rd extension\n",
      "                update(file, dat, hdr, 3)  # update the 3rd extension\n",
      "                update(file, dat, 'sci', 2)  # update the 2nd SCI extension\n",
      "                update(file, dat, 3, header=hdr)  # update the 3rd extension\n",
      "                update(file, dat, header=hdr, ext=5)  # update the 5th extension\n",
      "        \n",
      "        kwargs\n",
      "            Any additional keyword arguments to be passed to\n",
      "            `astropy.io.fits.open`.\n",
      "    \n",
      "    writeto(filename, data, header=None, output_verify='exception', overwrite=False, checksum=False)\n",
      "        Create a new FITS file using the supplied data/header.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : file path, file object, or file like object\n",
      "            File to write to.  If opened, must be opened in a writeable binary\n",
      "            mode such as 'wb' or 'ab+'.\n",
      "        \n",
      "        data : array, record array, or groups data object\n",
      "            data to write to the new file\n",
      "        \n",
      "        header : `Header` object, optional\n",
      "            the header associated with ``data``. If `None`, a header\n",
      "            of the appropriate type is created for the supplied data. This\n",
      "            argument is optional.\n",
      "        \n",
      "        output_verify : str\n",
      "            Output verification option.  Must be one of ``\"fix\"``, ``\"silentfix\"``,\n",
      "            ``\"ignore\"``, ``\"warn\"``, or ``\"exception\"``.  May also be any\n",
      "            combination of ``\"fix\"`` or ``\"silentfix\"`` with ``\"+ignore\"``,\n",
      "            ``+warn``, or ``+exception\" (e.g. ``\"fix+warn\"``).  See :ref:`verify`\n",
      "            for more info.\n",
      "        \n",
      "        overwrite : bool, optional\n",
      "            If ``True``, overwrite the output file if it exists. Raises an\n",
      "            ``OSError`` (``IOError`` for Python 2) if ``False`` and the\n",
      "            output file exists. Default is ``False``.\n",
      "        \n",
      "            .. versionchanged:: 1.3\n",
      "               ``overwrite`` replaces the deprecated ``clobber`` argument.\n",
      "        \n",
      "        checksum : bool, optional\n",
      "            If `True`, adds both ``DATASUM`` and ``CHECKSUM`` cards to the\n",
      "            headers of all HDU's written to the file.\n",
      "\n",
      "DATA\n",
      "    BITPIX2DTYPE = {-64: 'float64', -32: 'float32', 8: 'uint8', 16: 'int16...\n",
      "    DELAYED = <astropy.io.fits.hdu.base._Delayed object>\n",
      "    DTYPE2BITPIX = {'float32': -32, 'float64': -64, 'int16': 16, 'int32': ...\n",
      "    __all__ = ['Conf', 'conf', 'Card', 'Undefined', 'Column', 'ColDefs', '...\n",
      "    conf = <astropy.io.fits.Conf object>\n",
      "\n",
      "FILE\n",
      "    /anaconda3/lib/python3.6/site-packages/astropy/io/fits/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(astropy.io.fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fits_data = astropy.io.fits.open('asu.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: asu.fit\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      46   ()      \n",
      "  1  J_ApJS_184_218_table3    1 TableHDU        38   50R x 7C   [I6, F10.6, F10.6, F7.4, F5.1, F5.2, I1]   \n"
     ]
    }
   ],
   "source": [
    "fits_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XTENSION= 'TABLE   '           / Ascii Table Extension (TAB and NEWLINE sep)    \n",
       "BITPIX  =                    8 / Character data                                 \n",
       "NAXIS   =                    2 / Simple 2-D matrix                              \n",
       "NAXIS1  =                   52 / Number of bytes per record                     \n",
       "NAXIS2  =                   50 / Number of records                              \n",
       "PCOUNT  =                    0 / Get rid of random parameters                   \n",
       "GCOUNT  =                    1 / Only one group (isn't it obvious?)             \n",
       "TFIELDS =                    7 / Number of data fields (columns)                \n",
       "CDS-CAT = 'J/ApJS/184/218'     / Catalogue designation in CDS nomenclature      \n",
       "         The zCOSMOS 10k-bright spectroscopic sample (Lilly+, 2009)             \n",
       "EXTNAME = 'J_ApJS_184_218_table3' / Identification of the table                 \n",
       "CDS-NAME= 'J/ApJS/184/218/table3' / Table name in METAtab                       \n",
       "         zCOSMOS-bright 10k sample                                              \n",
       "TBCOL1  =                    2 / UCD=meta.id;meta.main int: ... offset=1        \n",
       "TFORM1  = 'I6      '           / Fortran Format                                 \n",
       "TTYPE1  = 'zCOSMOS '           / zCOSMOS identification number                  \n",
       "TBCOL2  =                    9 / UCD=pos.eq.ra;meta.main double: offset=8       \n",
       "TFORM2  = 'F10.6   '           / Fortran Format                                 \n",
       "TTYPE2  = 'RAJ2000 '           / Right Ascension in decimal degrees (J2000)     \n",
       "TUNIT2  = 'deg     '           / degree                                         \n",
       "TBCOL3  =                   20 / UCD=pos.eq.dec;meta.main double: offset=19     \n",
       "TFORM3  = 'F10.6   '           / Fortran Format                                 \n",
       "TTYPE3  = 'DEJ2000 '           / Declination in decimal degrees (J2000)         \n",
       "TUNIT3  = 'deg     '           / degree                                         \n",
       "TBCOL4  =                   31 / UCD=src.redshift float: ...... offset=30       \n",
       "TFORM4  = 'F7.4    '           / Fortran Format                                 \n",
       "TTYPE4  = 'z       '           / ? Spectroscopic redshift                       \n",
       "TNULL4  = 'NaN     '           / NULL definition                                \n",
       "TBCOL5  =                   39 / UCD=meta.code.qual float: .... offset=38       \n",
       "TFORM5  = 'F5.1    '           / Fortran Format                                 \n",
       "TTYPE5  = 'CClass  '           / Confidence class indicating reliability (1)    \n",
       "TBCOL6  =                   45 / UCD=phot.mag;em.opt.I float: . offset=44       \n",
       "TFORM6  = 'F5.2    '           / Fortran Format                                 \n",
       "TTYPE6  = 'Imag    '           / HST F814W filter selection AB magnitude        \n",
       "TUNIT6  = 'mag     '           / magnitude                                      \n",
       "TBCOL7  =                   51 / UCD=meta.code unsignedByte: .. offset=50       \n",
       "TFORM7  = 'I1      '           / Fortran Format                                 \n",
       "TTYPE7  = 'Mask    '           / Mask priority flag (2)                         "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fits_data[1].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = fits_data[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8798  0.6972  0.9069  0.8964  0.2835  0.6984  0.      0.      0.0793\n",
      "  0.      0.3712  0.5255  0.      0.      0.9389  0.3441  0.8321  0.7349\n",
      "  0.      0.      0.3315  0.1212  0.2231  0.218   0.      1.1745  0.      0.\n",
      "  0.8693  0.7435  0.663   0.8369  0.984   0.      0.4612  0.2465  0.6208\n",
      "  0.      0.4071  0.7439  0.7237  0.9305  0.4235  0.      0.1233  0.1948\n",
      "  0.7268  0.2214  0.3719  0.8061]\n"
     ]
    }
   ],
   "source": [
    "x = data[\"z\"]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22.27  21.96  22.24  21.84  22.14  22.5   21.91  22.47  22.41  22.38\n",
      "  22.31  22.29  22.47  22.49  22.46  22.15  22.49  22.49  22.05  22.44\n",
      "  22.46  21.81  22.47  22.46  22.31  22.49  22.36  22.39  22.5   22.5\n",
      "  22.47  22.35  22.33  20.66  21.63  21.46  22.5   22.49  22.39  22.35\n",
      "  22.19  22.44  22.4   22.48  19.69  22.1   22.46  20.47  22.5   22.46]\n"
     ]
    }
   ],
   "source": [
    "y = data[\"Imag\"]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d6c8f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(x, color='blue', linewidth=5)\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel(\"Redshift\")\n",
    "plt.ylabel(\"Number\")\n",
    "plt.show()\n",
    "plt.savefig(\"Redshift Plot 1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
